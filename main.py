import streamlit as st
import os
import pandas as pd
import time
import re
import csv
from datetime import datetime
import altair as alt
import json

# LangChain & Core
from langchain_community.retrievers import BM25Retriever
from langchain.retrievers import EnsembleRetriever
from langchain_chroma import Chroma
from langchain_core.documents import Document
from langchain.schema import HumanMessage # [ê°œì„ 2] HumanMessage ì¶”ê°€
from langchain_core.prompts import PromptTemplate

# Core ëª¨ë“ˆ
try:
    from core.config import PERSIST_DIRECTORY
    from core.llm import get_llm, get_embeddings
    from core.decision_ai import decision_ai
except ImportError:
    PERSIST_DIRECTORY = "./chroma_db"
    from core.llm import get_llm, get_embeddings

# ------------------------------------------------------------------
# [ê°œì„ ] ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œë¡œ ê³ ì •)
# ------------------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SHARED_DIR = os.path.join(BASE_DIR, "shared")
if not os.path.exists(SHARED_DIR):
    os.makedirs(SHARED_DIR)
# [ì„¤ì • íŒŒì¼ ê²½ë¡œ ì •ì˜]
CONFIG_FILE = os.path.join(SHARED_DIR, "system_config.json")

st.set_page_config(page_title="ì² ë„ì•ˆì „ AI ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸš„ ì² ë„ì•ˆì „ AI í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ (v1.0)")

# ------------------------------------------------------------------
# í•¨ìˆ˜ ì •ì˜
# ------------------------------------------------------------------
def get_vectorstore():
    # 1. DB í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(PERSIST_DIRECTORY):
        return None
    
    try:
        # 2. ChromaDB ë¡œë“œ
        # ì£¼ì˜: collection_name="regulations" ë¶€ë¶„ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.
        # admin.pyì—ì„œ ì €ì¥í•œ ê¸°ë³¸ ì„¤ì •ê³¼ ë§ì¶”ê¸° ìœ„í•¨ì…ë‹ˆë‹¤
        vectorstore = Chroma(
            persist_directory=PERSIST_DIRECTORY,
            embedding_function=get_embeddings()
        )
        return vectorstore
    except Exception as e:
        st.error(f"ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# [ì‹ ê·œ í•¨ìˆ˜] ì„¤ì •ëœ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
def get_selected_model():
    default_model = "korean-llama3:latest"
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                config = json.load(f)
                return config.get("selected_model", default_model)
        except:
            return default_model
    return default_model

def save_feedback(user_q, ai_a, user_correction, rating):
    """ì‚¬ìš©ì í”¼ë“œë°±ì„ CSVì— ì €ì¥ (ê´€ë¦¬ì í•™ìŠµìš©)"""
    feedback_file = os.path.join(SHARED_DIR, "feedback_log.csv")
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë” ìƒì„±
    if not os.path.exists(feedback_file):
        with open(feedback_file, mode="w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(["Timestamp", "Question", "AI_Answer", "User_Correction", "Rating", "Status"])

    # ë°ì´í„° ì¶”ê°€
    with open(feedback_file, mode="a", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow([
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            user_q,
            ai_a,
            user_correction,
            rating,
            "Pending"  # ê´€ë¦¬ìê°€ ì•„ì§ ë°˜ì˜ ì•ˆ í•¨
        ])

# def query_regulation(query, vectorstore, llm):
#     """
#     ì§ˆë¬¸ì— ëŒ€í•´ ë²¡í„° ì €ì¥ì†Œì—ì„œ ë¬¸ì„œë¥¼ ì°¾ê³ , 
#     'ì‚¬ìš©ì í”¼ë“œë°±'ì„ ìµœìš°ì„ ìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
#     """
#     # 1. ê²€ìƒ‰ ìˆ˜í–‰ (í”¼ë“œë°± ëˆ„ë½ ë°©ì§€ë¥¼ ìœ„í•´ kê°’ì„ ë„‰ë„‰íˆ 8ë¡œ ì„¤ì •)
#     # MMR(Maximal Marginal Relevance)ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ì–‘í•œ ë§¥ë½ì˜ ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
#     retriever = vectorstore.as_retriever(
#         search_type="mmr",
#         search_kwargs={"k": 8, "fetch_k": 20, "lambda_mult": 0.5}
#     )
#     docs = retriever.invoke(query)

#     if not docs:
#         return "ê´€ë ¨ëœ ê·œì • ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

#     # 2. [í•µì‹¬] ì‚¬ìš©ì í”¼ë“œë°± ìš°ì„ ìˆœìœ„ ì •ë ¬
#     # metadata['type'] == 'feedback' ì´ê±°ë‚˜ sourceê°€ 'ì‚¬ìš©ì í”¼ë“œë°±'ì¸ ê²ƒì„ ìµœìƒë‹¨ìœ¼ë¡œ ì˜¬ë¦¼
#     def get_priority(doc):
#         m = doc.metadata
#         reward = float(m.get("reward_score", 0))
#         confidence = float(m.get("confidence", 0.5))

#         # ì‹œê°„ ê°ì‡  (ì˜¤ë˜ëœ í”¼ë“œë°±ì€ ì˜í–¥ ê°ì†Œ)
#         try:
#             ts = datetime.fromisoformat(m.get("timestamp"))
#             age_days = (datetime.now() - ts).days
#             decay = max(0.5, 1 - age_days / 365)
#         except:
#             decay = 1.0
        
#         # í•µì‹¬ ê°•í™”í•™ìŠµ ê·¼ì‚¬ì‹ì…ë‹ˆë‹¤
#         return reward * confidence * decay

#     sorted_docs = sorted(
#         [d for d in docs if d.metadata.get("reward_score", 0) >= 0],
#         key=get_priority,
#         reverse=True
#     )

#     # 3. ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì¶œì²˜ë¥¼ ëª…í™•íˆ í•˜ì—¬ LLMì´ íŒë‹¨í•˜ê¸° ì‰½ê²Œ í•¨)
#     context_parts = []
#     for d in sorted_docs:
#         source_name = d.metadata.get('source', 'ì•Œ ìˆ˜ ì—†ìŒ')
#         # íŒŒì¼ ê²½ë¡œì¼ ê²½ìš° íŒŒì¼ëª…ë§Œ ì¶”ì¶œ
#         source_name = os.path.basename(source_name)
        
#         # í”¼ë“œë°± ë°ì´í„°ì¸ ê²½ìš° ê°•ì¡° í‘œì‹œ
#         if get_priority(d) >= 1:
#             context_parts.append(f"[â€¼ï¸ ìµœì‹  êµì • ì •ë³´ - ì¶œì²˜: {source_name}]\n{d.page_content}")
#         else:
#             context_parts.append(f"[ì¶œì²˜: {source_name}]\n{d.page_content}")
    
#     context_text = "\n\n".join(context_parts)

#     # 4. í”„ë¡¬í”„íŠ¸ ì •ì˜ (í”¼ë“œë°± ìµœìš°ì„  ì›ì¹™ ê°•ì œ)
#     prompt_template = """
#     ### [Role]
#     ë‹¹ì‹ ì€ ì² ë„ ì•ˆì „ ê·œì • ë° ì‹¤ë¬´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
#     ì œê³µëœ [ê·œì • ë° í”¼ë“œë°± ë¬¸ë§¥]ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹­ì‹œì˜¤.

#     ### [Priority Rule - ë§¤ìš° ì¤‘ìš”]
#     1. ë¬¸ë§¥ ì¤‘ **'[â€¼ï¸ ìµœì‹  êµì • ì •ë³´]'**ë¼ê³  í‘œì‹œëœ ë‚´ìš©ì€ ì‚¬ìš©ìê°€ ì§ì ‘ êµì •í•œ ì •ë‹µì…ë‹ˆë‹¤.
#     2. ì¼ë°˜ ê·œì • íŒŒì¼ì˜ ë‚´ìš©ê³¼ 'ìµœì‹  êµì • ì •ë³´'ì˜ ë‚´ìš©ì´ ì„œë¡œ ì¶©ëŒí•˜ê±°ë‚˜ ë‹¤ë¥¼ ê²½ìš°, **ë°˜ë“œì‹œ 'ìµœì‹  êµì • ì •ë³´'ë¥¼ ì •ë‹µìœ¼ë¡œ ì±„íƒ**í•˜ì‹­ì‹œì˜¤.
#     3. ë§Œì•½ ì´ì „ì˜ 'Feedback' íŒŒì¼ê³¼ í˜„ì¬ì˜ 'ì‚¬ìš©ì í”¼ë“œë°±' ë‚´ìš©ì´ ë‹¤ë¥´ë‹¤ë©´, ê°€ì¥ ìœ„ì— ë°°ì¹˜ëœ ë‚´ìš©ì„ ì‹ ë¢°í•˜ì‹­ì‹œì˜¤.

#     ### [Guidelines]
#     - ë°˜ë“œì‹œ í•œêµ­ì–´(Korean)ë¡œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
#     - ë‹µë³€ ì‹œ "ìµœì‹  êµì •ëœ í”¼ë“œë°±ì— ë”°ë¥´ë©´..." ë˜ëŠ” "í˜„í–‰ ê·œì • ì œOì¡°ì— ë”°ë¥´ë©´..."ê³¼ ê°™ì´ ê·¼ê±°ë¥¼ ë°íˆì‹­ì‹œì˜¤.

#     [ê·œì • ë° í”¼ë“œë°± ë¬¸ë§¥]
#     {context}

#     ì§ˆë¬¸: {question}

#     ë‹µë³€:
#     """
    
#     full_prompt = prompt_template.format(context=context_text, question=query)
    
#     try:
#         # LLM í˜¸ì¶œ
#         response = llm.invoke([HumanMessage(content=full_prompt)])
#         return response.content, sorted_docs
#     except Exception as e:
#         return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}", sorted_docs

# [ìˆ˜ì •] query_regulation í•¨ìˆ˜: í‚¤ì›Œë“œ ì •ë°€ë„ ë° ì „ë¬¸ê°€ ì •ì±… ë°˜ì˜
def query_regulation(query, vectorstore, llm):
    # 1. ì „ë¬¸ê°€ í”¼ë“œë°±(Applied) ë°ì´í„° ìµœìš°ì„  í™•ì¸ (Fast-Track)
    # ê´€ë¦¬ìê°€ admin.pyì—ì„œ 'ì²­ì›íœ´ê°€' ì •ë‹µì„ ìŠ¹ì¸í–ˆë‹¤ë©´ ì—¬ê¸°ì„œ ì¦‰ì‹œ ë°˜í™˜ë©ë‹ˆë‹¤.
    feedback_file = os.path.join(SHARED_DIR, "feedback_log.csv")
    if os.path.exists(feedback_file):
        try:
            fb_df = pd.read_csv(feedback_file)
            # ì§ˆë¬¸ì˜ ì• 5ê¸€ìê°€ í¬í•¨ëœ 'Applied' ìƒíƒœì˜ ì •ë‹µ ê²€ìƒ‰
            match = fb_df[(fb_df['Status'] == 'Applied') & (fb_df['Question'].str.contains(query[:5]))]
            if not match.empty:
                return f"âœ… **[ì „ë¬¸ê°€ ê²€ì¦ ë‹µë³€]**\n\n{match.iloc[-1]['User_Correction']}", []
        except: pass

    # 2. í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì—”ì§„ êµ¬ì„± (BM25 + Vector)
    # [ë¬¸ì œí•´ê²°] 'ì²­ì›íœ´ê°€'ë¼ëŠ” ì •í™•í•œ ë‹¨ì–´ë¥¼ ì°¾ê¸° ìœ„í•´ BM25 ê°€ì¤‘ì¹˜ë¥¼ 0.8ë¡œ ì„¤ì •
    all_docs_data = vectorstore.get()
    all_docs = [
        Document(page_content=text, metadata=meta) 
        for text, meta in zip(all_docs_data['documents'], all_docs_data['metadatas'])
    ]
    
    # í‚¤ì›Œë“œ ê²€ìƒ‰ê¸° (ë‹¨ì–´ ì¼ì¹˜ ì¤‘ì‹¬)
    bm25_retriever = BM25Retriever.from_documents(all_docs)
    bm25_retriever.k = 3
    
    # ë²¡í„° ê²€ìƒ‰ê¸° (ì˜ë¯¸ ìœ ì‚¬ë„ ì¤‘ì‹¬)
    vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 3})
    
    # ì•™ìƒë¸”: ë²•ë ¹ì€ í‚¤ì›Œë“œê°€ ì¤‘ìš”í•˜ë¯€ë¡œ BM25ì— ì••ë„ì  ê°€ì¤‘ì¹˜ ë¶€ì—¬
    ensemble_retriever = EnsembleRetriever(
        retrievers=[bm25_retriever, vector_retriever],
        weights=[0.8, 0.2] 
    )
    
    docs = ensemble_retriever.invoke(query)

    # 3. ì œëª© ê¸°ë°˜ ì¬ì •ë ¬ (Article_Title ìš°ì„ ìˆœìœ„ ë¶€ì—¬)
    # ì§ˆë¬¸ í‚¤ì›Œë“œê°€ ì¡°ë¬¸ ì œëª©ì— í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ê²€ìƒ‰ ê²°ê³¼ 1ìœ„ë¡œ ì˜¬ë¦¼
    query_keywords = query.split()
    docs = sorted(docs, key=lambda d: any(kw in d.metadata.get('Article_Title', '') for kw in query_keywords), reverse=True)

    # 4. í”„ë¡¬í”„íŠ¸ êµ¬ì„± (LLMì˜ í™˜ê° ë°©ì§€ ì§€ì¹¨ ê°•í™”)
    context_text = "\n\n".join([f"### {doc.metadata.get('Article_Title', 'ì¡°ë¬¸ ì •ë³´ ì—†ìŒ')}\n{doc.page_content}" for doc in docs])
    
    template = """ë‹¹ì‹ ì€ ìš°ë¦¬ê³µì‚¬ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì œê³µëœ [ê·œì • ë‚´ìš©]ì˜ 'ì œëª©'ê³¼ 'ë³¸ë¬¸'ì„ ëŒ€ì¡°í•˜ì—¬ ì§ˆë¬¸ì— ì •í™•íˆ ë‹µí•˜ì„¸ìš”.

    [ê·œì • ë‚´ìš©]
    {context}

    [ì§ˆë¬¸]
    {question}

    [ë‹µë³€ ê°€ì´ë“œë¼ì¸]
    1. ì§ˆë¬¸ì´ '{question}'ì¸ ê²½ìš°, ì œëª©ì— ì´ ë‹¨ì–´ê°€ í¬í•¨ëœ ì¡°ë¬¸(ì˜ˆ: ì œ26ì¡° ì²­ì›íœ´ê°€)ì„ ìš°ì„ ì ìœ¼ë¡œ ì„¤ëª…í•˜ì„¸ìš”.
    2. ì¡°ë¬¸ ë²ˆí˜¸ë¥¼ ì ˆëŒ€ ë‹¤ë¥¸ ì¡°ë¬¸(ì œ9ì¡° ë“±)ê³¼ í˜¼ë™í•˜ì§€ ë§ˆì„¸ìš”.
    3. ì¼ë°˜ì ì¸ ë…¸ë™ë²• ìƒì‹ì„ ì„ì§€ ë§ê³ , ì˜¤ì§ ìœ„ì— ì œê³µëœ í…ìŠ¤íŠ¸ë¡œë§Œ ë‹µë³€í•˜ì„¸ìš”.
    """
    
    prompt_text = template.format(context=context_text, question=query)
    response = llm.invoke([HumanMessage(content=prompt_text)])
    
    return response.content, docs

# ------------------------------------------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ------------------------------------------------------------------
if "llm" not in st.session_state:
    st.session_state["llm"] = get_llm("korean-llama3")

if "vectorstore" not in st.session_state:
    st.session_state["vectorstore"] = get_vectorstore()

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (messages ë¦¬ìŠ¤íŠ¸ì— sources ì •ë³´ë„ í•¨ê»˜ ì €ì¥)
if "messages" not in st.session_state:
    st.session_state["messages"] = []

llm = st.session_state["llm"]
vectorstore = st.session_state["vectorstore"]

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SHARED_DIR = os.path.join(BASE_DIR, "shared")
FILE_PATH = os.path.join(SHARED_DIR, "risk_df.pkl")

# ------------------------------------------------------------------
# ì‚¬ì´ë“œë°”
# ------------------------------------------------------------------
# with st.sidebar:
#     st.header("ğŸ”Œ ì‹œìŠ¤í…œ ìƒíƒœ")
#     if vectorstore is not None:
#         try:
#             count = vectorstore._collection.count()
#             st.success(f"ê·œì • DB ì—°ê²°ë¨ (ë¬¸ì„œ ì²­í¬: {count}ê°œ)")
#         except:
#             st.warning("ê·œì • DB ì—°ê²° ë¶ˆì•ˆì •")
#     else:
#         st.error("ê·œì • DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
#     if st.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
#         st.session_state["messages"] = []
#         st.rerun()

# ======================================
# íƒ­ êµ¬ì„±
# ======================================
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ’¬ ê·œì • ì±—ë´‡",
    "ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ",
    "ğŸ§  í†µí•© ìœ„í—˜ ë¶„ì„",
    "ğŸš¨ ìœ„í—˜ íŒë‹¨ & ì¡°ì¹˜ ì¶”ì²œ"
])

# ==================================================================
# TAB 1. ğŸ’¬ ê·œì • ì±—ë´‡ (ë©€í‹°í„´ + ê³ ê¸‰ê²€ìƒ‰ + í”¼ë“œë°± ë£¨í”„)
# ==================================================================
with tab1:
    
    current_model = get_selected_model()
    st.markdown(f"#### ğŸ’¬ ì² ë„ì•ˆì „ ê·œì • ì „ë¬¸ ì±—ë´‡ (Model: :orange[{current_model}])")
    st.caption("ğŸ’¡ ê·œì • ê²€ìƒ‰ë¶€í„° ì—…ë¬´ ì§ˆì˜ê¹Œì§€, AIê°€ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤.")
    
    # [1] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # [2] ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ê·œì •ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”..."):
        
        # 3-1. ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ ë° ì €ì¥
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # 3-2. ê·œì • DB ë¡œë“œ í™•ì¸
        vectorstore = get_vectorstore()
        
        if vectorstore is None:
            st.error("ğŸš¨ í•™ìŠµëœ ê·œì • DBê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ë¬¸ì„œë¥¼ ë¨¼ì € í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        else:
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                status_placeholder = st.empty()
                
                with st.spinner("ê·œì • ì •ë°€ ë¶„ì„ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        # --- [ì‹ ê·œ ì¶”ê°€] 1. ì „ë¬¸ê°€ í”¼ë“œë°± ë°ì´í„° ìš°ì„  í™•ì¸ ë¡œì§ ---
                        feedback_file = os.path.join(SHARED_DIR, "feedback_log.csv")
                        verified_answer = None
                        
                        if os.path.exists(feedback_file):
                            fb_df = pd.read_csv(feedback_file)
                            # Applied(í•™ìŠµ ì™„ë£Œ) ìƒíƒœì´ë©´ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ê³¼ ìœ ì‚¬í•œ ë°ì´í„° ê²€ìƒ‰
                            # (ì§ˆë¬¸ì˜ ì• 7ê¸€ì ì •ë„ê°€ í¬í•¨ë˜ê±°ë‚˜, ì§ˆë¬¸ ì „ì²´ê°€ í¬í•¨ë˜ëŠ” ê²½ìš°)
                            match = fb_df[
                                (fb_df['Status'] == 'Applied') & 
                                (fb_df['Question'].apply(lambda x: x[:7] in prompt or prompt[:7] in x))
                            ]
                            
                            if not match.empty:
                                # ê°€ì¥ ìµœê·¼ì— ìŠ¹ì¸ëœ ì •ë‹µì„ ê°€ì ¸ì˜´
                                verified_answer = match.iloc[-1]['User_Correction']

                        # --- 2. ë‹µë³€ ê²°ì • (í”¼ë“œë°± ì •ë‹µ vs RAG ìƒì„±) ---
                        if verified_answer:
                            # ì „ë¬¸ê°€ê°€ ì´ë¯¸ êµì •í•œ ì •ë‹µì´ ìˆëŠ” ê²½ìš°
                            response_text = f"âœ… **[ì „ë¬¸ê°€ ê²€ì¦ ë‹µë³€]**\n\n{verified_answer}"
                            docs = [] # í”¼ë“œë°± ë‹µë³€ì´ë¯€ë¡œ ë³„ë„ ê²€ìƒ‰ ê²°ê³¼ëŠ” ë¹„ì›€ (ë˜ëŠ” ê²€ìƒ‰ ë³‘í–‰ ê°€ëŠ¥)
                            status_msg = "ğŸ’¡ ê´€ë¦¬ìê°€ ìŠ¹ì¸í•œ ì „ë¬¸ê°€ ì§€ì‹ë² ì´ìŠ¤ì—ì„œ ì •ë‹µì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
                        else:
                            # ê²€ì¦ëœ ì •ë‹µì´ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ RAG ë¡œì§ ì‹¤í–‰
                            model_name = get_selected_model() 
                            llm_instance = get_llm(model_name)
                            response_text, docs = query_regulation(prompt, vectorstore, llm_instance)
                            status_msg = "ğŸ” í”¼ë“œë°± ìš°ì„  ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤. (AI ìƒì„± ë‹µë³€)"
                            
                        # ì†ŒìŠ¤ ì •ë³´ êµ¬ì¡°í™” (UI ì¶œë ¥ìš©)
                        sources_for_ui = []
                        seen_titles = set()
                        for doc in docs:
                            src_file = os.path.basename(doc.metadata.get("source", "íŒŒì¼"))
                            title = doc.metadata.get("Article_Title", "ë³¸ë¬¸")
                            
                            key = (src_file, title)
                            if key not in seen_titles:
                                sources_for_ui.append({
                                    "source": src_file, 
                                    "title": title, 
                                    "content": doc.page_content
                                })
                                seen_titles.add(key)

                        # ê²°ê³¼ ì¶œë ¥
                        message_placeholder.markdown(response_text)
                        status_placeholder.caption("ğŸ” í”¼ë“œë°± ìš°ì„  ê²€ìƒ‰ ì•Œê³ ë¦¬ì¦˜ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")
                        
                        # ì„¸ì…˜ì— Assistant ë©”ì‹œì§€ ì €ì¥
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": response_text,
                            "sources": sources_for_ui,
                            "status": "ğŸ” í”¼ë“œë°± ìš°ì„  ê²€ìƒ‰ ê²°ê³¼ì…ë‹ˆë‹¤.",
                            "timestamp": time.time()
                        })
                        
                        # í™”ë©´ ê°±ì‹  (í”¼ë“œë°± ë²„íŠ¼ ë° ëŒ€í™” ë‚´ì—­ ë°˜ì˜)
                        st.rerun()

                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # [3] ëŒ€í™” ë‚´ì—­ ì¶œë ¥ (if prompt ë¸”ë¡ ì™¸ë¶€)
    # ì§ˆë¬¸ì„ ì…ë ¥í•˜ì§€ ì•Šì•˜ì„ ë•Œë„ ì´ì „ ëŒ€í™”ê°€ ë³´ì—¬ì•¼ í•˜ë¯€ë¡œ ì¸ë´íŠ¸ë¥¼ ë°–ìœ¼ë¡œ ëºë‹ˆë‹¤.
    st.divider()
    
    if st.session_state.messages:
        # ë©”ì‹œì§€ë¥¼ (ì§ˆë¬¸, ë‹µë³€) ìŒìœ¼ë¡œ ê·¸ë£¹í™”
        conversations = []
        msgs = st.session_state.messages
        
        for i in range(0, len(msgs), 2):
            if i + 1 < len(msgs):
                conversations.append((msgs[i], msgs[i+1]))
            else:
                conversations.append((msgs[i], None))
        
        # ìµœì‹  ëŒ€í™”ê°€ ìœ„ë¡œ ì˜¤ë„ë¡ ì—­ìˆœ ì¶œë ¥
        for user_msg, ai_msg in reversed(conversations):
            with st.container():
                # A. ì‚¬ìš©ì ì§ˆë¬¸
                if user_msg:
                    with st.chat_message("user"):
                        st.write(user_msg["content"])
                
                # B. AI ë‹µë³€
                if ai_msg:
                    with st.chat_message("assistant"):
                        st.write(ai_msg["content"])
                        
                        if ai_msg.get("status"):
                            st.caption(ai_msg["status"])
                        
                        if ai_msg.get("sources"):
                            with st.expander("ğŸ“š ê·¼ê±° ê·œì • ë³´ê¸°"):
                                for src in ai_msg["sources"]:
                                    st.markdown(f"**ğŸ“„ {src['source']} - {src['title']}**")
                                    # í‘œ í˜•ì‹ ê¹¨ì§ ë°©ì§€ ë° ê¸¸ì´ ì œí•œ
                                    safe_content = src['content'].replace("|", " ").replace("\n", " ")[:250]
                                    st.caption(f"{safe_content}...")
                        
                        # í”¼ë“œë°± ë²„íŠ¼ UI
                        ts = ai_msg.get("timestamp", int(time.time()))
                        fb_key = f"fb_{ts}"
                        
                        col_f1, col_f2 = st.columns([1, 4])
                        with col_f1:
                            if st.button("ğŸ‘ ì¢‹ì•„ìš”", key=f"lk_{fb_key}"):
                                save_feedback(user_msg["content"], ai_msg["content"], "", "Good")
                                st.toast("í‰ê°€ ê°ì‚¬í•©ë‹ˆë‹¤!")
                        with col_f2:
                            with st.popover("ğŸ‘ ìˆ˜ì • ì œì•ˆ"):
                                correction = st.text_area("ì˜¬ë°”ë¥¸ ë‚´ìš©:", key=f"tx_{fb_key}")
                                if st.button("ì „ì†¡", key=f"sd_{fb_key}"):
                                    if correction:
                                        save_feedback(user_msg["content"], ai_msg["content"], correction, "Bad")
                                        st.success("ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìê°€ ê²€í†  í›„ DBì— ë°˜ì˜í•©ë‹ˆë‹¤.")

            st.divider()
                                
# ======================================
# TAB 2. ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ (Professional Ver.)
# ======================================
with tab2:
    # 1. í—¤ë” & ì»¨íŠ¸ë¡¤ íŒ¨ë„
    col_header, col_filter = st.columns([3, 1])
    
    with col_header:
        st.subheader("ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ")
        st.caption("ë°ì´í„° ê¸°ë°˜ ì‚¬ê³  ì›ì¸ ë° ì¶”ì„¸ ì‹¬ì¸µ ë¶„ì„")
        
    with col_filter:
        line_options = ["ì „ì²´", "1í˜¸ì„ ", "2í˜¸ì„ ", "7í˜¸ì„ "]
        selected_line = st.selectbox("ğŸ” í˜¸ì„  í•„í„°", line_options)

    st.markdown("---")

    if os.path.exists(FILE_PATH):
        try:
            df = pd.read_pickle(FILE_PATH)
            
            # -----------------------------------------------------------
            # [1] ë°ì´í„° ì „ì²˜ë¦¬
            # -----------------------------------------------------------
            col_map = {
                "line": "í˜¸ì„ ",
                "date": "ë°œìƒì¼ì",
                "cause": "ë¶€ì›ì¸",
                "place": "ë°œìƒì¥ì†Œ",
                "r_type": "ê·€ì±…êµ¬ë¶„",
                "age": "ì—°ë ¹ëŒ€"
            }
            
            for key, actual_col in col_map.items():
                if actual_col not in df.columns:
                    df[actual_col] = "ì •ë³´ì—†ìŒ" if key != "date" else "2024-01-01"

            # í˜¸ì„  ì •ì œ í•¨ìˆ˜
            def clean_line_name(val):
                val_str = str(val)
                if "1í˜¸ì„ " in val_str: return "1í˜¸ì„ "
                if "2í˜¸ì„ " in val_str: return "2í˜¸ì„ "
                if "7í˜¸ì„ " in val_str: return "7í˜¸ì„ "
                return "ê¸°íƒ€"
            
            # ê´„í˜¸ ë° ìˆ«ì ì œê±° í•¨ìˆ˜ ([2]ìŒì£¼ -> ìŒì£¼)
            def clean_label_text(val):
                val_str = str(val)
                # ëŒ€ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ìˆ«ì/ë¬¸ì ì œê±° í›„ ì•ë’¤ ê³µë°± ì œê±°
                return re.sub(r'\[.*?\]', '', val_str).strip()

            df["í˜¸ì„ _ì •ì œ"] = df[col_map["line"]].apply(clean_line_name)
            df[col_map["date"]] = pd.to_datetime(df[col_map["date"]], errors='coerce')
            df["ì›”"] = df[col_map["date"]].dt.strftime('%Y-%m')

            # ë¶„ì„ìš© ì»¬ëŸ¼ë“¤ì— ëŒ€í•´ ë¼ë²¨ í´ë¦¬ë‹ ë¯¸ë¦¬ ì ìš© (ê°€ë…ì„± í–¥ìƒ)
            target_cols_clean = [col_map["cause"], col_map["place"], col_map["r_type"], col_map["age"]]
            for col in target_cols_clean:
                df[col] = df[col].apply(clean_label_text)

            # -----------------------------------------------------------
            # [2] ë°ì´í„° í•„í„°ë§
            # -----------------------------------------------------------
            target_lines = ["1í˜¸ì„ ", "2í˜¸ì„ ", "7í˜¸ì„ "]
            
            if selected_line == "ì „ì²´":
                filtered_df = df[df["í˜¸ì„ _ì •ì œ"].isin(target_lines)]
                if filtered_df.empty: filtered_df = df 
            else:
                filtered_df = df[df["í˜¸ì„ _ì •ì œ"] == selected_line]

            # -----------------------------------------------------------
            # [3] ëŒ€ì‹œë³´ë“œ ì‹œê°í™”
            # -----------------------------------------------------------
            if not filtered_df.empty:
                
                # [KPI Section] í•µì‹¬ ìš”ì•½
                kpi1, kpi2, kpi3, kpi4 = st.columns(4)
                
                total_cnt = len(filtered_df)
                kpi1.metric("ì´ ë°œìƒ ê±´ìˆ˜", f"{total_cnt}ê±´")
                
                top_cause = filtered_df[col_map["cause"]].mode()[0] if not filtered_df[col_map["cause"]].empty else "-"
                cause_cnt = filtered_df[col_map["cause"]].value_counts().iloc[0] if not filtered_df[col_map["cause"]].empty else 0
                kpi2.metric("ìµœë‹¤ ë¹ˆë„ ì›ì¸", top_cause, f"{cause_cnt}ê±´")
                
                top_place = filtered_df[col_map["place"]].mode()[0] if not filtered_df[col_map["place"]].empty else "-"
                kpi3.metric("ì£¼ìš” ë°œìƒ ì¥ì†Œ", top_place)

                top_resp = filtered_df[col_map["r_type"]].mode()[0] if not filtered_df[col_map["r_type"]].empty else "-"
                kpi4.metric("ì£¼ìš” ê·€ì±… ì‚¬ìœ ", top_resp)

                st.markdown("###")

                # [Chart Row 1] ì‹œê³„ì—´ ë¶„ì„ (ê¸°ì¡´ ìœ ì§€)
                st.markdown("##### ğŸ“… ì›”ë³„ ì‚¬ê³  ë°œìƒ ì¶”ì´ ë° ì›ì¸ êµ¬ì„±")
                time_chart_data = filtered_df.groupby(["ì›”", col_map["cause"]]).size().reset_index(name='ê±´ìˆ˜')
                
                time_chart = alt.Chart(time_chart_data).mark_bar().encode(
                    x=alt.X('ì›”', title='ê¸°ê°„'),
                    y=alt.Y('ê±´ìˆ˜', title='ë°œìƒ ê±´ìˆ˜'),
                    color=alt.Color(col_map["cause"], title='ë¶€ì›ì¸'),
                    tooltip=['ì›”', col_map["cause"], 'ê±´ìˆ˜']
                ).properties(height=300) # ë†’ì´ ì•½ê°„ ì¡°ì •
                
                st.altair_chart(time_chart, use_container_width=True)

                st.divider()

                # [Chart Row 2] ìƒì„¸ í†µê³„ ë¶„ì„ (1x4 êµ¬ì¡°ë¡œ ë³€ê²½ + ì½”ë©˜íŠ¸)
                st.markdown("##### ğŸ“Š ìƒì„¸ í†µê³„ ë° ì¸ì‚¬ì´íŠ¸ ë¶„ì„")

                # --- [í•¨ìˆ˜] ì°¨íŠ¸, í…Œì´ë¸”, ì½”ë©˜íŠ¸ ìƒì„± ---
                def create_analysis_component(data, col_name, title):
                    # 1. ë°ì´í„° ì§‘ê³„
                    counts = data[col_name].value_counts().reset_index()
                    counts.columns = ["í•­ëª©", "ê±´ìˆ˜"]
                    
                    # 2. ë¹„ìœ¨ ê³„ì‚°
                    total = counts["ê±´ìˆ˜"].sum()
                    if total > 0:
                        counts["ë¹„ìœ¨"] = ((counts["ê±´ìˆ˜"] / total) * 100).round(1) # ì†Œìˆ˜ì  1ìë¦¬
                    else:
                        counts["ë¹„ìœ¨"] = 0
                    
                    # 3. Altair ë„ë„› ì°¨íŠ¸
                    base = alt.Chart(counts).encode(theta=alt.Theta("ê±´ìˆ˜", stack=True))
                    
                    pie = base.mark_arc(innerRadius=50, outerRadius=90).encode(
                        color=alt.Color("í•­ëª©", legend=alt.Legend(orient="right", title=None)), 
                        order=alt.Order("ê±´ìˆ˜", sort="descending"),
                        tooltip=["í•­ëª©", "ê±´ìˆ˜", alt.Tooltip("ë¹„ìœ¨", format=".1f")]
                    )
                    
                    # [ìˆ˜ì •] .filter() -> .transform_filter() ë¡œ ë³€ê²½
                    text = base.mark_text(radius=110).encode(
                        text=alt.Text("ë¹„ìœ¨", format=".0f"), 
                        order=alt.Order("ê±´ìˆ˜", sort="descending"),
                        color=alt.value("black")
                    ).transform_filter(
                        alt.datum.ë¹„ìœ¨ > 4  # ë¹„ìœ¨ì´ 4% ì´ˆê³¼ì¸ ê²ƒë§Œ í…ìŠ¤íŠ¸ í‘œì‹œ
                    )

                    chart = (pie + text).properties(height=250)

                    # 4. í…Œì´ë¸” ë°ì´í„° ì •ë¦¬
                    table_df = counts[["í•­ëª©", "ê±´ìˆ˜", "ë¹„ìœ¨"]].copy()
                    table_df.columns = ["í•­ëª©", "ê±´ìˆ˜", "ë¹„ìœ¨(%)"]
                    
                    # 5. ìë™ ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
                    if not counts.empty:
                        top1 = counts.iloc[0]
                        insight_text = f"""
                        - **ìµœë‹¤ ë¹ˆë„:** <span style='color:red'>**{top1['í•­ëª©']}**</span> ({top1['ê±´ìˆ˜']}ê±´, {top1['ë¹„ìœ¨']}%)
                        """
                        
                        if len(counts) > 1:
                            top2 = counts.iloc[1]
                            diff = top1['ê±´ìˆ˜'] - top2['ê±´ìˆ˜']
                            insight_text += f"""
                            - **2ìœ„ í•­ëª©:** {top2['í•­ëª©']} ({top2['ë¹„ìœ¨']}%)
                            - **ë¶„ì„:** 1ìœ„ í•­ëª©ì´ 2ìœ„ ëŒ€ë¹„ **{diff}ê±´** ë” ë§ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
                            """
                    else:
                        insight_text = "ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

                    return chart, table_df, insight_text

                # --- [ë©”ì¸ ë¡œì§] 1 Row per Metric (1x4 Stack) ---
                metrics = [
                    ("cause", "1. ë¶€ì›ì¸ ë¶„ì„"),
                    ("place", "2. ë°œìƒì¥ì†Œ ë¶„ì„"),
                    ("r_type", "3. ê·€ì±…êµ¬ë¶„ ë¶„ì„"),
                    ("age", "4. ì—°ë ¹ëŒ€ë³„ ë¶„ì„")
                ]

                for col_key, title in metrics:
                    st.markdown(f"**ğŸ“Œ {title}**")
                    
                    # ë ˆì´ì•„ì›ƒ ë¹„ìœ¨ [ì°¨íŠ¸(2) : í…Œì´ë¸”(1.5) : ì½”ë©˜íŠ¸(1.5)]
                    c1, c2, c3 = st.columns([2, 1.5, 1.5])
                    
                    chart, df_table, insight = create_analysis_component(filtered_df, col_map[col_key], title)
                    
                    with c1:
                        st.altair_chart(chart, use_container_width=True)
                    
                    with c2:
                        st.dataframe(
                            df_table, 
                            hide_index=True, 
                            use_container_width=True,
                            height=200
                        )
                    
                    with c3:
                        st.info("ğŸ’¡ **AI Insight**")
                        st.markdown(insight, unsafe_allow_html=True)
                    
                    st.divider() # í•­ëª© ê°„ êµ¬ë¶„ì„ 

                # [List Section] ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ê¸°ì¡´ ìœ ì§€)
                st.markdown(f"##### ğŸ“‹ {selected_line} Raw Data (ìƒìœ„ 100ê±´)")
                st.dataframe(
                    filtered_df.head(100), 
                    use_container_width=True, 
                    height=250, 
                    hide_index=True
                )
            
            else:
                st.warning(f"ì„ íƒí•˜ì‹  '{selected_line}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ë””ë²„ê¹…ìš© traceback ì¶œë ¥ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
            # import traceback
            # st.text(traceback.format_exc())
    else:
        st.info("ì•„ì§ ìƒí™©ë³´ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# ==================================================================
# TAB 3. ğŸ§  í†µí•© ìœ„í—˜ ë¶„ì„ (Risk Matrix) - [ì‹œê°í™” ê°•í™” & ìë™ ì œì•ˆ Ver]
# ==================================================================
with tab3:
    st.subheader("ğŸ§  í†µí•© ìœ„í—˜ë„ í‰ê°€ (Risk Matrix)")
    st.caption("ë°œìƒ ë¹ˆë„(ë°ì´í„° ê¸°ë°˜)ì™€ ì‹¬ê°ë„(ì‚¬ìš©ì ì„¤ì •)ë¥¼ ë¶„ì„í•˜ì—¬ ìœ„í—˜ ìš°ì„ ìˆœìœ„ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.")
    
    # íŒŒì¼ ê²½ë¡œ ë³€ìˆ˜ í™•ì¸ (ì „ì—­ ë³€ìˆ˜ FILE_PATH ì‚¬ìš© ê°€ì •)
    target_file = FILE_PATH if os.path.exists(FILE_PATH) else None
    
    if target_file:
        try:
            df_risk = pd.read_pickle(target_file)
            
            # ----------------------------------------------------------
            # [1] ë°ì´í„° ì „ì²˜ë¦¬
            # ----------------------------------------------------------
            col_cause = "ì£¼ì›ì¸" if "ì£¼ì›ì¸" in df_risk.columns else "cause"
            if col_cause not in df_risk.columns:
                df_risk[col_cause] = "ì •ë³´ì—†ìŒ"
            
            unique_causes = df_risk[col_cause].unique()
            
            # ----------------------------------------------------------
            # [2] ì‹¬ê°ë„ ì„¤ì • (í‚¤ì›Œë“œ ê¸°ë°˜ ìë™ ì œì•ˆ)
            # ----------------------------------------------------------
            def suggest_severity(cause_text):
                text = str(cause_text)
                if any(k in text for k in ['ì‚¬ë§', 'í­ë°œ', 'í™”ì¬', 'ë¶•ê´´', 'ì¶©ëŒ']): return 5 # ì¹˜ëª…ì 
                if any(k in text for k in ['ì¶”ë½', 'í˜‘ì°©', 'ë¼ì„', 'ê°ì „', 'ì ˆë‹¨']): return 4 # ì¤‘ëŒ€
                if any(k in text for k in ['ê³¨ì ˆ', 'í™”ìƒ', 'ëˆ„ì¶œ']): return 3 # ë³´í†µ
                if any(k in text for k in ['ì „ë„', 'ë„˜ì–´ì§', 'ë¶€ë”ªí˜', 'ë¯¸ë„ëŸ¬ì§']): return 2 # ê²½ë¯¸
                return 1 # ë¬´ì‹œ ê°€ëŠ¥

            with st.expander("âš™ï¸ [ì„¤ì •] ì‚¬ê³  ìœ í˜•ë³„ ì‹¬ê°ë„ ì¡°ì • (AI ìë™ ì œì•ˆ ì ìš©ë¨)", expanded=False):
                st.info("ğŸ’¡ ì‚¬ê³  ìœ í˜• í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ì‹¬ê°ë„ ì´ˆê¸°ê°’ì„ ìë™ìœ¼ë¡œ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ìƒí™©ì— ë§ê²Œ ì¡°ì •í•´ì£¼ì„¸ìš”.")
                
                suggested_data = [{"ì‚¬ê³ ìœ í˜•": c, "ì‹¬ê°ë„": suggest_severity(c)} for c in unique_causes]
                df_severity_base = pd.DataFrame(suggested_data)
                
                edited_df = st.data_editor(
                    df_severity_base,
                    column_config={
                        "ì‹¬ê°ë„": st.column_config.NumberColumn(
                            "ì‹¬ê°ë„ (1-5)", 
                            help="1(ê²½ë¯¸) ~ 5(ì¹˜ëª…ì )", 
                            min_value=1, max_value=5, step=1,
                            format="%dì "
                        )
                    },
                    use_container_width=True,
                    hide_index=True
                )
                
            # ----------------------------------------------------------
            # [3] ìœ„í—˜ë„ ê³„ì‚° ë¡œì§
            # ----------------------------------------------------------
            # 1. ë¹ˆë„ ê³„ì‚°
            df_freq = df_risk[col_cause].value_counts().reset_index()
            df_freq.columns = ["ì‚¬ê³ ìœ í˜•", "ë°œìƒê±´ìˆ˜"]
            
            # 2. ì‹¬ê°ë„ ë³‘í•©
            df_calc = pd.merge(df_freq, edited_df, on="ì‚¬ê³ ìœ í˜•", how="left")
            
            # 3. ë¹ˆë„ ë“±ê¸‰ ê³„ì‚°
            max_cnt = df_calc["ë°œìƒê±´ìˆ˜"].max()
            df_calc["ë¹ˆë„ë“±ê¸‰"] = df_calc["ë°œìƒê±´ìˆ˜"].apply(
                lambda x: int((x / max_cnt) * 4.99) + 1 if max_cnt > 0 else 1
            )
            
            # 4. ìœ„í—˜ ì ìˆ˜ ë° ë“±ê¸‰ íŒì •
            df_calc["ìœ„í—˜ì ìˆ˜"] = df_calc["ë¹ˆë„ë“±ê¸‰"] * df_calc["ì‹¬ê°ë„"]
            
            def get_grade(score):
                if score >= 15: return "High"
                elif score >= 8: return "Medium"
                return "Low"
            df_calc["ìœ„í—˜ë“±ê¸‰"] = df_calc["ìœ„í—˜ì ìˆ˜"].apply(get_grade)
            
            # 5. ì„¸ì…˜ ì €ì¥ (Tab 4 ì—°ë™)
            top_risks = df_calc.sort_values(["ìœ„í—˜ì ìˆ˜", "ë°œìƒê±´ìˆ˜"], ascending=[False, False])
            st.session_state['priority_risks'] = top_risks

            st.divider()

            # ----------------------------------------------------------
            # [4] ì‹œê°í™”: ë§¤íŠ¸ë¦­ìŠ¤ & ë¦¬ìŠ¤íŠ¸
            # ----------------------------------------------------------
            c_left, c_right = st.columns([1.4, 1])
            
            with c_left:
                st.markdown("##### ğŸ“Š 5x5 Risk Matrix")
                
                # --- [4-1] ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ì¤€ë¹„ ---
                grid_data = []
                for s in range(1, 6):
                    for f in range(1, 6):
                        score = s * f
                        if score >= 15: color, label = "#FF7675", "High"
                        elif score >= 8: color, label = "#FDCB6E", "Med"
                        else: color, label = "#55EFC4", "Low"
                        grid_data.append({"ì‹¬ê°ë„_X": s, "ë¹ˆë„_Y": f, "ì ìˆ˜": score, "Color": color, "Label": label})
                df_grid_base = pd.DataFrame(grid_data)
                
                # ì‹¤ì œ ë°ì´í„° ì§‘ê³„
                df_agg = df_calc.groupby(['ì‹¬ê°ë„', 'ë¹ˆë„ë“±ê¸‰']).agg(
                    ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸=('ì‚¬ê³ ìœ í˜•', lambda x: '<br>'.join(x[:10])),
                    ëŒ€í‘œì‚¬ê³ ìœ í˜•=('ì‚¬ê³ ìœ í˜•', 'first'),
                    íƒ€ì…ìˆ˜=('ì‚¬ê³ ìœ í˜•', 'count'),
                    ì´ë°œìƒê±´ìˆ˜=('ë°œìƒê±´ìˆ˜', 'sum')
                ).reset_index()
                
                # ë³‘í•©
                df_matrix_final = pd.merge(
                    df_grid_base, df_agg,
                    left_on=['ì‹¬ê°ë„_X', 'ë¹ˆë„_Y'], right_on=['ì‹¬ê°ë„', 'ë¹ˆë„ë“±ê¸‰'],
                    how='left'
                ).fillna({'íƒ€ì…ìˆ˜': 0, 'ì´ë°œìƒê±´ìˆ˜': 0, 'ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸': '-'})

                # ë¼ë²¨ ì»¬ëŸ¼ ìƒì„±
                def create_label(row):
                    if row['íƒ€ì…ìˆ˜'] > 1:
                        return f"{row['ëŒ€í‘œì‚¬ê³ ìœ í˜•']} ì™¸ {int(row['íƒ€ì…ìˆ˜'])-1}ê±´"
                    elif row['íƒ€ì…ìˆ˜'] == 1:
                        return str(row['ëŒ€í‘œì‚¬ê³ ìœ í˜•'])
                    else:
                        return ""

                df_matrix_final['ì…€_í…ìŠ¤íŠ¸'] = df_matrix_final.apply(create_label, axis=1)

                # --- [4-2] Altair ì°¨íŠ¸ êµ¬ì„± ---
                base = alt.Chart(df_matrix_final).encode(
                    x=alt.X('ì‹¬ê°ë„_X:O', title='ì‹¬ê°ë„ (ì¤‘ëŒ€ì„±) â¡ï¸', axis=alt.Axis(labelAngle=0)),
                    y=alt.Y('ë¹ˆë„_Y:O', title='ë¹ˆë„ (ê°€ëŠ¥ì„±) â¬†ï¸', sort="descending")
                )

                # Layer 1: ë°°ê²½
                heatmap = base.mark_rect(stroke='white', strokeWidth=1).encode(
                    color=alt.Color('Color', scale=None, legend=None),
                    tooltip=[
                        alt.Tooltip('Label', title='ìœ„í—˜ë“±ê¸‰'),
                        alt.Tooltip('ì ìˆ˜', title='ìœ„í—˜ì ìˆ˜'),
                        alt.Tooltip('ì´ë°œìƒê±´ìˆ˜', title='ì´ ë°œìƒ ê±´ìˆ˜'),
                        alt.Tooltip('íƒ€ì…ìˆ˜', title='í¬í•¨ëœ ì‚¬ê³ ìœ í˜• ìˆ˜'),
                        alt.Tooltip('ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸', title='ì‚¬ê³ ìœ í˜• ëª©ë¡')
                    ]
                )

                # Layer 2: ì ìˆ˜
                text_score = base.mark_text(align='right', baseline='top', dx=25, dy=-25, size=11, opacity=0.6).encode(
                    text=alt.Text('ì ìˆ˜', format='d'),
                    color=alt.value('black')
                )
                
                # Layer 3: ë‚´ìš©
                text_content = base.transform_filter(
                    alt.datum.íƒ€ì…ìˆ˜ > 0 
                ).mark_text(baseline='middle', size=12, fontWeight='bold', dy=5).encode(
                    text=alt.Text('ì…€_í…ìŠ¤íŠ¸:N'),
                    color=alt.value('black')
                )

                chart = alt.layer(heatmap, text_score, text_content).properties(
                    width='container', height=400
                ).configure_axis(labelFontSize=12, titleFontSize=14)
                
                st.altair_chart(chart, use_container_width=True)
                st.caption("ğŸ’¡ ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë¦¬ë©´ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            with c_right:
                st.markdown("##### ğŸš¨ ìœ„í—˜ ìš°ì„ ìˆœìœ„ (Top Risks)")
                
                if not top_risks.empty:
                    worst = top_risks.iloc[0]
                    st.error(
                        f"**âš ï¸ ìµœìš°ì„  ê´€ë¦¬ ëŒ€ìƒ**\n\n"
                        f"### {worst['ì‚¬ê³ ìœ í˜•']}\n"
                        f"- ìœ„í—˜ì ìˆ˜: **{worst['ìœ„í—˜ì ìˆ˜']:.0f}ì ** ({worst['ìœ„í—˜ë“±ê¸‰']})\n"
                        f"- ë°œìƒ: {worst['ë°œìƒê±´ìˆ˜']}ê±´ / ì‹¬ê°ë„: {worst['ì‹¬ê°ë„']}ë“±ê¸‰"
                    )
                
                st.divider()
                
                # ==========================================================
            # [ì¶”ê°€ ê¸°ëŠ¥] â„¹ï¸ ìœ„í—˜ì„± í‰ê°€ ê¸°ì¤€ ë° ë¡œì§ ì„¤ëª… (Legend)
            # ==========================================================
            with st.expander("â„¹ï¸ ìœ„í—˜ì„± í‰ê°€ ê¸°ì¤€ ë° ì‚°ì • ë¡œì§ (ìƒì„¸ ë³´ê¸°)", expanded=True):
                st.caption("ë³¸ ì‹œìŠ¤í…œì€ ì² ë„ì•ˆì „ê´€ë¦¬ì²´ê³„ ê¸°ìˆ ê¸°ì¤€ ë° ICAO SMS ë§¤ë‰´ì–¼ì„ ì¤€ìš©í•œ ìœ„í—˜ë„ í‰ê°€ ëª¨ë¸ì„ ë”°ë¦…ë‹ˆë‹¤.")
                
                l_col1, l_col2, l_col3 = st.columns(3)
                
                # 1. ì‹¬ê°ë„ (Severity) ì •ì˜
                with l_col1:
                    st.markdown("**1ï¸âƒ£ ì‹¬ê°ë„(Severity) ì‚°ì • ê¸°ì¤€**")
                    st.markdown(
                        """
                        <div style='font-size:13px; background-color:#f9f9f9; padding:10px; border-radius:5px;'>
                        <b>í‚¤ì›Œë“œ ê¸°ë°˜ ìë™ ë§¤í•‘ (AI)</b><br>
                        <span style='color:#FF4B4B'>ğŸ”´ 5ì  (ì¹˜ëª…):</span> ì‚¬ë§, í­ë°œ, í™”ì¬, ë¶•ê´´<br>
                        <span style='color:#FF8800'>ğŸŸ  4ì  (ì¤‘ëŒ€):</span> ì¶”ë½, í˜‘ì°©, ë¼ì„, ê°ì „<br>
                        <span style='color:#FFBB00'>ğŸŸ¡ 3ì  (ë³´í†µ):</span> ê³¨ì ˆ, í™”ìƒ, ëˆ„ì¶œ<br>
                        <span style='color:#00CC96'>ğŸŸ¢ 2ì  (ê²½ë¯¸):</span> ì „ë„, ë„˜ì–´ì§, ë¶€ë”ªí˜<br>
                        <span style='color:grey'>âšª 1ì  (ë¬´ì‹œ):</span> ê¸°íƒ€ ê²½ë¯¸í•œ ì‚¬í•­
                        </div>
                        """, unsafe_allow_html=True
                    )

                # 2. ë¹ˆë„ (Frequency) ë¡œì§
                with l_col2:
                    st.markdown("**2ï¸âƒ£ ë¹ˆë„(Frequency) ê³„ì‚° ë¡œì§**")
                    st.markdown(
                        """
                        <div style='font-size:13px; background-color:#f9f9f9; padding:10px; border-radius:5px;'>
                        <b>ìƒëŒ€ í‰ê°€ (Relative Grading)</b><br>
                        1.ë°ì´í„° ë‚´ ìµœë‹¤ ë°œìƒ ê±´ìˆ˜ë¥¼ ê¸°ì¤€, 5ë“±ê¸‰ êµ¬ê°„ìœ¼ë¡œ ìë™ í™˜ì‚°<br>
                        [ì˜ˆ: ìµœë‹¤ 100ê±´ì¼ ë•Œ, 80ê±´ ì´ìƒì€ 5ë“±ê¸‰]<br>
                        2.ê²½ê°ì‹¬ì„ ìœ„í•œ ë³´ìˆ˜ì  í‰ê°€, ë“±ê¸‰ì€ ì†Œìˆ˜ì  ì˜¬ë¦¼(ceiling) ì²˜ë¦¬<br>
                        [ì˜ˆ: 2.5 -> 3ë“±ê¸‰ (ë¬´ì¡°ê±´ ì˜¬ë¦¼)]<br>
                        
                        </div>
                        """, unsafe_allow_html=True
                    )

                # 3. ìœ„í—˜ë„ (Risk) íŒì •
                with l_col3:
                    st.markdown("**3ï¸âƒ£ ìœ„í—˜ ë“±ê¸‰(Risk Grade) íŒì •**")
                    st.markdown(
                        """
                        <div style='font-size:13px; background-color:#f9f9f9; padding:10px; border-radius:5px;'>
                        <b>Risk Score = ì‹¬ê°ë„ Ã— ë¹ˆë„</b><br>
                        <br>
                        <span style='background-color:#FFDDDD; padding:2px 5px; border-radius:3px;'>ğŸ”´ <b>High (15~25)</b></span>
                        ì¦‰ì‹œ ê°œì„  ëŒ€ì±… ìˆ˜ë¦½ í•„ìš” (Tab 4 ì—°ë™)<br>
                        <span style='background-color:#FFF8DD; padding:2px 5px; border-radius:3px;'>ğŸŸ¡ <b>Medium (8~14)</b></span>
                        ì§€ì†ì  ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬ í•„ìš”<br>
                        <span style='background-color:#DDFFDD; padding:2px 5px; border-radius:3px;'>ğŸŸ¢ <b>Low (1~7)</b></span>
                        í˜„ ìƒíƒœ ìœ ì§€ ë° ê´€ì°°
                        </div>
                        """, unsafe_allow_html=True
                    )

                st.markdown("**ìƒìœ„ ìœ„í—˜ ë¦¬ìŠ¤íŠ¸**")
                display_df = top_risks[['ì‚¬ê³ ìœ í˜•', 'ìœ„í—˜ë“±ê¸‰', 'ìœ„í—˜ì ìˆ˜', 'ë°œìƒê±´ìˆ˜']].head(5)
                st.dataframe(
                    display_df, hide_index=True, use_container_width=True,
                    column_config={
                        "ìœ„í—˜ë“±ê¸‰": st.column_config.TextColumn("ë“±ê¸‰"),
                        "ìœ„í—˜ì ìˆ˜": st.column_config.ProgressColumn("ìœ„í—˜ ì ìˆ˜", format="%dì ", min_value=0, max_value=25),
                    }
                )
                st.info("ğŸ‘‰ **Tab 4**ì—ì„œ AI ì¡°ì¹˜ ë§¤ë‰´ì–¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                    
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    else:
        st.warning("ë¶„ì„í•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


# ==================================================================
# TAB 4. ğŸš¨ ìœ„í—˜ íŒë‹¨ & ì¡°ì¹˜ ì¶”ì²œ (Action Plan) - [ë ˆì´ì•„ì›ƒ ê°œì„  Ver]
# ==================================================================
with tab4:
    st.subheader("ğŸš¨ ìœ„í—˜ ëŒ€ì‘ ì†”ë£¨ì…˜ (Action Plan)")
    st.caption("ìœ„í—˜ ìš”ì¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì¡°ì¹˜ ë°©ì•ˆì„ ì „ì²´ í™”ë©´ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

    if 'priority_risks' in st.session_state and not st.session_state['priority_risks'].empty:
        priority_df = st.session_state['priority_risks']
        risk_list = priority_df['ì‚¬ê³ ìœ í˜•'].tolist()
        
        # 1. ìƒë‹¨ ì»¨íŠ¸ë¡¤ íŒ¨ë„
        with st.container():
            c1, c2, c3 = st.columns([2, 2, 1])
            
            with c1:
                selected_risk = st.selectbox("ğŸ“Œ ë¶„ì„í•  ìœ„í—˜ ìš”ì¸ ì„ íƒ", risk_list)
            
            # ì„ íƒëœ ìœ„í—˜ ìš”ì¸ ì •ë³´
            target_row = priority_df[priority_df['ì‚¬ê³ ìœ í˜•'] == selected_risk].iloc[0]
            
            with c2:
                st.metric(
                    label="ìœ„í—˜ë„ ì •ë³´", 
                    value=f"{target_row['ìœ„í—˜ë“±ê¸‰']} ({target_row['ìœ„í—˜ì ìˆ˜']}ì )",
                    delta=f"ë°œìƒ {target_row['ë°œìƒê±´ìˆ˜']}ê±´",
                    delta_color="inverse"
                )
            
            with c3:
                st.write("") # ì¤„ë°”ê¿ˆ
                btn_generate = st.button("ğŸ§¬ ì¡°ì¹˜ë°©ì•ˆ ìƒì„±", type="primary", use_container_width=True)

        st.divider()

        # 2. ê²°ê³¼ ì¶œë ¥ í™”ë©´
        if btn_generate:
            # (ì£¼ì˜) get_vectorstore, get_selected_model, get_llm í•¨ìˆ˜ê°€ main.pyì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨
            vectorstore = get_vectorstore() 
            if not vectorstore:
                st.error("ğŸš¨ ë²¡í„° DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Tab 1ì—ì„œ DB ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner(f"'{selected_risk}' ê´€ë ¨ ê·œì • ë¶„ì„ ë° ì¡°ì¹˜ì•ˆ ì‘ì„± ì¤‘..."):
                    try:
                        # RAG ê²€ìƒ‰
                        query = f"{selected_risk} ì‚¬ê³  ì˜ˆë°© ì‘ì—… ì ˆì°¨ ì•ˆì „ ìˆ˜ì¹™"
                        retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
                        docs = retriever.invoke(query)
                        context = "\n".join([d.page_content for d in docs])
                        
                        # í”„ë¡¬í”„íŠ¸ ìƒì„±
                        prompt = f"""
                        ë‹¹ì‹ ì€ ì² ë„ ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                        ì•„ë˜ [ê²€ìƒ‰ëœ ê·œì •]ì„ ê·¼ê±°ë¡œ '{selected_risk}' ìœ„í—˜ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í–‰ë™ ë§¤ë‰´ì–¼ì„ ì‘ì„±í•˜ì„¸ìš”.
                        
                        [ê²€ìƒ‰ëœ ê·œì •]
                        {context}
                        
                        [ì‘ì„± ìš”ë ¹]
                        1. ì œëª©ì„ í¬ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
                        2. 'ì‘ì—… ì „', 'ì‘ì—… ì¤‘', 'ë¹„ìƒ ì‹œ' ë‹¨ê³„ë³„ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
                        3. ê·œì •ì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ ì•ˆì „ ìˆ˜ì¹™ì„ ì ìš©í•˜ë˜ ëª…ì‹œí•˜ì„¸ìš”.
                        4. ë¶ˆë¦¿ í¬ì¸íŠ¸ë¥¼ í™œìš©í•´ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.
                        """
                        
                        model_name = get_selected_model()
                        llm = get_llm(model_name)
                        
                        # LLM í˜¸ì¶œ
                        if hasattr(llm, 'invoke'):
                            resp = llm.invoke([HumanMessage(content=prompt)])
                            result_text = resp.content
                        else:
                            result_text = llm.predict(prompt)
                            
                        # ê²°ê³¼ ì¶œë ¥
                        st.markdown(f"### ğŸ“‹ [{selected_risk}] ì•ˆì „ ì¡°ì¹˜ ê°€ì´ë“œ")
                        
                        with st.container(border=True):
                            st.markdown(result_text)
                        
                        with st.expander("ğŸ“ ì°¸ê³ í•œ ê·œì • ì›ë¬¸ ë³´ê¸°"):
                            st.text(context)
                            
                    except Exception as e:
                        st.error(f"ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.warning("âš ï¸ Tab 3(í†µí•© ìœ„í—˜ ë¶„ì„)ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ìœ„í—˜ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")