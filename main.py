import os
import re
import pandas as pd
import streamlit as st
import altair as alt  

# ------------------------------------------------------------------
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •
# ------------------------------------------------------------------
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# core ëª¨ë“ˆ ì„¤ì •
from core.config import PERSIST_DIRECTORY
from core.llm import get_llm, get_embeddings
from core.decision_ai import decision_ai

# ------------------------------------------------------------------
# ê¸°ë³¸ í˜ì´ì§€ ì„¤ì •
# ------------------------------------------------------------------
st.set_page_config(
    page_title="ì‚¬ìš©ì ì½˜ì†”",
    layout="wide"
)

st.title("ğŸ›¡ï¸ ì² ë„ì•ˆì „ AI í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ")

# ------------------------------------------------------------------
# í•¨ìˆ˜ ì •ì˜
# ------------------------------------------------------------------
def get_vectorstore():
    # 1. DB í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(PERSIST_DIRECTORY):
        return None
    
    try:
        # 2. ChromaDB ë¡œë“œ
        # ì£¼ì˜: collection_name="regulations" ë¶€ë¶„ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.
        # admin.pyì—ì„œ ì €ì¥í•œ ê¸°ë³¸ ì„¤ì •ê³¼ ë§ì¶”ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
        vectorstore = Chroma(
            persist_directory=PERSIST_DIRECTORY,
            embedding_function=get_embeddings()
        )
        return vectorstore
    except Exception as e:
        st.error(f"ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def query_regulation(query, vectorstore, llm):
    """
    ì§ˆë¬¸ì— ëŒ€í•´ ë²¡í„° ì €ì¥ì†Œì—ì„œ ë¬¸ì„œë¥¼ ì°¾ê³  LLMì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # ê²€ìƒ‰ ë²”ìœ„ (k=6)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 6})
    
    docs = retriever.invoke(query)
    if not docs:
        return "í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê·œì • ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

    prompt_template = """
    ### [Role]
    ë‹¹ì‹ ì€ í•œêµ­ì˜ ì² ë„ ì•ˆì „ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì•„ë˜ [ê·œì • ë¬¸ë§¥]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹­ì‹œì˜¤.

    ### [Guidelines]
    1. **ë°˜ë“œì‹œ í•œêµ­ì–´(Korean)ë¡œë§Œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.** (Do not use English).
    2. ë‹µë³€ì€ [ê·œì • ë¬¸ë§¥]ì— ìˆëŠ” ë‚´ìš©ì—ë§Œ ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.
    3. ê·œì •ì— ì—†ëŠ” ë‚´ìš©ì„ ì§ˆë¬¸í•˜ë©´ "ê·œì •ì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
    4. ì¡°í•­ ë²ˆí˜¸(ì˜ˆ: ì œ3ì¡°)ë‚˜ ìˆ˜ì¹˜(ì˜ˆ: 10m, 30%)ëŠ” ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”.
    5. ë‹µë³€ í†¤ì€ ì „ë¬¸ì ì´ê³  ëª…í™•í•˜ë©° ì¹œì ˆí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

    [ê·œì • ë¬¸ë§¥]:
    {context}

    ì§ˆë¬¸: {question}
    
    ë‹µë³€:
    """
    PROMPT = PromptTemplate(
        template=prompt_template, 
        input_variables=["context", "question"]
    )

    chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": PROMPT},
        return_source_documents=True
    )
    
    result = chain.invoke({"query": query})
    return result["result"], result["source_documents"]

# ------------------------------------------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ------------------------------------------------------------------
if "llm" not in st.session_state:
    st.session_state["llm"] = get_llm("korean-llama3")

if "vectorstore" not in st.session_state:
    st.session_state["vectorstore"] = get_vectorstore()

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (messages ë¦¬ìŠ¤íŠ¸ì— sources ì •ë³´ë„ í•¨ê»˜ ì €ì¥)
if "messages" not in st.session_state:
    st.session_state["messages"] = []

llm = st.session_state["llm"]
vectorstore = st.session_state["vectorstore"]

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SHARED_DIR = os.path.join(BASE_DIR, "shared")
FILE_PATH = os.path.join(SHARED_DIR, "risk_df.pkl")

# ------------------------------------------------------------------
# ì‚¬ì´ë“œë°”
# ------------------------------------------------------------------
# with st.sidebar:
#     st.header("ğŸ”Œ ì‹œìŠ¤í…œ ìƒíƒœ")
#     if vectorstore is not None:
#         try:
#             count = vectorstore._collection.count()
#             st.success(f"ê·œì • DB ì—°ê²°ë¨ (ë¬¸ì„œ ì²­í¬: {count}ê°œ)")
#         except:
#             st.warning("ê·œì • DB ì—°ê²° ë¶ˆì•ˆì •")
#     else:
#         st.error("ê·œì • DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
#     if st.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
#         st.session_state["messages"] = []
#         st.rerun()

# ======================================
# íƒ­ êµ¬ì„±
# ======================================
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ’¬ ê·œì • ì±—ë´‡",
    "ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ",
    "ğŸ§  í†µí•© ìœ„í—˜ ë¶„ì„",
    "ğŸš¨ ìœ„í—˜ íŒë‹¨ & ì¡°ì¹˜ ì¶”ì²œ"
])

# ======================================
# TAB 1. ğŸ’¬ ê·œì • ì±—ë´‡ (ë©€í‹°í„´ + ê³ ê¸‰ ê²€ìƒ‰ ì ìš©)
# ======================================
with tab1:
    st.subheader("ğŸ’¬ ê·œì • ì „ë¬¸ ì±—ë´‡")
    st.caption("ğŸ’¡ íŒ: 'ì´ì „ ì§ˆë¬¸ì— ì´ì–´ì„œ...'ë¼ê³  ë¬¼ì–´ë³´ì‹œë©´ ë¬¸ë§¥ì„ ì´í•´í•©ë‹ˆë‹¤.")
    
    # [1] ìƒë‹¨ ê³ ì • ì…ë ¥ì°½
    with st.form(key="chat_form", clear_on_submit=True):
        col1, col2 = st.columns([8, 1])
        with col1:
            user_input = st.text_input(
                "ì§ˆë¬¸ ì…ë ¥", 
                placeholder="ì˜ˆ: ìœ„í—˜ë„í‰ê°€ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë¼?", 
                label_visibility="collapsed"
            )
        with col2:
            submit_btn = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°", use_container_width=True)

    # [2] ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
    if submit_btn and user_input:
        if vectorstore is None:
            st.error("âš ï¸ ê·œì • ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            with st.spinner("ê·œì • ì •ë°€ ë¶„ì„ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                
                # --- [ADD 0] ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ… (ë©€í‹°í„´ í•µì‹¬) ---
                # ìµœê·¼ 6ê°œ(ì§ˆë¬¸3+ë‹µë³€3) ëŒ€í™”ë§Œ ê°€ì ¸ì™€ì„œ í”„ë¡¬í”„íŠ¸ì— ë„£ìŒ (í† í° ì ˆì•½)
                history_text = ""
                if "messages" in st.session_state and st.session_state.messages:
                    recent_msgs = st.session_state.messages[-6:] 
                    history_text = "[ì´ì „ ëŒ€í™” ë‚´ì—­]\n"
                    for msg in recent_msgs:
                        role_label = "User" if msg["role"] == "user" else "Assistant"
                        # ì´ì „ ë‹µë³€ì˜ ê¸´ ë‚´ìš©ì€ ìš”ì•½í•˜ê±°ë‚˜ ì „ì²´ë¥¼ ë„£ë˜, ì†ŒìŠ¤ ì •ë³´ëŠ” ì œì™¸í•˜ê³  í…ìŠ¤íŠ¸ë§Œ ì „ë‹¬
                        content_preview = msg["content"]
                        history_text += f"- {role_label}: {content_preview}\n"
                    history_text += "\n"

                # --- 1. ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ë¡œì§ (ê¸°ì¡´ ìœ ì§€) ---
                search_kwargs = {"k": 6} 
                status_msg = "ğŸ” ì „ì²´ ê·œì • ë¬¸ì„œì—ì„œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                
                try:
                    all_data = vectorstore.get() 
                    unique_sources = list(set([m['source'] for m in all_data['metadatas'] if m]))
                except:
                    unique_sources = []

                target_source_name = None
                for source in unique_sources:
                    base_name = os.path.basename(source)
                    clean_name = os.path.splitext(base_name)[0]
                    keywords = re.split(r'[_\s\.\-\(\)\[\]]+', clean_name)
                    
                    for kw in keywords:
                        if len(kw) >= 2 and kw in user_input:
                            search_kwargs["filter"] = {"source": source}
                            target_source_name = base_name
                            break
                    if target_source_name: break

                if target_source_name:
                    status_msg = f"ğŸ¯ **'{target_source_name}'** ë¬¸ì„œ ë‚´ì—ì„œ ì§‘ì¤‘ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                
                # --- 2. ê²€ìƒ‰ ìˆ˜í–‰ (MMR ë°©ì‹ - ê¸°ì¡´ ìœ ì§€) ---
                retriever = vectorstore.as_retriever(
                    search_type="mmr", 
                    search_kwargs={**search_kwargs, "fetch_k": 20, "lambda_mult": 0.7} 
                )
                
                retrieved_docs = retriever.invoke(user_input)
                
                # --- 3. ë¬¸ì„œ ì •ì œ (ê¸°ì¡´ ìœ ì§€) ---
                final_docs = []
                seen_content = set()
                for d in retrieved_docs:
                    if d.page_content not in seen_content:
                        if "|||" in d.page_content or len(d.page_content.strip()) < 10:
                            continue
                        final_docs.append(d)
                        seen_content.add(d.page_content)
                
                context_text = "\n\n".join([d.page_content for d in final_docs])

                # --- 4. í”„ë¡¬í”„íŠ¸ ë° LLM í˜¸ì¶œ (ë©€í‹°í„´ ì ìš©) ---
                if not context_text:
                    response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ê·œì • ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ)"
                    final_docs = [] 
                else:
                    # [Modify] í”„ë¡¬í”„íŠ¸ì— history_text ì¶”ê°€
                    prompt_template = f"""
                    [System Instruction]
                    ë‹¹ì‹ ì€ ì‚¬ë‚´ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                    - [History]ëŠ” ì´ì „ ëŒ€í™”ì˜ ë§¥ë½ì…ë‹ˆë‹¤.
                    - [Context]ëŠ” í˜„ì¬ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê·œì • ì›ë¬¸ì…ë‹ˆë‹¤.
                    
                    **ë‹µë³€ ì‘ì„± ì›ì¹™**:
                    1. **ê·¼ê±° ì¤‘ì‹¬**: ìƒìƒí•˜ì§€ ë§ê³  ë°˜ë“œì‹œ [Context]ì— ìˆëŠ” ë‚´ìš©ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. 
                    2. **ë§¥ë½ ìœ ì§€**: [History]ë¥¼ ì°¸ê³ í•˜ì—¬ ëŒ€ëª…ì‚¬('ê·¸ê²ƒ', 'ì•ì˜ ë‚´ìš©')ê°€ ë¬´ì—‡ì„ ì§€ì¹­í•˜ëŠ”ì§€ íŒŒì•…í•˜ì„¸ìš”.
                    3. **í‘œ/ìˆ˜ì¹˜ ìœ ì§€**: ë“±ê¸‰í‘œ, ì§€ê¸‰ìœ¨ ë“±ì€ ë§ˆí¬ë‹¤ìš´ í‘œ(Table)ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.
                    4. **ì¡°í•­ ëª…ì‹œ**: ê°€ëŠ¥í•˜ë‹¤ë©´ "ì œOOì¡°ì— ë”°ë¥´ë©´..." í˜•íƒœë¡œ ì¶œì²˜ë¥¼ ë°íˆì„¸ìš”.
                    5. **ì–¸ì–´**: í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

                    {history_text}

                    [Context]:
                    {context_text}

                    [Current Question]:
                    {user_input}

                    [Answer]:
                    """
                    try:
                        # invoke ëŒ€ì‹ , LLM ëª¨ë¸ ì¢…ë¥˜ì— ë”°ë¼ ì•ˆì „í•˜ê²Œ í˜¸ì¶œ
                        from langchain.schema import HumanMessage
                        if hasattr(llm, 'invoke'):
                             response = llm.invoke([HumanMessage(content=prompt_template)])
                             response_text = response.content
                        else:
                             response_text = llm.predict(prompt_template)
                    except Exception as e:
                        response_text = f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

                # --- 5. UI ì—…ë°ì´íŠ¸ (ê¸°ì¡´ ìœ ì§€) ---
                st.session_state.messages.append({"role": "user", "content": user_input})
                
                formatted_sources = []
                seen_titles = set()
                
                for doc in final_docs:
                    src_file = os.path.basename(doc.metadata.get("source", "íŒŒì¼"))
                    raw_title = doc.metadata.get("Article_Title", "ë³¸ë¬¸")
                    match = re.match(r"(ì œ\s*\d+\s*ì¡°(?:ì˜\d+)?(?:\([^)]*\))?)", raw_title)
                    clean_title = match.group(1) if match else raw_title[:30]
                    
                    key = (src_file, clean_title)
                    if key not in seen_titles:
                        formatted_sources.append({
                            "source": src_file,
                            "title": clean_title,
                            "content": doc.page_content
                        })
                        seen_titles.add(key)

                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response_text,
                    "sources": formatted_sources,
                    "status": status_msg
                })
                
    # [3] ëŒ€í™” ë‚´ìš© ì¶œë ¥ (ê¸°ì¡´ ìœ ì§€)
    st.divider()
    
    conversations = []
    current_group = []

    for msg in st.session_state.messages:
        if msg["role"] == "user":
            if current_group:
                conversations.append(current_group)
            current_group = [msg]
        else:
            current_group.append(msg)
    if current_group:
        conversations.append(current_group)

    if conversations:
        for group in reversed(conversations):
            with st.container():
                for msg in group:
                    with st.chat_message(msg["role"]):
                        st.write(msg["content"])
                        if msg["role"] == "assistant":
                            if msg.get("status"):
                                st.caption(msg["status"])
                            if msg.get("sources"):
                                with st.expander("ğŸ“š ê´€ë ¨ ê·¼ê±° ê·œì • í™•ì¸"):
                                    for i, src in enumerate(msg["sources"]):
                                        st.markdown(f"**[{i+1}] {src['source']} - {src['title']}**")
                                        display_content = src['content'].replace("|", " ").replace("\n", " ")[:200]
                                        st.caption(f"{display_content}...")
                st.divider()

# ======================================
# TAB 2. ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ (Professional Ver.)
# ======================================
with tab2:
    # 1. í—¤ë” & ì»¨íŠ¸ë¡¤ íŒ¨ë„
    col_header, col_filter = st.columns([3, 1])
    
    with col_header:
        st.subheader("ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ")
        st.caption("ë°ì´í„° ê¸°ë°˜ ì‚¬ê³  ì›ì¸ ë° ì¶”ì„¸ ì‹¬ì¸µ ë¶„ì„")
        
    with col_filter:
        line_options = ["ì „ì²´", "1í˜¸ì„ ", "2í˜¸ì„ ", "7í˜¸ì„ "]
        selected_line = st.selectbox("ğŸ” í˜¸ì„  í•„í„°", line_options)

    st.markdown("---")

    if os.path.exists(FILE_PATH):
        try:
            df = pd.read_pickle(FILE_PATH)
            
            # -----------------------------------------------------------
            # [1] ë°ì´í„° ì „ì²˜ë¦¬
            # -----------------------------------------------------------
            col_map = {
                "line": "í˜¸ì„ ",
                "date": "ë°œìƒì¼ì",
                "cause": "ë¶€ì›ì¸",
                "place": "ë°œìƒì¥ì†Œ",
                "r_type": "ê·€ì±…êµ¬ë¶„",
                "age": "ì—°ë ¹ëŒ€"
            }
            
            for key, actual_col in col_map.items():
                if actual_col not in df.columns:
                    df[actual_col] = "ì •ë³´ì—†ìŒ" if key != "date" else "2024-01-01"

            # í˜¸ì„  ì •ì œ í•¨ìˆ˜
            def clean_line_name(val):
                val_str = str(val)
                if "1í˜¸ì„ " in val_str: return "1í˜¸ì„ "
                if "2í˜¸ì„ " in val_str: return "2í˜¸ì„ "
                if "7í˜¸ì„ " in val_str: return "7í˜¸ì„ "
                return "ê¸°íƒ€"
            
            # ê´„í˜¸ ë° ìˆ«ì ì œê±° í•¨ìˆ˜ ([2]ìŒì£¼ -> ìŒì£¼)
            def clean_label_text(val):
                val_str = str(val)
                # ëŒ€ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ìˆ«ì/ë¬¸ì ì œê±° í›„ ì•ë’¤ ê³µë°± ì œê±°
                return re.sub(r'\[.*?\]', '', val_str).strip()

            df["í˜¸ì„ _ì •ì œ"] = df[col_map["line"]].apply(clean_line_name)
            df[col_map["date"]] = pd.to_datetime(df[col_map["date"]], errors='coerce')
            df["ì›”"] = df[col_map["date"]].dt.strftime('%Y-%m')

            # ë¶„ì„ìš© ì»¬ëŸ¼ë“¤ì— ëŒ€í•´ ë¼ë²¨ í´ë¦¬ë‹ ë¯¸ë¦¬ ì ìš© (ê°€ë…ì„± í–¥ìƒ)
            target_cols_clean = [col_map["cause"], col_map["place"], col_map["r_type"], col_map["age"]]
            for col in target_cols_clean:
                df[col] = df[col].apply(clean_label_text)

            # -----------------------------------------------------------
            # [2] ë°ì´í„° í•„í„°ë§
            # -----------------------------------------------------------
            target_lines = ["1í˜¸ì„ ", "2í˜¸ì„ ", "7í˜¸ì„ "]
            
            if selected_line == "ì „ì²´":
                filtered_df = df[df["í˜¸ì„ _ì •ì œ"].isin(target_lines)]
                if filtered_df.empty: filtered_df = df 
            else:
                filtered_df = df[df["í˜¸ì„ _ì •ì œ"] == selected_line]

            # -----------------------------------------------------------
            # [3] ëŒ€ì‹œë³´ë“œ ì‹œê°í™”
            # -----------------------------------------------------------
            if not filtered_df.empty:
                
                # [KPI Section] í•µì‹¬ ìš”ì•½
                kpi1, kpi2, kpi3, kpi4 = st.columns(4)
                
                total_cnt = len(filtered_df)
                kpi1.metric("ì´ ë°œìƒ ê±´ìˆ˜", f"{total_cnt}ê±´")
                
                top_cause = filtered_df[col_map["cause"]].mode()[0] if not filtered_df[col_map["cause"]].empty else "-"
                cause_cnt = filtered_df[col_map["cause"]].value_counts().iloc[0] if not filtered_df[col_map["cause"]].empty else 0
                kpi2.metric("ìµœë‹¤ ë¹ˆë„ ì›ì¸", top_cause, f"{cause_cnt}ê±´")
                
                top_place = filtered_df[col_map["place"]].mode()[0] if not filtered_df[col_map["place"]].empty else "-"
                kpi3.metric("ì£¼ìš” ë°œìƒ ì¥ì†Œ", top_place)

                top_resp = filtered_df[col_map["r_type"]].mode()[0] if not filtered_df[col_map["r_type"]].empty else "-"
                kpi4.metric("ì£¼ìš” ê·€ì±… ì‚¬ìœ ", top_resp)

                st.markdown("###")

                # [Chart Row 1] ì‹œê³„ì—´ ë¶„ì„ (ê¸°ì¡´ ìœ ì§€)
                st.markdown("##### ğŸ“… ì›”ë³„ ì‚¬ê³  ë°œìƒ ì¶”ì´ ë° ì›ì¸ êµ¬ì„±")
                time_chart_data = filtered_df.groupby(["ì›”", col_map["cause"]]).size().reset_index(name='ê±´ìˆ˜')
                
                time_chart = alt.Chart(time_chart_data).mark_bar().encode(
                    x=alt.X('ì›”', title='ê¸°ê°„'),
                    y=alt.Y('ê±´ìˆ˜', title='ë°œìƒ ê±´ìˆ˜'),
                    color=alt.Color(col_map["cause"], title='ë¶€ì›ì¸'),
                    tooltip=['ì›”', col_map["cause"], 'ê±´ìˆ˜']
                ).properties(height=300) # ë†’ì´ ì•½ê°„ ì¡°ì •
                
                st.altair_chart(time_chart, use_container_width=True)

                st.divider()

                # [Chart Row 2] ìƒì„¸ í†µê³„ ë¶„ì„ (1x4 êµ¬ì¡°ë¡œ ë³€ê²½ + ì½”ë©˜íŠ¸)
                st.markdown("##### ğŸ“Š ìƒì„¸ í†µê³„ ë° ì¸ì‚¬ì´íŠ¸ ë¶„ì„")

                # --- [í•¨ìˆ˜] ì°¨íŠ¸, í…Œì´ë¸”, ì½”ë©˜íŠ¸ ìƒì„± ---
                def create_analysis_component(data, col_name, title):
                    # 1. ë°ì´í„° ì§‘ê³„
                    counts = data[col_name].value_counts().reset_index()
                    counts.columns = ["í•­ëª©", "ê±´ìˆ˜"]
                    
                    # 2. ë¹„ìœ¨ ê³„ì‚°
                    total = counts["ê±´ìˆ˜"].sum()
                    if total > 0:
                        counts["ë¹„ìœ¨"] = ((counts["ê±´ìˆ˜"] / total) * 100).round(1) # ì†Œìˆ˜ì  1ìë¦¬
                    else:
                        counts["ë¹„ìœ¨"] = 0
                    
                    # 3. Altair ë„ë„› ì°¨íŠ¸
                    base = alt.Chart(counts).encode(theta=alt.Theta("ê±´ìˆ˜", stack=True))
                    
                    pie = base.mark_arc(innerRadius=50, outerRadius=90).encode(
                        color=alt.Color("í•­ëª©", legend=alt.Legend(orient="right", title=None)), 
                        order=alt.Order("ê±´ìˆ˜", sort="descending"),
                        tooltip=["í•­ëª©", "ê±´ìˆ˜", alt.Tooltip("ë¹„ìœ¨", format=".1f")]
                    )
                    
                    # [ìˆ˜ì •] .filter() -> .transform_filter() ë¡œ ë³€ê²½
                    text = base.mark_text(radius=110).encode(
                        text=alt.Text("ë¹„ìœ¨", format=".0f"), 
                        order=alt.Order("ê±´ìˆ˜", sort="descending"),
                        color=alt.value("black")
                    ).transform_filter(
                        alt.datum.ë¹„ìœ¨ > 4  # ë¹„ìœ¨ì´ 4% ì´ˆê³¼ì¸ ê²ƒë§Œ í…ìŠ¤íŠ¸ í‘œì‹œ
                    )

                    chart = (pie + text).properties(height=250)

                    # 4. í…Œì´ë¸” ë°ì´í„° ì •ë¦¬
                    table_df = counts[["í•­ëª©", "ê±´ìˆ˜", "ë¹„ìœ¨"]].copy()
                    table_df.columns = ["í•­ëª©", "ê±´ìˆ˜", "ë¹„ìœ¨(%)"]
                    
                    # 5. ìë™ ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
                    if not counts.empty:
                        top1 = counts.iloc[0]
                        insight_text = f"""
                        - **ìµœë‹¤ ë¹ˆë„:** <span style='color:red'>**{top1['í•­ëª©']}**</span> ({top1['ê±´ìˆ˜']}ê±´, {top1['ë¹„ìœ¨']}%)
                        """
                        
                        if len(counts) > 1:
                            top2 = counts.iloc[1]
                            diff = top1['ê±´ìˆ˜'] - top2['ê±´ìˆ˜']
                            insight_text += f"""
                            - **2ìœ„ í•­ëª©:** {top2['í•­ëª©']} ({top2['ë¹„ìœ¨']}%)
                            - **ë¶„ì„:** 1ìœ„ í•­ëª©ì´ 2ìœ„ ëŒ€ë¹„ **{diff}ê±´** ë” ë§ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
                            ì§‘ì¤‘ì ì¸ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
                            """
                    else:
                        insight_text = "ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

                    return chart, table_df, insight_text

                # --- [ë©”ì¸ ë¡œì§] 1 Row per Metric (1x4 Stack) ---
                metrics = [
                    ("cause", "1. ë¶€ì›ì¸ ë¶„ì„"),
                    ("place", "2. ë°œìƒì¥ì†Œ ë¶„ì„"),
                    ("r_type", "3. ê·€ì±…êµ¬ë¶„ ë¶„ì„"),
                    ("age", "4. ì—°ë ¹ëŒ€ë³„ ë¶„ì„")
                ]

                for col_key, title in metrics:
                    st.markdown(f"**ğŸ“Œ {title}**")
                    
                    # ë ˆì´ì•„ì›ƒ ë¹„ìœ¨ [ì°¨íŠ¸(2) : í…Œì´ë¸”(1.5) : ì½”ë©˜íŠ¸(1.5)]
                    c1, c2, c3 = st.columns([2, 1.5, 1.5])
                    
                    chart, df_table, insight = create_analysis_component(filtered_df, col_map[col_key], title)
                    
                    with c1:
                        st.altair_chart(chart, use_container_width=True)
                    
                    with c2:
                        st.dataframe(
                            df_table, 
                            hide_index=True, 
                            use_container_width=True,
                            height=200
                        )
                    
                    with c3:
                        st.info("ğŸ’¡ **AI Insight**")
                        st.markdown(insight, unsafe_allow_html=True)
                    
                    st.divider() # í•­ëª© ê°„ êµ¬ë¶„ì„ 

                # [List Section] ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ê¸°ì¡´ ìœ ì§€)
                st.markdown(f"##### ğŸ“‹ {selected_line} Raw Data (ìƒìœ„ 100ê±´)")
                st.dataframe(
                    filtered_df.head(100), 
                    use_container_width=True, 
                    height=250, 
                    hide_index=True
                )
            
            else:
                st.warning(f"ì„ íƒí•˜ì‹  '{selected_line}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ë””ë²„ê¹…ìš© traceback ì¶œë ¥ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
            # import traceback
            # st.text(traceback.format_exc())
    else:
        st.info("ì•„ì§ ìƒí™©ë³´ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# ======================================
# TAB 3. ğŸ›¡ï¸ í†µí•© ìœ„í—˜ ë¶„ì„ (Integrated Risk Analysis) - Ver 1.2
# ======================================
with tab3:
    st.subheader("ğŸ›¡ï¸ í†µí•© ìœ„í—˜ë„ í‰ê°€ (Risk Assessment)")
    
    # -------------------------------------------------------
    # [Data Load & Preprocessing]
    # -------------------------------------------------------
    if os.path.exists(FILE_PATH):
        df_risk = pd.read_pickle(FILE_PATH)
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        col_map = {"cause": "ë¶€ì›ì¸"}
        if "ë¶€ì›ì¸" not in df_risk.columns:
            df_risk["ë¶€ì›ì¸"] = df_risk["cause"] if "cause" in df_risk.columns else "ì •ë³´ì—†ìŒ"
        
        # ë¼ë²¨ í´ë¦¬ë‹
        df_risk["ë¶€ì›ì¸"] = df_risk["ë¶€ì›ì¸"].apply(lambda x: re.sub(r'\[.*?\]', '', str(x)).strip())

        # -------------------------------------------------------
        # [Step 1] ì‹¬ê°ë„(Severity) ë°ì´í„° ì¤€ë¹„ (ì„¤ì • UIëŠ” í•˜ë‹¨/ìˆ¨ê¹€ ì²˜ë¦¬)
        # -------------------------------------------------------
        unique_causes = df_risk["ë¶€ì›ì¸"].unique()

        # ê¸°ë³¸ ì‹¬ê°ë„ ë§¤í•‘ í•¨ìˆ˜
        def get_default_severity(cause):
            cause = str(cause)
            if any(x in cause for x in ['ì‚¬ë§', 'íƒˆì„ ', 'ì¶©ëŒ', 'í™”ì¬', 'í­ë°œ', 'ìì‚´']): return 5
            if any(x in cause for x in ['ì¶”ë½', 'ê°ì „', 'ë¼ì„', 'í˜‘ì°©', 'ì ˆë‹¨']): return 4
            if any(x in cause for x in ['ê³¨ì ˆ', 'ë² ì„', 'í™”ìƒ', 'ëˆ„ìˆ˜']): return 3
            if any(x in cause for x in ['ë„˜ì–´ì§', 'ì „ë„', 'ë¶€ë”ªí˜', 'ìŒì£¼', 'ë¶€ì£¼ì˜']): return 2
            return 1

        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        severity_data = []
        for c in unique_causes:
            severity_data.append({"ì‚¬ê³ ìœ í˜•": c, "ì‹¬ê°ë„(1-5)": get_default_severity(c)})
        
        df_severity_default = pd.DataFrame(severity_data).sort_values(by="ì‹¬ê°ë„(1-5)", ascending=False)

        # -------------------------------------------------------
        # [Step 1-1] ì„¤ì •ì°½: ì‹œê°ì  ê°„ì†Œí™”ë¥¼ ìœ„í•´ Expander ì‚¬ìš©
        # -------------------------------------------------------
        # ì±—ë´‡ì˜ í•µì‹¬(ë¶„ì„ ê²°ê³¼)ì„ ë¨¼ì € ë³´ì—¬ì£¼ê¸° ìœ„í•´ ì„¤ì •ì„ ì ‘ì–´ë‘ 
        with st.expander("âš™ï¸ [ì„¤ì •] ì‚¬ê³  ìœ í˜•ë³„ ì‹¬ê°ë„ ê¸°ì¤€ ë³€ê²½í•˜ê¸° (í´ë¦­)", expanded=False):
            st.caption("ì•„ë˜ í‘œì—ì„œ ì‚¬ê³  ìœ í˜•ë³„ ì‹¬ê°ë„(1~5)ë¥¼ ìˆ˜ì •í•˜ë©´ ë§¤íŠ¸ë¦­ìŠ¤ì— ì¦‰ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.")
            edited_severity_df = st.data_editor(
                df_severity_default,
                column_config={
                    "ì‹¬ê°ë„(1-5)": st.column_config.NumberColumn(
                        "ì‹¬ê°ë„", help="1:ê²½ë¯¸ ~ 5:ì¹˜ëª…", min_value=1, max_value=5, step=1
                    )
                },
                use_container_width=True,
                hide_index=True,
                key="severity_editor" # í‚¤ë¥¼ ì§€ì •í•˜ì—¬ ìƒíƒœ ìœ ì§€
            )

        # -------------------------------------------------------
        # [Step 2] ìœ„í—˜ë„(Risk) ê³„ì‚° ë¡œì§
        # -------------------------------------------------------
        # 1. ë¹ˆë„(Frequency) ì§‘ê³„
        df_freq = df_risk["ë¶€ì›ì¸"].value_counts().reset_index()
        df_freq.columns = ["ì‚¬ê³ ìœ í˜•", "ë°œìƒê±´ìˆ˜"]

        # 2. ì‹¬ê°ë„(Severity) ë³‘í•© (í¸ì§‘ëœ ë°ì´í„° ì‚¬ìš©)
        df_calc = pd.merge(df_freq, edited_severity_df, on="ì‚¬ê³ ìœ í˜•", how="left")

        # 3. ë¹ˆë„ ë“±ê¸‰(Freq Level) ìë™ ì‚°ì¶œ (1~5ë“±ê¸‰)
        max_count = df_calc["ë°œìƒê±´ìˆ˜"].max()
        def get_freq_level(cnt, max_val):
            if max_val == 0: return 1
            ratio = cnt / max_val
            if ratio >= 0.8: return 5
            elif ratio >= 0.6: return 4
            elif ratio >= 0.4: return 3
            elif ratio >= 0.2: return 2
            else: return 1

        df_calc["ë¹ˆë„ë“±ê¸‰(1-5)"] = df_calc["ë°œìƒê±´ìˆ˜"].apply(lambda x: get_freq_level(x, max_count))
        df_calc["ìœ„í—˜ì ìˆ˜"] = df_calc["ë¹ˆë„ë“±ê¸‰(1-5)"] * df_calc["ì‹¬ê°ë„(1-5)"]

        # 4. Risk Zone íŒì •
        def get_risk_zone(score):
            if score >= 15: return "ğŸ”´ High"
            elif score >= 8: return "ğŸŸ¡ Medium"
            else: return "ğŸŸ¢ Low"

        df_calc["ìœ„í—˜ë“±ê¸‰"] = df_calc["ìœ„í—˜ì ìˆ˜"].apply(get_risk_zone)

        # Tab 4 ì—°ë™ì„ ìœ„í•œ ì„¸ì…˜ ì €ì¥
        top_risks = df_calc.sort_values(by=["ìœ„í—˜ì ìˆ˜", "ë°œìƒê±´ìˆ˜"], ascending=[False, False])
        st.session_state['priority_risks'] = top_risks

        st.divider()

        # -------------------------------------------------------
        # [Step 3] 5x5 Risk Matrix ì‹œê°í™” (ê°œì„ ëœ ë²„ì „)
        # -------------------------------------------------------
        c_left, c_right = st.columns([1.6, 1])

        with c_left:
            st.markdown("##### ğŸ“Š ìœ„í—˜ì„± í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤ (Risk Matrix)")
            
            # 1. ê·¸ë¦¬ë“œ ë°ì´í„° ìƒì„±
            grid_data = []
            for s in range(1, 6): 
                for f in range(1, 6):
                    score = s * f
                    if score >= 15: 
                        risk_grade, color, text_color = "High", "#FF4B4B", "white"
                    elif score >= 8: 
                        risk_grade, color, text_color = "Medium", "#FFAA00", "black"
                    else: 
                        risk_grade, color, text_color = "Low", "#00CC96", "black"
                    
                    grid_data.append({
                        "ì‹¬ê°ë„_X": s, "ë¹ˆë„ë“±ê¸‰_Y": f,
                        "ìœ„í—˜ì ìˆ˜": score,
                        "ë¼ë²¨": f"{risk_grade}\n{score}", # ì¤„ë°”ê¿ˆ ì ìš©
                        "ë°°ê²½ìƒ‰": color,
                        "ê¸€ììƒ‰": text_color
                    })
            df_grid_base = pd.DataFrame(grid_data)

            # 2. ë°ì´í„° ì§‘ê³„
            df_agg = df_calc.groupby(["ì‹¬ê°ë„(1-5)", "ë¹ˆë„ë“±ê¸‰(1-5)"]).agg(
                ì´ê±´ìˆ˜=("ë°œìƒê±´ìˆ˜", "sum"),
                ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸=("ì‚¬ê³ ìœ í˜•", lambda x: ", ".join(x.unique()))
            ).reset_index()
            
            # 3. ë³‘í•©
            df_matrix_final = pd.merge(
                df_grid_base, df_agg, 
                left_on=["ì‹¬ê°ë„_X", "ë¹ˆë„ë“±ê¸‰_Y"], 
                right_on=["ì‹¬ê°ë„(1-5)", "ë¹ˆë„ë“±ê¸‰(1-5)"], 
                how="left"
            ).fillna({"ì´ê±´ìˆ˜": 0, "ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸": "-"})

            # 4. Altair ì°¨íŠ¸ (í°íŠ¸ í¬ê¸° ë° ë°°ì¹˜ ìˆ˜ì •)
            base = alt.Chart(df_matrix_final).encode(
                x=alt.X("ì‹¬ê°ë„_X:O", title="ì¤‘ëŒ€ì„± (Severity) â¡ï¸", axis=alt.Axis(labelAngle=0)),
                y=alt.Y("ë¹ˆë„ë“±ê¸‰_Y:O", title="ê°€ëŠ¥ì„± (Frequency) â¬†ï¸", sort="descending")
            ).properties(height=450) # ë†’ì´ í™•ë³´

            # Layer 1: ë°°ê²½ íˆíŠ¸ë§µ
            heatmap = base.mark_rect().encode(
                color=alt.Color("ë°°ê²½ìƒ‰:N", scale=None),
                tooltip=["ì‹¬ê°ë„_X", "ë¹ˆë„ë“±ê¸‰_Y", "ë¼ë²¨", "ì´ê±´ìˆ˜", "ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸"]
            )

            # Layer 2: ìœ„í—˜ ì ìˆ˜/ë“±ê¸‰ í…ìŠ¤íŠ¸ (í°íŠ¸ í¬ê²Œ!)
            text_score = base.mark_text(baseline="middle").encode(
                text=alt.Text("ë¼ë²¨"),
                color=alt.Color("ê¸€ììƒ‰:N", scale=None),
                size=alt.value(15),  # [ìˆ˜ì •] í°íŠ¸ í¬ê¸° ëŒ€í­ í™•ëŒ€ (24px)
                opacity=alt.value(0.6) # ë°°ê²½ ê¸€ì”¨ì²˜ëŸ¼ ì€ì€í•˜ê²Œ
            )

            # Layer 3: ì‹¤ì œ ë°œìƒ ê±´ìˆ˜ (ê°•ì¡°)
            text_count = base.transform_filter(
                alt.datum.ì´ê±´ìˆ˜ > 0
            ).mark_text(dy=25, fontWeight="bold").encode( # dy: ìœ„ì¹˜ë¥¼ ì•„ë˜ë¡œ
                text=alt.Text("ì´ê±´ìˆ˜", format="d"), # ìˆ«ìë§Œ í‘œì‹œ
                color=alt.value("blue"),
                size=alt.value(16)   # [ìˆ˜ì •] ê±´ìˆ˜ í°íŠ¸ í¬ê¸° í™•ëŒ€ (16px)
            )

            final_chart = (heatmap + text_score + text_count).configure_axis(
                labelFontSize=12,
                titleFontSize=14
            )
            
            st.altair_chart(final_chart, use_container_width=True)

        with c_right:
            st.markdown("##### ğŸš¨ ìœ„í—˜ ìš°ì„ ìˆœìœ„ (Top Risks)")
            
            # ìµœìš°ì„  ìœ„í—˜ í•­ëª© ì¹´ë“œë·°
            if not top_risks.empty:
                worst = top_risks.iloc[0]
                st.error(f"**1ìœ„: {worst['ì‚¬ê³ ìœ í˜•']}**")
                
                col_kpi1, col_kpi2 = st.columns(2)
                col_kpi1.metric("ìœ„í—˜ ì ìˆ˜", f"{worst['ìœ„í—˜ì ìˆ˜']}ì ", help="ì‹¬ê°ë„ x ë¹ˆë„")
                col_kpi2.metric("ë°œìƒ ê±´ìˆ˜", f"{worst['ë°œìƒê±´ìˆ˜']}ê±´")
                
                st.progress(min(worst['ìœ„í—˜ì ìˆ˜']/25.0, 1.0), text="ìœ„í—˜ë„ ìˆ˜ì¤€")

            st.write("") # ì—¬ë°±
            
            # ë¦¬ìŠ¤íŠ¸ ë·°
            st.dataframe(
                top_risks[["ì‚¬ê³ ìœ í˜•", "ìœ„í—˜ë“±ê¸‰", "ìœ„í—˜ì ìˆ˜", "ë°œìƒê±´ìˆ˜"]],
                hide_index=True,
                use_container_width=True,
                height=300
            )

        # AI Insight
        st.info("ğŸ’¡ **AI ë¶„ì„:** ë¶‰ì€ìƒ‰(High) ì˜ì—­ì— ìœ„ì¹˜í•œ ì‚¬ê³  ìœ í˜•ì€ 'ì¦‰ì‹œ ê°œì„ 'ì´ í•„ìš”í•œ í•­ëª©ì…ë‹ˆë‹¤. ìš°ì¸¡ ë¦¬ìŠ¤íŠ¸ ìƒìœ„ í•­ëª©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì•ˆì „ ëŒ€ì±…ì„ ìˆ˜ë¦½í•˜ì„¸ìš”.")

    else:
        st.warning("ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# ======================================
# TAB 4. ğŸ¤– ìœ„í—˜ íŒë‹¨ ë° ì¡°ì¹˜ (AI Action Plan) - Ver 1.2 (Debug Mode)
# ======================================
from langchain.schema import HumanMessage, SystemMessage

with tab4:
    st.subheader("ğŸ¤– AI ìœ„í—˜ ëŒ€ì‘ ì†”ë£¨ì…˜")
    st.caption("ìœ„í—˜ì„± í‰ê°€ ê²°ê³¼(Tab 3)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ê·œ ë°ì´í„°(Tab 1)ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë§ì¶¤í˜• ì¡°ì¹˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.")

    # 1. Tab 3 ë¶„ì„ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
    if 'priority_risks' in st.session_state and not st.session_state['priority_risks'].empty:
        priority_df = st.session_state['priority_risks']
        risk_options = priority_df['ì‚¬ê³ ìœ í˜•'].tolist()

        c1, c2 = st.columns([1, 2])
        
        with c1:
            st.markdown("##### ğŸ” ë¶„ì„ ëŒ€ìƒ ì„ íƒ")
            selected_risk = st.selectbox("ì¡°ì¹˜ ë°©ì•ˆì„ í™•ì¸í•  ìœ„í—˜ ìš”ì¸:", risk_options)
            
            # ì„ íƒëœ í•­ëª© ì •ë³´
            target_row = priority_df[priority_df['ì‚¬ê³ ìœ í˜•'] == selected_risk].iloc[0]
            st.info(f"""
            **{selected_risk}**
            - ë“±ê¸‰: {target_row['ìœ„í—˜ë“±ê¸‰']}
            - ì ìˆ˜: {target_row['ìœ„í—˜ì ìˆ˜']} (ê±´ìˆ˜: {target_row['ë°œìƒê±´ìˆ˜']})
            """)
            
            generate_btn = st.button("ğŸ§¬ ì¡°ì¹˜ë°©ì•ˆ ìƒì„± (Real-time)", type="primary", use_container_width=True)

        with c2:
            st.markdown(f"##### ğŸ“‹ '{selected_risk}' ì•ˆì „ ì¡°ì¹˜ ê°€ì´ë“œ")
            
            if generate_btn:
                # [í•„ìˆ˜ ì²´í¬] ë²¡í„° DBì™€ LLM ë¡œë“œ ì—¬ë¶€ í™•ì¸
                if 'vectorstore' not in st.session_state:
                    st.error("âš ï¸ ë²¡í„° DBê°€ ì—†ìŠµë‹ˆë‹¤. Tab 1ì—ì„œ ë¬¸ì„œë¥¼ ë¨¼ì € ì„ë² ë”©í•´ì£¼ì„¸ìš”.")
                # elif 'llm' not in st.session_state: # (í˜¹ì‹œ llmì„ ì„¸ì…˜ì— ë„£ìœ¼ì…¨ë‹¤ë©´ ì²´í¬)
                #     st.error("âš ï¸ LLM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    with st.spinner(f"ê·œì • DB ê²€ìƒ‰ ë° ë¶„ì„ ì¤‘..."):
                        try:
                            # ---------------------------------------------------
                            # [1] ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” (ë‹¨ìˆœ í‚¤ì›Œë“œ -> ë¬¸ì¥í˜•)
                            # ---------------------------------------------------
                            # í‚¤ì›Œë“œê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê²€ìƒ‰ì´ ì˜ ì•ˆë˜ë¯€ë¡œ ê¼¬ë¦¬ë§ì„ ë¶™ì—¬ì¤ë‹ˆë‹¤.
                            search_query = f"{selected_risk} ì‚¬ê³  ì˜ˆë°© ì‘ì—… ì ˆì°¨ ì•ˆì „ ìˆ˜ì¹™ ê¸ˆì§€ ì‚¬í•­"
                            
                            # ---------------------------------------------------
                            # [2] ë²¡í„° DB ê²€ìƒ‰ (Retriever)
                            # ---------------------------------------------------
                            # k=4: ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì¡°ê° 4ê°œë¥¼ ê°€ì ¸ì˜´
                            retriever = st.session_state['vectorstore'].as_retriever(search_kwargs={"k": 4})
                            docs = retriever.get_relevant_documents(search_query)
                            
                            # ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© í•©ì¹˜ê¸°
                            context_text = "\n\n".join([doc.page_content for doc in docs])
                            
                            # ---------------------------------------------------
                            # [3] ë””ë²„ê¹…ìš©: ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ë¬´ì—‡ì¸ì§€ í™•ì¸ (ì¤‘ìš”!)
                            # ---------------------------------------------------
                            with st.expander("ğŸ” [ë””ë²„ê¹…] ë²¡í„° DBê°€ ì°¾ì•„ë‚¸ ì›ë¬¸ ë‚´ìš© ë³´ê¸°", expanded=False):
                                if not docs:
                                    st.warning("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ê°€ ë§¤ë‰´ì–¼ì— ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                for i, doc in enumerate(docs):
                                    st.text(f"[ë¬¸ì„œ {i+1}] Source: {doc.metadata.get('source', 'unknown')}")
                                    st.caption(doc.page_content[:300] + "...") # ì•ë¶€ë¶„ë§Œ ë¯¸ë¦¬ë³´ê¸°

                            # ---------------------------------------------------
                            # [4] LLM ìƒì„± ìš”ì²­ (ì‹¤ì œ ì—°ë™)
                            # ---------------------------------------------------
                            # ë¬¸ë§¥ì´ ë„ˆë¬´ ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ ë§í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì¡°ì •
                            if not context_text:
                                st.warning("ê´€ë ¨ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ì ì¸ ì•ˆì „ ì§€ì¹¨ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                                context_text = "ê´€ë ¨ ì‚¬ê·œ ì—†ìŒ. ì¼ë°˜ì ì¸ ì‚°ì—… ì•ˆì „ ê¸°ì¤€ì„ ì ìš©í•  ê²ƒ."

                            prompt = f"""
                            ë‹¹ì‹ ì€ ì² ë„/ì‚°ì—… ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                            ì•„ë˜ì˜ [ê²€ìƒ‰ëœ ì‚¬ê·œ/ë§¤ë‰´ì–¼]ë§Œì„ ê·¼ê±°ë¡œ í•˜ì—¬, 
                            ìœ„í—˜ ìš”ì¸ '{selected_risk}'ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ëŒ€ì‘ ë§¤ë‰´ì–¼ì„ ì‘ì„±í•˜ì„¸ìš”.

                            [ê²€ìƒ‰ëœ ì‚¬ê·œ/ë§¤ë‰´ì–¼]
                            {context_text}

                            [ì‘ì„± ì›ì¹™]
                            1. ê²€ìƒ‰ëœ ë‚´ìš©ì— '{selected_risk}'ì™€ ì§ì ‘ ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ë‹¤ë©´, "ê´€ë ¨ëœ ë‚´ë¶€ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§íˆ ë§í•˜ê³  ì¼ë°˜ì ì¸ ì•ˆì „ ìˆ˜ì¹™ì„ ì œì•ˆí•˜ì„¸ìš”.
                            2. ëœ¬êµ¬ë¦„ ì¡ëŠ” ì†Œë¦¬ ëŒ€ì‹  'ì‘ì—… ì „', 'ì‘ì—… ì¤‘', 'ë¹„ìƒ ì‹œ' ë“± êµ¬ì²´ì ì¸ í–‰ë™ ìš”ë ¹ì„ ë‚˜ì—´í•˜ì„¸ìš”.
                            3. ì¶œì²˜(ë¬¸ì„œëª… ë“±)ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤ë©´ í•¨ê»˜ ëª…ì‹œí•˜ì„¸ìš”.
                            """
                            
                            # ì‹¤ì œ LLM í˜¸ì¶œ (main.py ìƒë‹¨ì— ì„ ì–¸ëœ llm ê°ì²´ ì‚¬ìš©)
                            # (st.write_streamì„ ì“°ë©´ íƒ€ìê¸° íš¨ê³¼ ê°€ëŠ¥ - LangChain ë²„ì „ì— ë”°ë¼ ë‹¤ë¦„)
                            
                            # ë°©ë²• A: invoke ì‚¬ìš© (LangChain ìµœì‹ )
                            # response = llm.invoke(prompt)
                            # result_text = response.content
                            
                            # ë°©ë²• B: predict ì‚¬ìš© (LangChain êµ¬ë²„ì „)
                            # result_text = llm.predict(prompt)
                            
                            # [ê°€ì •] main.pyì— 'llm' ê°ì²´ê°€ ìˆë‹¤ê³  ê°€ì •í•˜ê³  ì‹¤í–‰
                            # ë§Œì•½ llm ê°ì²´ ì´ë¦„ì´ ë‹¤ë¥´ë©´(chat_model ë“±) ìˆ˜ì • í•„ìš”
                            if 'llm' in globals():
                                response = llm.invoke([HumanMessage(content=prompt)])
                                result_text = response.content
                            elif 'chat_model' in globals(): # ì´ë¦„ì´ chat_modelì¼ ê²½ìš°
                                response = chat_model.invoke([HumanMessage(content=prompt)])
                                result_text = response.content
                            else:
                                result_text = "âš ï¸ ì½”ë“œ ì—ëŸ¬: 'llm' ë˜ëŠ” 'chat_model' ê°ì²´ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. main.pyë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

                            st.markdown(result_text)

                        except Exception as e:
                            st.error(f"ìƒì„± ì˜¤ë¥˜: {e}")
                            st.info("ğŸ’¡ íŒ: Tab 1ì—ì„œ ë²¡í„° DBê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")
            else:
                st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ìœ„í—˜ ìš”ì¸ì„ ì„ íƒí•˜ê³  ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

    else:
        st.warning("âš ï¸ Tab 3(ìœ„í—˜ ë¶„ì„)ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")