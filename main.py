import streamlit as st
import os
import pandas as pd
import time
import re
import csv
from datetime import datetime
import altair as alt
import json

# LangChain & Core
from langchain_chroma import Chroma
from langchain.schema import HumanMessage # [ê°œì„ 2] HumanMessage ì¶”ê°€
from langchain_core.prompts import PromptTemplate

# Core ëª¨ë“ˆ
try:
    from core.config import PERSIST_DIRECTORY
    from core.llm import get_llm, get_embeddings
    from core.decision_ai import decision_ai
except ImportError:
    PERSIST_DIRECTORY = "./chroma_db"
    from core.llm import get_llm, get_embeddings

# ------------------------------------------------------------------
# [ê°œì„ ] ê²½ë¡œ ì„¤ì • (ì ˆëŒ€ ê²½ë¡œë¡œ ê³ ì •)
# ------------------------------------------------------------------
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SHARED_DIR = os.path.join(BASE_DIR, "shared")
if not os.path.exists(SHARED_DIR):
    os.makedirs(SHARED_DIR)
# [ì„¤ì • íŒŒì¼ ê²½ë¡œ ì •ì˜]
CONFIG_FILE = os.path.join(SHARED_DIR, "system_config.json")

st.set_page_config(page_title="ì² ë„ì•ˆì „ AI ì‹œìŠ¤í…œ", layout="wide")
st.title("ğŸš„ ì² ë„ì•ˆì „ AI í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ (v1.0)")

# ------------------------------------------------------------------
# í•¨ìˆ˜ ì •ì˜
# ------------------------------------------------------------------
def get_vectorstore():
    # 1. DB í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(PERSIST_DIRECTORY):
        return None
    
    try:
        # 2. ChromaDB ë¡œë“œ
        # ì£¼ì˜: collection_name="regulations" ë¶€ë¶„ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.
        # admin.pyì—ì„œ ì €ì¥í•œ ê¸°ë³¸ ì„¤ì •ê³¼ ë§ì¶”ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
        vectorstore = Chroma(
            persist_directory=PERSIST_DIRECTORY,
            embedding_function=get_embeddings()
        )
        return vectorstore
    except Exception as e:
        st.error(f"ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# [ì‹ ê·œ í•¨ìˆ˜] ì„¤ì •ëœ ëª¨ë¸ëª… ê°€ì ¸ì˜¤ê¸°
def get_selected_model():
    default_model = "korean-llama3:latest"
    if os.path.exists(CONFIG_FILE):
        try:
            with open(CONFIG_FILE, "r", encoding="utf-8") as f:
                config = json.load(f)
                return config.get("selected_model", default_model)
        except:
            return default_model
    return default_model

def save_feedback(user_q, ai_a, user_correction, rating):
    """ì‚¬ìš©ì í”¼ë“œë°±ì„ CSVì— ì €ì¥ (ê´€ë¦¬ì í•™ìŠµìš©)"""
    feedback_file = os.path.join(SHARED_DIR, "feedback_log.csv")
    
    # íŒŒì¼ì´ ì—†ìœ¼ë©´ í—¤ë” ìƒì„±
    if not os.path.exists(feedback_file):
        with open(feedback_file, mode="w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerow(["Timestamp", "Question", "AI_Answer", "User_Correction", "Rating", "Status"])

    # ë°ì´í„° ì¶”ê°€
    with open(feedback_file, mode="a", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow([
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            user_q,
            ai_a,
            user_correction,
            rating,
            "Pending"  # ê´€ë¦¬ìê°€ ì•„ì§ ë°˜ì˜ ì•ˆ í•¨
        ])

def query_regulation(query, vectorstore, llm):
    """
    ì§ˆë¬¸ì— ëŒ€í•´ ë²¡í„° ì €ì¥ì†Œì—ì„œ ë¬¸ì„œë¥¼ ì°¾ê³  LLMì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # ê²€ìƒ‰ ë²”ìœ„ (k=6)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 6})
    
    docs = retriever.invoke(query)
    if not docs:
        return "í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê·œì • ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

    prompt_template = """
    ### [Role]
    ë‹¹ì‹ ì€ í•œêµ­ì˜ ì² ë„ ì•ˆì „ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì•„ë˜ [ê·œì • ë¬¸ë§¥]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹­ì‹œì˜¤.

    ### [Guidelines]
    1. **ë°˜ë“œì‹œ í•œêµ­ì–´(Korean)ë¡œë§Œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.** (Do not use English).
    2. ë‹µë³€ì€ [ê·œì • ë¬¸ë§¥]ì— ìˆëŠ” ë‚´ìš©ì—ë§Œ ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.
    3. ê·œì •ì— ì—†ëŠ” ë‚´ìš©ì„ ì§ˆë¬¸í•˜ë©´ "ê·œì •ì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
    4. ì¡°í•­ ë²ˆí˜¸(ì˜ˆ: ì œ3ì¡°)ë‚˜ ìˆ˜ì¹˜(ì˜ˆ: 10m, 30%)ëŠ” ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”.
    5. ë‹µë³€ í†¤ì€ ì „ë¬¸ì ì´ê³  ëª…í™•í•˜ë©° ì¹œì ˆí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

    [ê·œì • ë¬¸ë§¥]:
    {context}

    ì§ˆë¬¸: {question}
    
    ë‹µë³€:
    """
    PROMPT = PromptTemplate(
        template=prompt_template, 
        input_variables=["context", "question"]
    )

    chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": PROMPT},
        return_source_documents=True
    )
    
    result = chain.invoke({"query": query})
    return result["result"], result["source_documents"]
                                
# ------------------------------------------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ------------------------------------------------------------------
if "llm" not in st.session_state:
    st.session_state["llm"] = get_llm("korean-llama3")

if "vectorstore" not in st.session_state:
    st.session_state["vectorstore"] = get_vectorstore()

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (messages ë¦¬ìŠ¤íŠ¸ì— sources ì •ë³´ë„ í•¨ê»˜ ì €ì¥)
if "messages" not in st.session_state:
    st.session_state["messages"] = []

llm = st.session_state["llm"]
vectorstore = st.session_state["vectorstore"]

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SHARED_DIR = os.path.join(BASE_DIR, "shared")
FILE_PATH = os.path.join(SHARED_DIR, "risk_df.pkl")

# ------------------------------------------------------------------
# ì‚¬ì´ë“œë°”
# ------------------------------------------------------------------
# with st.sidebar:
#     st.header("ğŸ”Œ ì‹œìŠ¤í…œ ìƒíƒœ")
#     if vectorstore is not None:
#         try:
#             count = vectorstore._collection.count()
#             st.success(f"ê·œì • DB ì—°ê²°ë¨ (ë¬¸ì„œ ì²­í¬: {count}ê°œ)")
#         except:
#             st.warning("ê·œì • DB ì—°ê²° ë¶ˆì•ˆì •")
#     else:
#         st.error("ê·œì • DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
#     if st.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
#         st.session_state["messages"] = []
#         st.rerun()

# ======================================
# íƒ­ êµ¬ì„±
# ======================================
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ’¬ ê·œì • ì±—ë´‡",
    "ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ",
    "ğŸ§  í†µí•© ìœ„í—˜ ë¶„ì„",
    "ğŸš¨ ìœ„í—˜ íŒë‹¨ & ì¡°ì¹˜ ì¶”ì²œ"
])

# ==================================================================
# TAB 1. ğŸ’¬ ê·œì • ì±—ë´‡ (ë©€í‹°í„´ + ê³ ê¸‰ê²€ìƒ‰ + í”¼ë“œë°± ë£¨í”„)
# ==================================================================
with tab1:
    current_model = get_selected_model()
    st.markdown(f"#### ğŸ’¬ ì² ë„ì•ˆì „ ê·œì • ì „ë¬¸ ì±—ë´‡ (Model: :orange[{current_model}])")
    st.caption("ğŸ’¡ ê·œì • ê²€ìƒ‰ë¶€í„° ì—…ë¬´ ì§ˆì˜ê¹Œì§€, AIê°€ ë¬¸ë§¥ì„ ì´í•´í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤.")
    # [1] ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # [2] ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶œë ¥ (ì±„íŒ…ë°© ìŠ¤íƒ€ì¼)
    # for msg in st.session_state.messages:
    #     with st.chat_message(msg["role"]):
    #         st.markdown(msg["content"])
            
    #         if msg["role"] == "assistant":
    #             if msg.get("sources"):
    #                 with st.expander("ğŸ“š ê·¼ê±° ê·œì • ë° ì¶œì²˜ í™•ì¸"):
    #                     for src in msg["sources"]:
    #                         st.markdown(f"**ğŸ“„ {src['source']}**")
    #                         safe_content = src['content'].replace("|", " ").replace("\n", " ")[:200]
    #                         st.caption(f"{safe_content}...")
    #             if msg.get("status"):
    #                 st.caption(msg["status"])

    # [3] ìƒˆë¡œìš´ ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬
    if prompt := st.chat_input("ê·œì •ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”..."):
        
        # 3-1. ì‚¬ìš©ì ë©”ì‹œì§€ ì¦‰ì‹œ í‘œì‹œ ë° ì €ì¥
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})

        # 3-2. ê·œì • DB ë¡œë“œ í™•ì¸
        vectorstore = get_vectorstore()
        
        if vectorstore is None:
            st.error("ğŸš¨ í•™ìŠµëœ ê·œì • DBê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ë¬¸ì„œë¥¼ ë¨¼ì € í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.")
        else:
            with st.chat_message("assistant"):
                message_placeholder = st.empty()
                status_placeholder = st.empty()
                
                with st.spinner("ê·œì • ì •ë°€ ë¶„ì„ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                    try:
                        # --- [Core 1] ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬ë§·íŒ… ---
                        history_text = ""
                        recent_msgs = st.session_state.messages[-6:-1] 
                        if recent_msgs:
                            history_text = "[ì´ì „ ëŒ€í™” ë‚´ì—­]\n"
                            for m in recent_msgs:
                                role_label = "User" if m["role"] == "user" else "Assistant"
                                history_text += f"- {role_label}: {m['content']}\n"
                        
                        # --- [Core 2] ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ---
                        search_kwargs = {"k": 6}
                        status_msg = "ğŸ” ì „ì²´ ê·œì • ë¬¸ì„œì—ì„œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                        
                        try:
                            all_data = vectorstore.get()
                            unique_sources = list(set([m['source'] for m in all_data['metadatas'] if m]))
                            
                            target_source = None
                            for src in unique_sources:
                                base_name = os.path.basename(src).split('.')[0]
                                if len(base_name) >= 2 and base_name in prompt:
                                    target_source = src
                                    break
                            
                            if target_source:
                                search_kwargs["filter"] = {"source": target_source}
                                status_msg = f"ğŸ¯ **'{os.path.basename(target_source)}'** ë¬¸ì„œ ë‚´ì—ì„œ ì§‘ì¤‘ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                        except:
                            pass 
                        
                        # --- [Core 3] MMR ê²€ìƒ‰ ìˆ˜í–‰ ---
                        retriever = vectorstore.as_retriever(
                            search_type="mmr",
                            search_kwargs={**search_kwargs, "fetch_k": 20, "lambda_mult": 0.6}
                        )
                        docs = retriever.invoke(prompt)
                        context_text = "\n\n".join([d.page_content for d in docs])
                        
                        # ì†ŒìŠ¤ ì •ë³´ êµ¬ì¡°í™”
                        sources_for_ui = []
                        seen_titles = set()
                        for doc in docs:
                            src_file = os.path.basename(doc.metadata.get("source", "íŒŒì¼"))
                            raw_title = doc.metadata.get("Article_Title", "ë³¸ë¬¸")
                            match = re.match(r"(ì œ\s*\d+\s*ì¡°(?:ì˜\d+)?(?:\([^)]*\))?)", raw_title)
                            clean_title = match.group(1) if match else raw_title[:30]
                            
                            key = (src_file, clean_title)
                            if key not in seen_titles:
                                sources_for_ui.append({"source": src_file, "title": clean_title, "content": doc.page_content})
                                seen_titles.add(key)

                        # --- [Core 4] LLM ë‹µë³€ ìƒì„± (ìˆ˜ì •ëœ ë¶€ë¶„) ---
                        if not context_text:
                            response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ê·œì • ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                        else:
                            tmpl = f"""
                            [System Instruction]
                            ë‹¹ì‹ ì€ ì² ë„ì•ˆì „ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                            
                            **ë‹µë³€ ì‘ì„± ì›ì¹™**:
                            1. **ê·¼ê±° ì¤‘ì‹¬**: ìƒìƒí•˜ì§€ ë§ê³  ë°˜ë“œì‹œ [Context]ì— ìˆëŠ” ë‚´ìš©ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. 
                            2. **ë§¥ë½ ìœ ì§€**: [History]ë¥¼ ì°¸ê³ í•˜ì—¬ ëŒ€ëª…ì‚¬('ê·¸ê²ƒ', 'ì•ì˜ ë‚´ìš©')ê°€ ë¬´ì—‡ì„ ì§€ì¹­í•˜ëŠ”ì§€ íŒŒì•…í•˜ì„¸ìš”.
                            3. **í‘œ/ìˆ˜ì¹˜ ìœ ì§€**: ë“±ê¸‰í‘œ, ì§€ê¸‰ìœ¨ ë“±ì€ ë§ˆí¬ë‹¤ìš´ í‘œ(Table)ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.
                            4. **ì¡°í•­ ëª…ì‹œ**: ê°€ëŠ¥í•˜ë‹¤ë©´ "ì œOOì¡°ì— ë”°ë¥´ë©´..." í˜•íƒœë¡œ ì¶œì²˜ë¥¼ ë°íˆì„¸ìš”.
                            5. **ê³„ì‚°**: ìˆ˜ì‹ì„ ì„¤ëª…í•  ë•Œë„ í•œêµ­ì–´ë¡œ í’€ì–´ì„œ ì„¤ëª…í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: "A multiplied by B" -> "Aì— Bë¥¼ ê³±í•˜ì—¬")
                            
                            {history_text}

                            [Context]:
                            {context_text}

                            [Current Question]:
                            {prompt}

                            [Answer]:
                            """
                            
                            # LLM í˜¸ì¶œ ë° ë³€ìˆ˜ í• ë‹¹ (NameError í•´ê²°)
                            model_name = get_selected_model() 
                            llm = get_llm(model_name)
                            
                            if hasattr(llm, 'invoke'):
                                resp = llm.invoke([HumanMessage(content=tmpl)])
                                response_text = resp.content
                            else:
                                response_text = llm.predict(tmpl)

                        # --- [UI Update] ê²°ê³¼ ì¶œë ¥ ---
                        # response_textê°€ ìœ„ì—ì„œ ë°˜ë“œì‹œ í• ë‹¹ë˜ë¯€ë¡œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
                        message_placeholder.markdown(response_text)
                        status_placeholder.caption(status_msg)
                        
                        # ê·¼ê±° ë¬¸ì„œ ì•„ì½”ë””ì–¸
                        if sources_for_ui:
                            with st.expander("ğŸ“š ê·¼ê±° ê·œì • ë° ì¶œì²˜ í™•ì¸"):
                                for src in sources_for_ui:
                                    st.markdown(f"**ğŸ“„ {src['source']} - {src['title']}**")
                                    safe_content = src['content'].replace("|", " ").replace("\n", " ")[:200]
                                    st.caption(f"{safe_content}...")

                        # ì„¸ì…˜ì— Assistant ë©”ì‹œì§€ ì €ì¥
                        st.session_state.messages.append({
                            "role": "assistant", 
                            "content": response_text,
                            "sources": sources_for_ui,
                            "status": status_msg,
                            "timestamp": time.time() # í”¼ë“œë°± IDìš©
                        })
                        # ë©”ì‹œì§€ ì €ì¥ í›„ í™”ë©´ ê°±ì‹  (í”¼ë“œë°± ë²„íŠ¼ í™œì„±í™”ë¥¼ ìœ„í•´)
                        st.rerun()

                    except Exception as e:
                        st.error(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

    # 5. ëŒ€í™” ë‚´ì—­ ì¶œë ¥ (ì—­ìˆœ + í”¼ë“œë°± UI í¬í•¨)
    st.divider()
    
    # ë©”ì‹œì§€ê°€ ìˆì„ ë•Œë§Œ ì²˜ë¦¬
    if st.session_state.messages:
        # (1) ë©”ì‹œì§€ë¥¼ (ì§ˆë¬¸, ë‹µë³€) ìŒìœ¼ë¡œ ê·¸ë£¹í™”
        # ê°€ì •: ë¦¬ìŠ¤íŠ¸ëŠ” í•­ìƒ [User, Assistant, User, Assistant...] ìˆœì„œë¡œ ì €ì¥ë¨
        conversations = []
        msgs = st.session_state.messages
        
        # 2ê°œì”© ë¬¶ì–´ì„œ ë¦¬ìŠ¤íŠ¸ì— ë‹´ìŒ
        for i in range(0, len(msgs), 2):
            if i + 1 < len(msgs):
                # (User Msg, Assistant Msg) íŠœí”Œë¡œ ì €ì¥
                conversations.append((msgs[i], msgs[i+1]))
            else:
                # ì§ì´ ì•ˆ ë§ëŠ” ë§ˆì§€ë§‰ ë©”ì‹œì§€ (í˜¹ì‹œ ëª¨ë¥¼ ì˜ˆì™¸ ì²˜ë¦¬)
                conversations.append((msgs[i], None))
        
        # (2) ê·¸ë£¹ ìì²´ë¥¼ ì—­ìˆœìœ¼ë¡œ ìˆœíšŒ (ìµœì‹  ëŒ€í™” ì„¸íŠ¸ê°€ ë¨¼ì € ë‚˜ì˜´)
        for user_msg, ai_msg in reversed(conversations):
            with st.container():
                # A. ì‚¬ìš©ì ì§ˆë¬¸ ì¶œë ¥
                if user_msg:
                    with st.chat_message("user"):
                        st.write(user_msg["content"])
                
                # B. AI ë‹µë³€ ì¶œë ¥
                if ai_msg:
                    with st.chat_message("assistant"):
                        st.write(ai_msg["content"])
                        
                        # ë¶€ê°€ ì •ë³´ (ìƒíƒœ, ì¶œì²˜)
                        if ai_msg.get("status"):
                            st.caption(ai_msg["status"])
                        
                        if ai_msg.get("sources"):
                            with st.expander("ğŸ“š ê·¼ê±° ê·œì • ë³´ê¸°"):
                                for src in ai_msg["sources"]:
                                    st.markdown(f"**ğŸ“„ {src['source']}**")
                                    safe_content = src['content'].replace("|", " ").replace("\n", " ")[:200]
                                    st.caption(f"{safe_content}...")
                        
                        # í”¼ë“œë°± ë²„íŠ¼ (ë‹µë³€ ë°”ë¡œ ì•„ë˜ ìœ„ì¹˜)
                        ts = ai_msg.get("timestamp", int(time.time()))
                        fb_key = f"fb_{ts}"
                        
                        col_f1, col_f2 = st.columns([1, 4])
                        with col_f1:
                            if st.button("ğŸ‘ ì¢‹ì•„ìš”", key=f"lk_{fb_key}"):
                                save_feedback(user_msg["content"], ai_msg["content"], "", "Good")
                                st.toast("í‰ê°€ ê°ì‚¬í•©ë‹ˆë‹¤!")
                        with col_f2:
                            with st.popover("ğŸ‘ ìˆ˜ì • ì œì•ˆ"):
                                correction = st.text_area("ì˜¬ë°”ë¥¸ ë‚´ìš©:", key=f"tx_{fb_key}")
                                if st.button("ì „ì†¡", key=f"sd_{fb_key}"):
                                    if correction:
                                        save_feedback(user_msg["content"], ai_msg["content"], correction, "Bad")
                                        st.success("ì „ì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.")

            # ì„¸íŠ¸ ê°„ êµ¬ë¶„ì„ 
            st.divider()
                                
# ======================================
# TAB 2. ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ (Professional Ver.)
# ======================================
with tab2:
    # 1. í—¤ë” & ì»¨íŠ¸ë¡¤ íŒ¨ë„
    col_header, col_filter = st.columns([3, 1])
    
    with col_header:
        st.subheader("ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ")
        st.caption("ë°ì´í„° ê¸°ë°˜ ì‚¬ê³  ì›ì¸ ë° ì¶”ì„¸ ì‹¬ì¸µ ë¶„ì„")
        
    with col_filter:
        line_options = ["ì „ì²´", "1í˜¸ì„ ", "2í˜¸ì„ ", "7í˜¸ì„ "]
        selected_line = st.selectbox("ğŸ” í˜¸ì„  í•„í„°", line_options)

    st.markdown("---")

    if os.path.exists(FILE_PATH):
        try:
            df = pd.read_pickle(FILE_PATH)
            
            # -----------------------------------------------------------
            # [1] ë°ì´í„° ì „ì²˜ë¦¬
            # -----------------------------------------------------------
            col_map = {
                "line": "í˜¸ì„ ",
                "date": "ë°œìƒì¼ì",
                "cause": "ë¶€ì›ì¸",
                "place": "ë°œìƒì¥ì†Œ",
                "r_type": "ê·€ì±…êµ¬ë¶„",
                "age": "ì—°ë ¹ëŒ€"
            }
            
            for key, actual_col in col_map.items():
                if actual_col not in df.columns:
                    df[actual_col] = "ì •ë³´ì—†ìŒ" if key != "date" else "2024-01-01"

            # í˜¸ì„  ì •ì œ í•¨ìˆ˜
            def clean_line_name(val):
                val_str = str(val)
                if "1í˜¸ì„ " in val_str: return "1í˜¸ì„ "
                if "2í˜¸ì„ " in val_str: return "2í˜¸ì„ "
                if "7í˜¸ì„ " in val_str: return "7í˜¸ì„ "
                return "ê¸°íƒ€"
            
            # ê´„í˜¸ ë° ìˆ«ì ì œê±° í•¨ìˆ˜ ([2]ìŒì£¼ -> ìŒì£¼)
            def clean_label_text(val):
                val_str = str(val)
                # ëŒ€ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ìˆ«ì/ë¬¸ì ì œê±° í›„ ì•ë’¤ ê³µë°± ì œê±°
                return re.sub(r'\[.*?\]', '', val_str).strip()

            df["í˜¸ì„ _ì •ì œ"] = df[col_map["line"]].apply(clean_line_name)
            df[col_map["date"]] = pd.to_datetime(df[col_map["date"]], errors='coerce')
            df["ì›”"] = df[col_map["date"]].dt.strftime('%Y-%m')

            # ë¶„ì„ìš© ì»¬ëŸ¼ë“¤ì— ëŒ€í•´ ë¼ë²¨ í´ë¦¬ë‹ ë¯¸ë¦¬ ì ìš© (ê°€ë…ì„± í–¥ìƒ)
            target_cols_clean = [col_map["cause"], col_map["place"], col_map["r_type"], col_map["age"]]
            for col in target_cols_clean:
                df[col] = df[col].apply(clean_label_text)

            # -----------------------------------------------------------
            # [2] ë°ì´í„° í•„í„°ë§
            # -----------------------------------------------------------
            target_lines = ["1í˜¸ì„ ", "2í˜¸ì„ ", "7í˜¸ì„ "]
            
            if selected_line == "ì „ì²´":
                filtered_df = df[df["í˜¸ì„ _ì •ì œ"].isin(target_lines)]
                if filtered_df.empty: filtered_df = df 
            else:
                filtered_df = df[df["í˜¸ì„ _ì •ì œ"] == selected_line]

            # -----------------------------------------------------------
            # [3] ëŒ€ì‹œë³´ë“œ ì‹œê°í™”
            # -----------------------------------------------------------
            if not filtered_df.empty:
                
                # [KPI Section] í•µì‹¬ ìš”ì•½
                kpi1, kpi2, kpi3, kpi4 = st.columns(4)
                
                total_cnt = len(filtered_df)
                kpi1.metric("ì´ ë°œìƒ ê±´ìˆ˜", f"{total_cnt}ê±´")
                
                top_cause = filtered_df[col_map["cause"]].mode()[0] if not filtered_df[col_map["cause"]].empty else "-"
                cause_cnt = filtered_df[col_map["cause"]].value_counts().iloc[0] if not filtered_df[col_map["cause"]].empty else 0
                kpi2.metric("ìµœë‹¤ ë¹ˆë„ ì›ì¸", top_cause, f"{cause_cnt}ê±´")
                
                top_place = filtered_df[col_map["place"]].mode()[0] if not filtered_df[col_map["place"]].empty else "-"
                kpi3.metric("ì£¼ìš” ë°œìƒ ì¥ì†Œ", top_place)

                top_resp = filtered_df[col_map["r_type"]].mode()[0] if not filtered_df[col_map["r_type"]].empty else "-"
                kpi4.metric("ì£¼ìš” ê·€ì±… ì‚¬ìœ ", top_resp)

                st.markdown("###")

                # [Chart Row 1] ì‹œê³„ì—´ ë¶„ì„ (ê¸°ì¡´ ìœ ì§€)
                st.markdown("##### ğŸ“… ì›”ë³„ ì‚¬ê³  ë°œìƒ ì¶”ì´ ë° ì›ì¸ êµ¬ì„±")
                time_chart_data = filtered_df.groupby(["ì›”", col_map["cause"]]).size().reset_index(name='ê±´ìˆ˜')
                
                time_chart = alt.Chart(time_chart_data).mark_bar().encode(
                    x=alt.X('ì›”', title='ê¸°ê°„'),
                    y=alt.Y('ê±´ìˆ˜', title='ë°œìƒ ê±´ìˆ˜'),
                    color=alt.Color(col_map["cause"], title='ë¶€ì›ì¸'),
                    tooltip=['ì›”', col_map["cause"], 'ê±´ìˆ˜']
                ).properties(height=300) # ë†’ì´ ì•½ê°„ ì¡°ì •
                
                st.altair_chart(time_chart, use_container_width=True)

                st.divider()

                # [Chart Row 2] ìƒì„¸ í†µê³„ ë¶„ì„ (1x4 êµ¬ì¡°ë¡œ ë³€ê²½ + ì½”ë©˜íŠ¸)
                st.markdown("##### ğŸ“Š ìƒì„¸ í†µê³„ ë° ì¸ì‚¬ì´íŠ¸ ë¶„ì„")

                # --- [í•¨ìˆ˜] ì°¨íŠ¸, í…Œì´ë¸”, ì½”ë©˜íŠ¸ ìƒì„± ---
                def create_analysis_component(data, col_name, title):
                    # 1. ë°ì´í„° ì§‘ê³„
                    counts = data[col_name].value_counts().reset_index()
                    counts.columns = ["í•­ëª©", "ê±´ìˆ˜"]
                    
                    # 2. ë¹„ìœ¨ ê³„ì‚°
                    total = counts["ê±´ìˆ˜"].sum()
                    if total > 0:
                        counts["ë¹„ìœ¨"] = ((counts["ê±´ìˆ˜"] / total) * 100).round(1) # ì†Œìˆ˜ì  1ìë¦¬
                    else:
                        counts["ë¹„ìœ¨"] = 0
                    
                    # 3. Altair ë„ë„› ì°¨íŠ¸
                    base = alt.Chart(counts).encode(theta=alt.Theta("ê±´ìˆ˜", stack=True))
                    
                    pie = base.mark_arc(innerRadius=50, outerRadius=90).encode(
                        color=alt.Color("í•­ëª©", legend=alt.Legend(orient="right", title=None)), 
                        order=alt.Order("ê±´ìˆ˜", sort="descending"),
                        tooltip=["í•­ëª©", "ê±´ìˆ˜", alt.Tooltip("ë¹„ìœ¨", format=".1f")]
                    )
                    
                    # [ìˆ˜ì •] .filter() -> .transform_filter() ë¡œ ë³€ê²½
                    text = base.mark_text(radius=110).encode(
                        text=alt.Text("ë¹„ìœ¨", format=".0f"), 
                        order=alt.Order("ê±´ìˆ˜", sort="descending"),
                        color=alt.value("black")
                    ).transform_filter(
                        alt.datum.ë¹„ìœ¨ > 4  # ë¹„ìœ¨ì´ 4% ì´ˆê³¼ì¸ ê²ƒë§Œ í…ìŠ¤íŠ¸ í‘œì‹œ
                    )

                    chart = (pie + text).properties(height=250)

                    # 4. í…Œì´ë¸” ë°ì´í„° ì •ë¦¬
                    table_df = counts[["í•­ëª©", "ê±´ìˆ˜", "ë¹„ìœ¨"]].copy()
                    table_df.columns = ["í•­ëª©", "ê±´ìˆ˜", "ë¹„ìœ¨(%)"]
                    
                    # 5. ìë™ ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
                    if not counts.empty:
                        top1 = counts.iloc[0]
                        insight_text = f"""
                        - **ìµœë‹¤ ë¹ˆë„:** <span style='color:red'>**{top1['í•­ëª©']}**</span> ({top1['ê±´ìˆ˜']}ê±´, {top1['ë¹„ìœ¨']}%)
                        """
                        
                        if len(counts) > 1:
                            top2 = counts.iloc[1]
                            diff = top1['ê±´ìˆ˜'] - top2['ê±´ìˆ˜']
                            insight_text += f"""
                            - **2ìœ„ í•­ëª©:** {top2['í•­ëª©']} ({top2['ë¹„ìœ¨']}%)
                            - **ë¶„ì„:** 1ìœ„ í•­ëª©ì´ 2ìœ„ ëŒ€ë¹„ **{diff}ê±´** ë” ë§ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
                            """
                    else:
                        insight_text = "ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

                    return chart, table_df, insight_text

                # --- [ë©”ì¸ ë¡œì§] 1 Row per Metric (1x4 Stack) ---
                metrics = [
                    ("cause", "1. ë¶€ì›ì¸ ë¶„ì„"),
                    ("place", "2. ë°œìƒì¥ì†Œ ë¶„ì„"),
                    ("r_type", "3. ê·€ì±…êµ¬ë¶„ ë¶„ì„"),
                    ("age", "4. ì—°ë ¹ëŒ€ë³„ ë¶„ì„")
                ]

                for col_key, title in metrics:
                    st.markdown(f"**ğŸ“Œ {title}**")
                    
                    # ë ˆì´ì•„ì›ƒ ë¹„ìœ¨ [ì°¨íŠ¸(2) : í…Œì´ë¸”(1.5) : ì½”ë©˜íŠ¸(1.5)]
                    c1, c2, c3 = st.columns([2, 1.5, 1.5])
                    
                    chart, df_table, insight = create_analysis_component(filtered_df, col_map[col_key], title)
                    
                    with c1:
                        st.altair_chart(chart, use_container_width=True)
                    
                    with c2:
                        st.dataframe(
                            df_table, 
                            hide_index=True, 
                            use_container_width=True,
                            height=200
                        )
                    
                    with c3:
                        st.info("ğŸ’¡ **AI Insight**")
                        st.markdown(insight, unsafe_allow_html=True)
                    
                    st.divider() # í•­ëª© ê°„ êµ¬ë¶„ì„ 

                # [List Section] ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ê¸°ì¡´ ìœ ì§€)
                st.markdown(f"##### ğŸ“‹ {selected_line} Raw Data (ìƒìœ„ 100ê±´)")
                st.dataframe(
                    filtered_df.head(100), 
                    use_container_width=True, 
                    height=250, 
                    hide_index=True
                )
            
            else:
                st.warning(f"ì„ íƒí•˜ì‹  '{selected_line}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ë””ë²„ê¹…ìš© traceback ì¶œë ¥ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
            # import traceback
            # st.text(traceback.format_exc())
    else:
        st.info("ì•„ì§ ìƒí™©ë³´ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# ==================================================================
# TAB 3. ğŸ§  í†µí•© ìœ„í—˜ ë¶„ì„ (Risk Matrix) - [ì‹œê°í™” ê°•í™” & ìë™ ì œì•ˆ Ver]
# ==================================================================
with tab3:
    st.subheader("ğŸ§  í†µí•© ìœ„í—˜ë„ í‰ê°€ (Risk Matrix)")
    st.caption("ë°œìƒ ë¹ˆë„(ë°ì´í„° ê¸°ë°˜)ì™€ ì‹¬ê°ë„(ì‚¬ìš©ì ì„¤ì •)ë¥¼ ë¶„ì„í•˜ì—¬ ìœ„í—˜ ìš°ì„ ìˆœìœ„ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.")
    
    # íŒŒì¼ ê²½ë¡œ ë³€ìˆ˜ í™•ì¸ (ì „ì—­ ë³€ìˆ˜ FILE_PATH ì‚¬ìš© ê°€ì •)
    target_file = FILE_PATH if os.path.exists(FILE_PATH) else None
    
    if target_file:
        try:
            df_risk = pd.read_pickle(target_file)
            
            # ----------------------------------------------------------
            # [1] ë°ì´í„° ì „ì²˜ë¦¬
            # ----------------------------------------------------------
            col_cause = "ì£¼ì›ì¸" if "ì£¼ì›ì¸" in df_risk.columns else "cause"
            if col_cause not in df_risk.columns:
                df_risk[col_cause] = "ì •ë³´ì—†ìŒ"
            
            unique_causes = df_risk[col_cause].unique()
            
            # ----------------------------------------------------------
            # [2] ì‹¬ê°ë„ ì„¤ì • (í‚¤ì›Œë“œ ê¸°ë°˜ ìë™ ì œì•ˆ)
            # ----------------------------------------------------------
            def suggest_severity(cause_text):
                text = str(cause_text)
                if any(k in text for k in ['ì‚¬ë§', 'í­ë°œ', 'í™”ì¬', 'ë¶•ê´´', 'ì¶©ëŒ']): return 5 # ì¹˜ëª…ì 
                if any(k in text for k in ['ì¶”ë½', 'í˜‘ì°©', 'ë¼ì„', 'ê°ì „', 'ì ˆë‹¨']): return 4 # ì¤‘ëŒ€
                if any(k in text for k in ['ê³¨ì ˆ', 'í™”ìƒ', 'ëˆ„ì¶œ']): return 3 # ë³´í†µ
                if any(k in text for k in ['ì „ë„', 'ë„˜ì–´ì§', 'ë¶€ë”ªí˜', 'ë¯¸ë„ëŸ¬ì§']): return 2 # ê²½ë¯¸
                return 1 # ë¬´ì‹œ ê°€ëŠ¥

            with st.expander("âš™ï¸ [ì„¤ì •] ì‚¬ê³  ìœ í˜•ë³„ ì‹¬ê°ë„ ì¡°ì • (AI ìë™ ì œì•ˆ ì ìš©ë¨)", expanded=False):
                st.info("ğŸ’¡ ì‚¬ê³  ìœ í˜• í‚¤ì›Œë“œë¥¼ ë¶„ì„í•˜ì—¬ ì‹¬ê°ë„ ì´ˆê¸°ê°’ì„ ìë™ìœ¼ë¡œ ì œì•ˆí–ˆìŠµë‹ˆë‹¤. ì‹¤ì œ ìƒí™©ì— ë§ê²Œ ì¡°ì •í•´ì£¼ì„¸ìš”.")
                
                suggested_data = [{"ì‚¬ê³ ìœ í˜•": c, "ì‹¬ê°ë„": suggest_severity(c)} for c in unique_causes]
                df_severity_base = pd.DataFrame(suggested_data)
                
                edited_df = st.data_editor(
                    df_severity_base,
                    column_config={
                        "ì‹¬ê°ë„": st.column_config.NumberColumn(
                            "ì‹¬ê°ë„ (1-5)", 
                            help="1(ê²½ë¯¸) ~ 5(ì¹˜ëª…ì )", 
                            min_value=1, max_value=5, step=1,
                            format="%dì "
                        )
                    },
                    use_container_width=True,
                    hide_index=True
                )
                
            # ----------------------------------------------------------
            # [3] ìœ„í—˜ë„ ê³„ì‚° ë¡œì§
            # ----------------------------------------------------------
            # 1. ë¹ˆë„ ê³„ì‚°
            df_freq = df_risk[col_cause].value_counts().reset_index()
            df_freq.columns = ["ì‚¬ê³ ìœ í˜•", "ë°œìƒê±´ìˆ˜"]
            
            # 2. ì‹¬ê°ë„ ë³‘í•©
            df_calc = pd.merge(df_freq, edited_df, on="ì‚¬ê³ ìœ í˜•", how="left")
            
            # 3. ë¹ˆë„ ë“±ê¸‰ ê³„ì‚°
            max_cnt = df_calc["ë°œìƒê±´ìˆ˜"].max()
            df_calc["ë¹ˆë„ë“±ê¸‰"] = df_calc["ë°œìƒê±´ìˆ˜"].apply(
                lambda x: int((x / max_cnt) * 4.99) + 1 if max_cnt > 0 else 1
            )
            
            # 4. ìœ„í—˜ ì ìˆ˜ ë° ë“±ê¸‰ íŒì •
            df_calc["ìœ„í—˜ì ìˆ˜"] = df_calc["ë¹ˆë„ë“±ê¸‰"] * df_calc["ì‹¬ê°ë„"]
            
            def get_grade(score):
                if score >= 15: return "High"
                elif score >= 8: return "Medium"
                return "Low"
            df_calc["ìœ„í—˜ë“±ê¸‰"] = df_calc["ìœ„í—˜ì ìˆ˜"].apply(get_grade)
            
            # 5. ì„¸ì…˜ ì €ì¥ (Tab 4 ì—°ë™)
            top_risks = df_calc.sort_values(["ìœ„í—˜ì ìˆ˜", "ë°œìƒê±´ìˆ˜"], ascending=[False, False])
            st.session_state['priority_risks'] = top_risks

            st.divider()

            # ----------------------------------------------------------
            # [4] ì‹œê°í™”: ë§¤íŠ¸ë¦­ìŠ¤ & ë¦¬ìŠ¤íŠ¸
            # ----------------------------------------------------------
            c_left, c_right = st.columns([1.4, 1])
            
            with c_left:
                st.markdown("##### ğŸ“Š 5x5 Risk Matrix")
                
                # --- [4-1] ë§¤íŠ¸ë¦­ìŠ¤ ë°ì´í„° ì¤€ë¹„ ---
                grid_data = []
                for s in range(1, 6):
                    for f in range(1, 6):
                        score = s * f
                        if score >= 15: color, label = "#FF7675", "High"
                        elif score >= 8: color, label = "#FDCB6E", "Med"
                        else: color, label = "#55EFC4", "Low"
                        grid_data.append({"ì‹¬ê°ë„_X": s, "ë¹ˆë„_Y": f, "ì ìˆ˜": score, "Color": color, "Label": label})
                df_grid_base = pd.DataFrame(grid_data)
                
                # ì‹¤ì œ ë°ì´í„° ì§‘ê³„
                df_agg = df_calc.groupby(['ì‹¬ê°ë„', 'ë¹ˆë„ë“±ê¸‰']).agg(
                    ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸=('ì‚¬ê³ ìœ í˜•', lambda x: '<br>'.join(x[:10])),
                    ëŒ€í‘œì‚¬ê³ ìœ í˜•=('ì‚¬ê³ ìœ í˜•', 'first'),
                    íƒ€ì…ìˆ˜=('ì‚¬ê³ ìœ í˜•', 'count'),
                    ì´ë°œìƒê±´ìˆ˜=('ë°œìƒê±´ìˆ˜', 'sum')
                ).reset_index()
                
                # ë³‘í•©
                df_matrix_final = pd.merge(
                    df_grid_base, df_agg,
                    left_on=['ì‹¬ê°ë„_X', 'ë¹ˆë„_Y'], right_on=['ì‹¬ê°ë„', 'ë¹ˆë„ë“±ê¸‰'],
                    how='left'
                ).fillna({'íƒ€ì…ìˆ˜': 0, 'ì´ë°œìƒê±´ìˆ˜': 0, 'ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸': '-'})

                # ë¼ë²¨ ì»¬ëŸ¼ ìƒì„±
                def create_label(row):
                    if row['íƒ€ì…ìˆ˜'] > 1:
                        return f"{row['ëŒ€í‘œì‚¬ê³ ìœ í˜•']} ì™¸ {int(row['íƒ€ì…ìˆ˜'])-1}ê±´"
                    elif row['íƒ€ì…ìˆ˜'] == 1:
                        return str(row['ëŒ€í‘œì‚¬ê³ ìœ í˜•'])
                    else:
                        return ""

                df_matrix_final['ì…€_í…ìŠ¤íŠ¸'] = df_matrix_final.apply(create_label, axis=1)

                # --- [4-2] Altair ì°¨íŠ¸ êµ¬ì„± ---
                base = alt.Chart(df_matrix_final).encode(
                    x=alt.X('ì‹¬ê°ë„_X:O', title='ì‹¬ê°ë„ (ì¤‘ëŒ€ì„±) â¡ï¸', axis=alt.Axis(labelAngle=0)),
                    y=alt.Y('ë¹ˆë„_Y:O', title='ë¹ˆë„ (ê°€ëŠ¥ì„±) â¬†ï¸', sort="descending")
                )

                # Layer 1: ë°°ê²½
                heatmap = base.mark_rect(stroke='white', strokeWidth=1).encode(
                    color=alt.Color('Color', scale=None, legend=None),
                    tooltip=[
                        alt.Tooltip('Label', title='ìœ„í—˜ë“±ê¸‰'),
                        alt.Tooltip('ì ìˆ˜', title='ìœ„í—˜ì ìˆ˜'),
                        alt.Tooltip('ì´ë°œìƒê±´ìˆ˜', title='ì´ ë°œìƒ ê±´ìˆ˜'),
                        alt.Tooltip('íƒ€ì…ìˆ˜', title='í¬í•¨ëœ ì‚¬ê³ ìœ í˜• ìˆ˜'),
                        alt.Tooltip('ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸', title='ì‚¬ê³ ìœ í˜• ëª©ë¡')
                    ]
                )

                # Layer 2: ì ìˆ˜
                text_score = base.mark_text(align='right', baseline='top', dx=25, dy=-25, size=11, opacity=0.6).encode(
                    text=alt.Text('ì ìˆ˜', format='d'),
                    color=alt.value('black')
                )
                
                # Layer 3: ë‚´ìš©
                text_content = base.transform_filter(
                    alt.datum.íƒ€ì…ìˆ˜ > 0 
                ).mark_text(baseline='middle', size=12, fontWeight='bold', dy=5).encode(
                    text=alt.Text('ì…€_í…ìŠ¤íŠ¸:N'),
                    color=alt.value('black')
                )

                chart = alt.layer(heatmap, text_score, text_content).properties(
                    width='container', height=400
                ).configure_axis(labelFontSize=12, titleFontSize=14)
                
                st.altair_chart(chart, use_container_width=True)
                st.caption("ğŸ’¡ ë§ˆìš°ìŠ¤ë¥¼ ì˜¬ë¦¬ë©´ ìƒì„¸ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            with c_right:
                st.markdown("##### ğŸš¨ ìœ„í—˜ ìš°ì„ ìˆœìœ„ (Top Risks)")
                
                if not top_risks.empty:
                    worst = top_risks.iloc[0]
                    st.error(
                        f"**âš ï¸ ìµœìš°ì„  ê´€ë¦¬ ëŒ€ìƒ**\n\n"
                        f"### {worst['ì‚¬ê³ ìœ í˜•']}\n"
                        f"- ìœ„í—˜ì ìˆ˜: **{worst['ìœ„í—˜ì ìˆ˜']:.0f}ì ** ({worst['ìœ„í—˜ë“±ê¸‰']})\n"
                        f"- ë°œìƒ: {worst['ë°œìƒê±´ìˆ˜']}ê±´ / ì‹¬ê°ë„: {worst['ì‹¬ê°ë„']}ë“±ê¸‰"
                    )
                
                st.divider()
                
                # ==========================================================
            # [ì¶”ê°€ ê¸°ëŠ¥] â„¹ï¸ ìœ„í—˜ì„± í‰ê°€ ê¸°ì¤€ ë° ë¡œì§ ì„¤ëª… (Legend)
            # ==========================================================
            with st.expander("â„¹ï¸ ìœ„í—˜ì„± í‰ê°€ ê¸°ì¤€ ë° ì‚°ì • ë¡œì§ (ìƒì„¸ ë³´ê¸°)", expanded=True):
                st.caption("ë³¸ ì‹œìŠ¤í…œì€ ì² ë„ì•ˆì „ê´€ë¦¬ì²´ê³„ ê¸°ìˆ ê¸°ì¤€ ë° ICAO SMS ë§¤ë‰´ì–¼ì„ ì¤€ìš©í•œ ìœ„í—˜ë„ í‰ê°€ ëª¨ë¸ì„ ë”°ë¦…ë‹ˆë‹¤.")
                
                l_col1, l_col2, l_col3 = st.columns(3)
                
                # 1. ì‹¬ê°ë„ (Severity) ì •ì˜
                with l_col1:
                    st.markdown("**1ï¸âƒ£ ì‹¬ê°ë„(Severity) ì‚°ì • ê¸°ì¤€**")
                    st.markdown(
                        """
                        <div style='font-size:13px; background-color:#f9f9f9; padding:10px; border-radius:5px;'>
                        <b>í‚¤ì›Œë“œ ê¸°ë°˜ ìë™ ë§¤í•‘ (AI)</b><br>
                        <span style='color:#FF4B4B'>ğŸ”´ 5ì  (ì¹˜ëª…):</span> ì‚¬ë§, í­ë°œ, í™”ì¬, ë¶•ê´´<br>
                        <span style='color:#FF8800'>ğŸŸ  4ì  (ì¤‘ëŒ€):</span> ì¶”ë½, í˜‘ì°©, ë¼ì„, ê°ì „<br>
                        <span style='color:#FFBB00'>ğŸŸ¡ 3ì  (ë³´í†µ):</span> ê³¨ì ˆ, í™”ìƒ, ëˆ„ì¶œ<br>
                        <span style='color:#00CC96'>ğŸŸ¢ 2ì  (ê²½ë¯¸):</span> ì „ë„, ë„˜ì–´ì§, ë¶€ë”ªí˜<br>
                        <span style='color:grey'>âšª 1ì  (ë¬´ì‹œ):</span> ê¸°íƒ€ ê²½ë¯¸í•œ ì‚¬í•­
                        </div>
                        """, unsafe_allow_html=True
                    )

                # 2. ë¹ˆë„ (Frequency) ë¡œì§
                with l_col2:
                    st.markdown("**2ï¸âƒ£ ë¹ˆë„(Frequency) ê³„ì‚° ë¡œì§**")
                    st.markdown(
                        """
                        <div style='font-size:13px; background-color:#f9f9f9; padding:10px; border-radius:5px;'>
                        <b>ìƒëŒ€ í‰ê°€ (Relative Grading)</b><br>
                        1.ë°ì´í„° ë‚´ ìµœë‹¤ ë°œìƒ ê±´ìˆ˜ë¥¼ ê¸°ì¤€, 5ë“±ê¸‰ êµ¬ê°„ìœ¼ë¡œ ìë™ í™˜ì‚°<br>
                        [ì˜ˆ: ìµœë‹¤ 100ê±´ì¼ ë•Œ, 80ê±´ ì´ìƒì€ 5ë“±ê¸‰]<br>
                        2.ê²½ê°ì‹¬ì„ ìœ„í•œ ë³´ìˆ˜ì  í‰ê°€, ë“±ê¸‰ì€ ì†Œìˆ˜ì  ì˜¬ë¦¼(ceiling) ì²˜ë¦¬<br>
                        [ì˜ˆ: 2.5 -> 3ë“±ê¸‰ (ë¬´ì¡°ê±´ ì˜¬ë¦¼)]<br>
                        
                        </div>
                        """, unsafe_allow_html=True
                    )

                # 3. ìœ„í—˜ë„ (Risk) íŒì •
                with l_col3:
                    st.markdown("**3ï¸âƒ£ ìœ„í—˜ ë“±ê¸‰(Risk Grade) íŒì •**")
                    st.markdown(
                        """
                        <div style='font-size:13px; background-color:#f9f9f9; padding:10px; border-radius:5px;'>
                        <b>Risk Score = ì‹¬ê°ë„ Ã— ë¹ˆë„</b><br>
                        <br>
                        <span style='background-color:#FFDDDD; padding:2px 5px; border-radius:3px;'>ğŸ”´ <b>High (15~25)</b></span>
                        ì¦‰ì‹œ ê°œì„  ëŒ€ì±… ìˆ˜ë¦½ í•„ìš” (Tab 4 ì—°ë™)<br>
                        <span style='background-color:#FFF8DD; padding:2px 5px; border-radius:3px;'>ğŸŸ¡ <b>Medium (8~14)</b></span>
                        ì§€ì†ì  ëª¨ë‹ˆí„°ë§ ë° ê´€ë¦¬ í•„ìš”<br>
                        <span style='background-color:#DDFFDD; padding:2px 5px; border-radius:3px;'>ğŸŸ¢ <b>Low (1~7)</b></span>
                        í˜„ ìƒíƒœ ìœ ì§€ ë° ê´€ì°°
                        </div>
                        """, unsafe_allow_html=True
                    )

                st.markdown("**ìƒìœ„ ìœ„í—˜ ë¦¬ìŠ¤íŠ¸**")
                display_df = top_risks[['ì‚¬ê³ ìœ í˜•', 'ìœ„í—˜ë“±ê¸‰', 'ìœ„í—˜ì ìˆ˜', 'ë°œìƒê±´ìˆ˜']].head(5)
                st.dataframe(
                    display_df, hide_index=True, use_container_width=True,
                    column_config={
                        "ìœ„í—˜ë“±ê¸‰": st.column_config.TextColumn("ë“±ê¸‰"),
                        "ìœ„í—˜ì ìˆ˜": st.column_config.ProgressColumn("ìœ„í—˜ ì ìˆ˜", format="%dì ", min_value=0, max_value=25),
                    }
                )
                st.info("ğŸ‘‰ **Tab 4**ì—ì„œ AI ì¡°ì¹˜ ë§¤ë‰´ì–¼ì„ í™•ì¸í•˜ì„¸ìš”.")
                    
        except Exception as e:
            st.error(f"ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    else:
        st.warning("ë¶„ì„í•  ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")


# ==================================================================
# TAB 4. ğŸš¨ ìœ„í—˜ íŒë‹¨ & ì¡°ì¹˜ ì¶”ì²œ (Action Plan) - [ë ˆì´ì•„ì›ƒ ê°œì„  Ver]
# ==================================================================
with tab4:
    st.subheader("ğŸš¨ ìœ„í—˜ ëŒ€ì‘ ì†”ë£¨ì…˜ (Action Plan)")
    st.caption("ìœ„í—˜ ìš”ì¸ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ì¡°ì¹˜ ë°©ì•ˆì„ ì „ì²´ í™”ë©´ìœ¼ë¡œ ìƒì„±í•©ë‹ˆë‹¤.")

    if 'priority_risks' in st.session_state and not st.session_state['priority_risks'].empty:
        priority_df = st.session_state['priority_risks']
        risk_list = priority_df['ì‚¬ê³ ìœ í˜•'].tolist()
        
        # 1. ìƒë‹¨ ì»¨íŠ¸ë¡¤ íŒ¨ë„
        with st.container():
            c1, c2, c3 = st.columns([2, 2, 1])
            
            with c1:
                selected_risk = st.selectbox("ğŸ“Œ ë¶„ì„í•  ìœ„í—˜ ìš”ì¸ ì„ íƒ", risk_list)
            
            # ì„ íƒëœ ìœ„í—˜ ìš”ì¸ ì •ë³´
            target_row = priority_df[priority_df['ì‚¬ê³ ìœ í˜•'] == selected_risk].iloc[0]
            
            with c2:
                st.metric(
                    label="ìœ„í—˜ë„ ì •ë³´", 
                    value=f"{target_row['ìœ„í—˜ë“±ê¸‰']} ({target_row['ìœ„í—˜ì ìˆ˜']}ì )",
                    delta=f"ë°œìƒ {target_row['ë°œìƒê±´ìˆ˜']}ê±´",
                    delta_color="inverse"
                )
            
            with c3:
                st.write("") # ì¤„ë°”ê¿ˆ
                btn_generate = st.button("ğŸ§¬ ì¡°ì¹˜ë°©ì•ˆ ìƒì„±", type="primary", use_container_width=True)

        st.divider()

        # 2. ê²°ê³¼ ì¶œë ¥ í™”ë©´
        if btn_generate:
            # (ì£¼ì˜) get_vectorstore, get_selected_model, get_llm í•¨ìˆ˜ê°€ main.pyì— ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•¨
            vectorstore = get_vectorstore() 
            if not vectorstore:
                st.error("ğŸš¨ ë²¡í„° DBê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Tab 1ì—ì„œ DB ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
            else:
                with st.spinner(f"'{selected_risk}' ê´€ë ¨ ê·œì • ë¶„ì„ ë° ì¡°ì¹˜ì•ˆ ì‘ì„± ì¤‘..."):
                    try:
                        # RAG ê²€ìƒ‰
                        query = f"{selected_risk} ì‚¬ê³  ì˜ˆë°© ì‘ì—… ì ˆì°¨ ì•ˆì „ ìˆ˜ì¹™"
                        retriever = vectorstore.as_retriever(search_kwargs={"k": 4})
                        docs = retriever.invoke(query)
                        context = "\n".join([d.page_content for d in docs])
                        
                        # í”„ë¡¬í”„íŠ¸ ìƒì„±
                        prompt = f"""
                        ë‹¹ì‹ ì€ ì² ë„ ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                        ì•„ë˜ [ê²€ìƒ‰ëœ ê·œì •]ì„ ê·¼ê±°ë¡œ '{selected_risk}' ìœ„í—˜ì— ëŒ€í•œ êµ¬ì²´ì ì¸ í–‰ë™ ë§¤ë‰´ì–¼ì„ ì‘ì„±í•˜ì„¸ìš”.
                        
                        [ê²€ìƒ‰ëœ ê·œì •]
                        {context}
                        
                        [ì‘ì„± ìš”ë ¹]
                        1. ì œëª©ì„ í¬ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.
                        2. 'ì‘ì—… ì „', 'ì‘ì—… ì¤‘', 'ë¹„ìƒ ì‹œ' ë‹¨ê³„ë³„ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
                        3. ê·œì •ì— ì—†ëŠ” ë‚´ìš©ì€ ì¼ë°˜ ì•ˆì „ ìˆ˜ì¹™ì„ ì ìš©í•˜ë˜ ëª…ì‹œí•˜ì„¸ìš”.
                        4. ë¶ˆë¦¿ í¬ì¸íŠ¸ë¥¼ í™œìš©í•´ ê°€ë…ì„±ì„ ë†’ì´ì„¸ìš”.
                        """
                        
                        model_name = get_selected_model()
                        llm = get_llm(model_name)
                        
                        # LLM í˜¸ì¶œ
                        if hasattr(llm, 'invoke'):
                            resp = llm.invoke([HumanMessage(content=prompt)])
                            result_text = resp.content
                        else:
                            result_text = llm.predict(prompt)
                            
                        # ê²°ê³¼ ì¶œë ¥
                        st.markdown(f"### ğŸ“‹ [{selected_risk}] ì•ˆì „ ì¡°ì¹˜ ê°€ì´ë“œ")
                        
                        with st.container(border=True):
                            st.markdown(result_text)
                        
                        with st.expander("ğŸ“ ì°¸ê³ í•œ ê·œì • ì›ë¬¸ ë³´ê¸°"):
                            st.text(context)
                            
                    except Exception as e:
                        st.error(f"ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        st.warning("âš ï¸ Tab 3(í†µí•© ìœ„í—˜ ë¶„ì„)ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ìœ„í—˜ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")