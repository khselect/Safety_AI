import os
import re
import pandas as pd
import streamlit as st
import altair as alt  

# ------------------------------------------------------------------
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° ì„¤ì •
# ------------------------------------------------------------------
from langchain_chroma import Chroma
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

# core ëª¨ë“ˆ ì„¤ì •
from core.config import PERSIST_DIRECTORY
from core.llm import get_llm, get_embeddings
from core.decision_ai import decision_ai

# ------------------------------------------------------------------
# ê¸°ë³¸ í˜ì´ì§€ ì„¤ì •
# ------------------------------------------------------------------
st.set_page_config(
    page_title="ì‚¬ìš©ì ì½˜ì†”",
    layout="wide"
)

st.title("ğŸ›¡ï¸ ì² ë„ì•ˆì „ AI í†µí•© ë¶„ì„ ì‹œìŠ¤í…œ")

# ------------------------------------------------------------------
# í•¨ìˆ˜ ì •ì˜
# ------------------------------------------------------------------
def get_vectorstore():
    # 1. DB í´ë”ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
    if not os.path.exists(PERSIST_DIRECTORY):
        return None
    
    try:
        # 2. ChromaDB ë¡œë“œ
        # ì£¼ì˜: collection_name="regulations" ë¶€ë¶„ì„ ì‚­ì œí–ˆìŠµë‹ˆë‹¤.
        # admin.pyì—ì„œ ì €ì¥í•œ ê¸°ë³¸ ì„¤ì •ê³¼ ë§ì¶”ê¸° ìœ„í•¨ì…ë‹ˆë‹¤.
        vectorstore = Chroma(
            persist_directory=PERSIST_DIRECTORY,
            embedding_function=get_embeddings()
        )
        return vectorstore
    except Exception as e:
        st.error(f"ë²¡í„° ì €ì¥ì†Œ ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

def query_regulation(query, vectorstore, llm):
    """
    ì§ˆë¬¸ì— ëŒ€í•´ ë²¡í„° ì €ì¥ì†Œì—ì„œ ë¬¸ì„œë¥¼ ì°¾ê³  LLMì´ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    # ê²€ìƒ‰ ë²”ìœ„ (k=6)
    retriever = vectorstore.as_retriever(search_kwargs={"k": 6})
    
    docs = retriever.invoke(query)
    if not docs:
        return "í•´ë‹¹ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ê·œì • ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []

    prompt_template = """
    ### [Role]
    ë‹¹ì‹ ì€ í•œêµ­ì˜ ì² ë„ ì•ˆì „ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
    ì•„ë˜ [ê·œì • ë¬¸ë§¥]ì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•˜ì‹­ì‹œì˜¤.

    ### [Guidelines]
    1. **ë°˜ë“œì‹œ í•œêµ­ì–´(Korean)ë¡œë§Œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.** (Do not use English).
    2. ë‹µë³€ì€ [ê·œì • ë¬¸ë§¥]ì— ìˆëŠ” ë‚´ìš©ì—ë§Œ ê¸°ë°˜í•´ì•¼ í•©ë‹ˆë‹¤.
    3. ê·œì •ì— ì—†ëŠ” ë‚´ìš©ì„ ì§ˆë¬¸í•˜ë©´ "ê·œì •ì— ê´€ë ¨ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
    4. ì¡°í•­ ë²ˆí˜¸(ì˜ˆ: ì œ3ì¡°)ë‚˜ ìˆ˜ì¹˜(ì˜ˆ: 10m, 30%)ëŠ” ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”.
    5. ë‹µë³€ í†¤ì€ ì „ë¬¸ì ì´ê³  ëª…í™•í•˜ë©° ì¹œì ˆí•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.

    [ê·œì • ë¬¸ë§¥]:
    {context}

    ì§ˆë¬¸: {question}
    
    ë‹µë³€:
    """
    PROMPT = PromptTemplate(
        template=prompt_template, 
        input_variables=["context", "question"]
    )

    chain = RetrievalQA.from_chain_type(
        llm=llm,
        chain_type="stuff",
        retriever=retriever,
        chain_type_kwargs={"prompt": PROMPT},
        return_source_documents=True
    )
    
    result = chain.invoke({"query": query})
    return result["result"], result["source_documents"]

# ------------------------------------------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# ------------------------------------------------------------------
if "llm" not in st.session_state:
    st.session_state["llm"] = get_llm("korean-llama3")

if "vectorstore" not in st.session_state:
    st.session_state["vectorstore"] = get_vectorstore()

# ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (messages ë¦¬ìŠ¤íŠ¸ì— sources ì •ë³´ë„ í•¨ê»˜ ì €ì¥)
if "messages" not in st.session_state:
    st.session_state["messages"] = []

llm = st.session_state["llm"]
vectorstore = st.session_state["vectorstore"]

BASE_DIR = os.path.dirname(os.path.abspath(__file__))
SHARED_DIR = os.path.join(BASE_DIR, "shared")
FILE_PATH = os.path.join(SHARED_DIR, "risk_df.pkl")

# ------------------------------------------------------------------
# ì‚¬ì´ë“œë°”
# ------------------------------------------------------------------
# with st.sidebar:
#     st.header("ğŸ”Œ ì‹œìŠ¤í…œ ìƒíƒœ")
#     if vectorstore is not None:
#         try:
#             count = vectorstore._collection.count()
#             st.success(f"ê·œì • DB ì—°ê²°ë¨ (ë¬¸ì„œ ì²­í¬: {count}ê°œ)")
#         except:
#             st.warning("ê·œì • DB ì—°ê²° ë¶ˆì•ˆì •")
#     else:
#         st.error("ê·œì • DBë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
#     if st.button("ëŒ€í™” ë‚´ìš© ì´ˆê¸°í™”"):
#         st.session_state["messages"] = []
#         st.rerun()

# ======================================
# íƒ­ êµ¬ì„±
# ======================================
tab1, tab2, tab3, tab4 = st.tabs([
    "ğŸ’¬ ê·œì • ì±—ë´‡",
    "ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ",
    "ğŸ§  í†µí•© ìœ„í—˜ ë¶„ì„",
    "ğŸš¨ ìœ„í—˜ íŒë‹¨ & ì¡°ì¹˜ ì¶”ì²œ"
])

# # ======================================
# # TAB 1. ğŸ’¬ ê·œì • ì±—ë´‡ (Smart Filtering & Enhanced Prompt ì ìš©)
# # ======================================
# with tab1:
#     st.subheader("ğŸ’¬ ê·œì • ì „ë¬¸ ì±—ë´‡")
#     st.caption("ğŸ’¡ íŒ: ê·œì • ì´ë¦„ì„ í¬í•¨í•˜ë©´ ì •í™•ë„ê°€ ë¹„ì•½ì ìœ¼ë¡œ ìƒìŠ¹í•©ë‹ˆë‹¤.")
    
#     # [1] ìƒë‹¨ ê³ ì • ì…ë ¥ì°½
#     with st.form(key="chat_form", clear_on_submit=True):
#         col1, col2 = st.columns([8, 1])
#         with col1:
#             user_input = st.text_input(
#                 "ì§ˆë¬¸ ì…ë ¥", 
#                 placeholder="ì˜ˆ: ë³´ìˆ˜ê·œì •ì—ì„œ í‰ê°€ê¸‰ ì§€ê¸‰ìœ¨ì€ ì–´ë–»ê²Œ ë¼?", 
#                 label_visibility="collapsed"
#             )
#         with col2:
#             submit_btn = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°", use_container_width=True)

#     # [2] ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
#     if submit_btn and user_input:
#         if vectorstore is None:
#             st.error("âš ï¸ ê·œì • ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#         else:
#             with st.spinner("ê·œì • ì •ë°€ ë¶„ì„ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
#                 # ------------------------------------------------------------------
#                 # [í•µì‹¬ ë¡œì§ 1] ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ í•„í„°ë§ (Smart Filtering)
#                 # ------------------------------------------------------------------
#                 # 1. DBì— ìˆëŠ” ëª¨ë“  íŒŒì¼ëª… ê°€ì ¸ì˜¤ê¸°
#                 try:
#                     all_data = vectorstore.get()
#                     unique_sources = list(set([m['source'] for m in all_data['metadatas']]))
#                 except:
#                     unique_sources = []

#                 # 2. ì§ˆë¬¸ì— íŒŒì¼ëª…ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
#                 search_filter = None
#                 target_source_name = "ì „ì²´ ê·œì •"
                
#                 for source in unique_sources:
#                     # íŒŒì¼ëª… ì •ì œ (ì˜ˆ: "ì¸ì‚¬ê·œì •.pdf" -> "ì¸ì‚¬ê·œì •")
#                     clean_name = os.path.splitext(os.path.basename(source))[0]
#                     # ì§ˆë¬¸ì— í‚¤ì›Œë“œê°€ ìˆê³ , 2ê¸€ì ì´ìƒì¼ ë•Œ í•„í„° ì ìš©
#                     if len(clean_name) >= 2 and clean_name in user_input:
#                         search_filter = {"source": source}
#                         target_source_name = clean_name
#                         break 
                
#                 # 3. ê²€ìƒ‰ ìˆ˜í–‰ (í•„í„° ìœ ë¬´ì— ë”°ë¼ ì „ëµ ë³€ê²½)
#                 if search_filter:
#                     # íŠ¹ì • ë¬¸ì„œ ì§€ì • ì‹œ: í•´ë‹¹ ë¬¸ì„œ ì§‘ì¤‘ ê²€ìƒ‰ (k=7)
#                     retriever = vectorstore.as_retriever(
#                         search_kwargs={"k": 7, "filter": search_filter}
#                     )
#                     status_msg = f"ğŸ¯ **'{target_source_name}'** ë¬¸ì„œ ë‚´ì—ì„œ ì§‘ì¤‘ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
#                 else:
#                     # ì§€ì • ì—†ì„ ì‹œ: ë„“ì€ ë²”ìœ„ ê²€ìƒ‰ (k=10) -> ìœ ì‚¬ ë¬¸ì„œê°€ ë§ì•„ë„ ì •ë‹µ í¬í•¨ í™•ë¥  ë†’ì„
#                     retriever = vectorstore.as_retriever(
#                         search_kwargs={"k": 10}
#                     )
#                     status_msg = "ğŸ” ì „ì²´ ê·œì • ë¬¸ì„œì—ì„œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."

#                 # 4. ë¬¸ì„œ ì¡°íšŒ ë° ì¤‘ë³µ ì œê±°
#                 retrieved_docs = retriever.invoke(user_input)
                
#                 seen_content = set()
#                 final_docs = []
#                 for d in retrieved_docs:
#                     if d.page_content not in seen_content:
#                         final_docs.append(d)
#                         seen_content.add(d.page_content)
                
#                 # ì»¨í…ìŠ¤íŠ¸ ìƒì„± (í† í° ì ˆì•½ ìœ„í•´ ìƒìœ„ 6ê°œ ì‚¬ìš©)
#                 context_text = "\n\n".join([d.page_content for d in final_docs[:6]])

#                 # ------------------------------------------------------------------
#                 # [í•µì‹¬ ë¡œì§ 2] í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°•í™” (Enhanced Prompt)
#                 # ------------------------------------------------------------------
#                 if not context_text:
#                     response_text = "ê´€ë ¨ëœ ê·œì • ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
#                 else:
#                     # ìš©ì–´ í˜¼ë™ ë°©ì§€ ë° í‘œ ì²˜ë¦¬ ì§€ì¹¨ ì¶”ê°€
#                     prompt_template = f"""
#                     [System Instruction]
#                     ë‹¹ì‹ ì€ ì‚¬ë‚´ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ [ì œê³µëœ ê·œì •]ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
                    
#                     **ì¤‘ìš” ì§€ì¹¨**:
#                     1. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
#                     2. ì§ˆë¬¸ì— ì–¸ê¸‰ëœ ê·œì • ë‚´ ë‹¨ì–´ë¥¼ ì°¸ì¡°í•´(ì˜ˆ: ë³´ìˆ˜, ì¸ì‚¬, ì•ˆì „) ìµœìš°ì„ ìœ¼ë¡œ ì¸ìš©í•˜ì„¸ìš”.
#                     3. ì•„ë˜ [ê·œì • ë¬¸ì„œ]ì— í¬í•¨ëœ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
#                     4. ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³  "ê·œì •ì— ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
#                     5. ê°€ëŠ¥í•œ ê²½ìš° ì¡°ë¬¸ ë²ˆí˜¸ì™€ í•¨ê»˜ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.

#                     [ì œê³µëœ ê·œì •]:
#                     {context_text}

#                     [ì§ˆë¬¸]:
#                     {user_input}

#                     [ë‹µë³€]:
#                     """
                    
#                     # LLM í˜¸ì¶œ (main.py ìƒë‹¨ì— llm ê°ì²´ê°€ ìˆë‹¤ê³  ê°€ì •)
#                     try:
#                         response_text = llm.invoke(prompt_template).content
#                     except Exception as e:
#                         response_text = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

#                 # ------------------------------------------------------------------
#                 # [UI ì²˜ë¦¬] ë©”ì‹œì§€ ì €ì¥ ë° ì¶œì²˜ ì •ì œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€+ê°œì„ )
#                 # ------------------------------------------------------------------
                
#                 # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
#                 st.session_state.messages.append({"role": "user", "content": user_input})
                
#                 # ì¶œì²˜ ì •ì œ ë¡œì§ (User Code ë°˜ì˜)
#                 formatted_sources = []
#                 seen_titles = set()
                
#                 for doc in final_docs: # ê²€ìƒ‰ëœ final_docs ì‚¬ìš©
#                     source_file = os.path.basename(doc.metadata.get("source", "íŒŒì¼ ì •ë³´ ì—†ìŒ"))
#                     raw_title = doc.metadata.get("Article_Title", "ì¡°í•­ ì •ë³´ ì—†ìŒ")
                    
#                     # ì œëª© ì •ì œ (Regex)
#                     match = re.match(r"(ì œ\s*\d+\s*ì¡°(?:ì˜\d+)?(?:\([^)]*\))?)", raw_title)
#                     if match:
#                         clean_title = match.group(1)
#                     else:
#                         clean_title = raw_title[:30] + "..." if len(raw_title) > 30 else raw_title

#                     unique_key = (source_file, clean_title)
                    
#                     if unique_key not in seen_titles:
#                         formatted_sources.append({
#                             "source": source_file,
#                             "title": clean_title,
#                             "content": doc.page_content
#                         })
#                         seen_titles.add(unique_key)

#                 # AI ë©”ì‹œì§€ ì €ì¥ (status_msg í¬í•¨)
#                 st.session_state.messages.append({
#                     "role": "assistant", 
#                     "content": response_text,
#                     "sources": formatted_sources,
#                     "status": status_msg # ê²€ìƒ‰ ìƒíƒœ ì •ë³´ ì¶”ê°€
#                 })

#     # [3] ëŒ€í™” ë‚´ìš© ì¶œë ¥ (ì—­ìˆœ)
#     st.divider()
    
#     # ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ì—­ìˆœìœ¼ë¡œ ì¶œë ¥
#     if "messages" in st.session_state and st.session_state.messages:
#         for msg in reversed(st.session_state.messages):
#             with st.chat_message(msg["role"]):
#                 st.write(msg["content"])
                
#                 # AI ë‹µë³€ì¸ ê²½ìš° ë¶€ê°€ ì •ë³´ í‘œì‹œ
#                 if msg["role"] == "assistant":
#                     # ê²€ìƒ‰ ìƒíƒœ (í•„í„°ë§ ì—¬ë¶€) í‘œì‹œ - í† ìŠ¤íŠ¸ ë©”ì‹œì§€ ëŠë‚Œìœ¼ë¡œ ì‘ê²Œ
#                     if msg.get("status"):
#                         st.caption(msg["status"])
                    
#                     # ê·¼ê±° ê·œì • í‘œì‹œ
#                     if msg.get("sources"):
#                         with st.expander("ğŸ“š ê´€ë ¨ ê·¼ê±° ê·œì • í™•ì¸ (ì›ë¬¸ ë³´ê¸°)"):
#                             for i, src in enumerate(msg["sources"]):
#                                 st.markdown(f"**[{i+1}] {src['source']} - {src['title']}**")
#                                 st.info(f"{src['content'][:300]} ... (ìƒëµ)")
# # ======================================
# # TAB 1. ğŸ’¬ ê·œì • ì±—ë´‡ (ìœ ì—°í•œ í‚¤ì›Œë“œ ë§¤ì¹­ & í‘œ ì¸ì‹ ê°•í™”)
# # ======================================
# with tab1:
#     st.subheader("ğŸ’¬ ê·œì • ì „ë¬¸ ì±—ë´‡")
#     st.caption("ğŸ’¡ íŒ: ê·œì • ì´ë¦„ì„ í¬í•¨í•˜ë©´ ì •í™•ë„ê°€ ë¹„ì•½ì ìœ¼ë¡œ ìƒìŠ¹í•©ë‹ˆë‹¤.")
    
#     # [1] ìƒë‹¨ ê³ ì • ì…ë ¥ì°½
#     with st.form(key="chat_form", clear_on_submit=True):
#         col1, col2 = st.columns([8, 1])
#         with col1:
#             user_input = st.text_input(
#                 "ì§ˆë¬¸ ì…ë ¥", 
#                 placeholder="ì˜ˆ: ìœ„í—˜ë„í‰ê°€ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë¼?", 
#                 label_visibility="collapsed"
#             )
#         with col2:
#             submit_btn = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°", use_container_width=True)

#     # [2] ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
#     if submit_btn and user_input:
#         if vectorstore is None:
#             st.error("âš ï¸ ê·œì • ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
#         else:
#             with st.spinner("ê·œì • ì •ë°€ ë¶„ì„ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
#                 # ------------------------------------------------------------------
#                 # [í•µì‹¬ ë¡œì§ 1] ìœ ì—°í•œ ìŠ¤ë§ˆíŠ¸ ê²€ìƒ‰ í•„í„°ë§ (Flexible Smart Filtering)
#                 # ------------------------------------------------------------------
#                 try:
#                     all_data = vectorstore.get()
#                     unique_sources = list(set([m['source'] for m in all_data['metadatas']]))
#                 except:
#                     unique_sources = []

#                 search_filter = None
#                 target_source_name = "ì „ì²´ ê·œì •"
                
#                 # íŒŒì¼ëª… ë¶„ì„ ë° ìœ ì—°í•œ ë§¤ì¹­
#                 # ì˜ˆ: íŒŒì¼ëª…ì´ "02.ë³´ìˆ˜ ë° ë³µë¦¬í›„ìƒê·œì •.pdf"ì¼ ë•Œ -> "ë³´ìˆ˜"ë¼ëŠ” ë‹¨ì–´ë§Œ ì§ˆë¬¸ì— ìˆì–´ë„ ë§¤ì¹­ ì„±ê³µì‹œí‚´
#                 for source in unique_sources:
#                     base_name = os.path.basename(source) # ì˜ˆ: 02_ë³´ìˆ˜ê·œì •_v1.pdf
#                     clean_name = os.path.splitext(base_name)[0] # ì˜ˆ: 02_ë³´ìˆ˜ê·œì •_v1
                    
#                     # íŒŒì¼ëª…ì„ íŠ¹ìˆ˜ë¬¸ì ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì˜ˆ: ['02', 'ë³´ìˆ˜ê·œì •', 'v1'])
#                     # ë” ì„¸ë°€í•˜ê²Œ: 2ê¸€ì ì´ìƒì¸ í•œê¸€ ë‹¨ì–´ë¥¼ ì¶”ì¶œí•˜ëŠ” ê²ƒì´ ì¢‹ìŒ
#                     keywords = re.split(r'[_\s\.\-\(\)\[\]]+', clean_name)
                    
#                     match_found = False
#                     for kw in keywords:
#                         # í‚¤ì›Œë“œê°€ 2ê¸€ì ì´ìƒì´ê³ , ì‚¬ìš©ì ì§ˆë¬¸ì— í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ í•„í„° ì ìš©
#                         # ì˜ˆ: kw="ë³´ìˆ˜" -> user_input="ë³´ìˆ˜ê·œì •ì—ì„œ..." (ë§¤ì¹­ ì„±ê³µ)
#                         if len(kw) >= 2 and kw in user_input:
#                             search_filter = {"source": source}
#                             target_source_name = base_name
#                             match_found = True
#                             break
                    
#                     if match_found:
#                         break # í•˜ë‚˜ë¼ë„ ë§¤ì¹­ë˜ë©´ ì¤‘ë‹¨ (ìš°ì„ ìˆœìœ„ ë¡œì§ì´ í•„ìš”í•˜ë©´ ìˆ˜ì • ê°€ëŠ¥)
                
#                 # 3. ê²€ìƒ‰ ìˆ˜í–‰
#                 if search_filter:
#                     # í•„í„°ë§ ì„±ê³µ ì‹œ: í•´ë‹¹ ë¬¸ì„œ ì§‘ì¤‘ ê²€ìƒ‰
#                     retriever = vectorstore.as_retriever(
#                         search_kwargs={"k": 8, "filter": search_filter} # kë¥¼ ì¡°ê¸ˆ ë” ëŠ˜ë¦¼
#                     )
#                     status_msg = f"ğŸ¯ **'{target_source_name}'** ë¬¸ì„œ ë‚´ì—ì„œ ì§‘ì¤‘ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
#                 else:
#                     # í•„í„°ë§ ì‹¤íŒ¨ ì‹œ: ì „ì²´ ê²€ìƒ‰ (k=10)
#                     retriever = vectorstore.as_retriever(
#                         search_kwargs={"k": 10}
#                     )
#                     status_msg = "ğŸ” ì „ì²´ ê·œì • ë¬¸ì„œì—ì„œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."

#                 # 4. ë¬¸ì„œ ì¡°íšŒ ë° ì¤‘ë³µ ì œê±°
#                 retrieved_docs = retriever.invoke(user_input)
                
#                 seen_content = set()
#                 final_docs = []
#                 for d in retrieved_docs:
#                     # ë‚´ìš© ì¤‘ë³µ ì œê±° (ì •í™•íˆ ê°™ì€ ì²­í¬ê°€ ì—¬ëŸ¬ ë²ˆ ì¡í ë•Œ)
#                     if d.page_content not in seen_content:
#                         final_docs.append(d)
#                         seen_content.add(d.page_content)
                
#                 context_text = "\n\n".join([d.page_content for d in final_docs[:6]])

#                 # ------------------------------------------------------------------
#                 # [í•µì‹¬ ë¡œì§ 2] í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ê°•í™” (í‘œ/ìˆ˜ì¹˜ ê°•ì¡°)
#                 # ------------------------------------------------------------------
#                 if not context_text:
#                     response_text = "ê´€ë ¨ëœ ê·œì • ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
#                 else:
#                     prompt_template = f"""
#                     [System Instruction]
#                     ë‹¹ì‹ ì€ ì‚¬ë‚´ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ [ì œê³µëœ ê·œì •]ì„ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
                    
#                     **ì ˆëŒ€ ê·œì¹™**:
#                     1. ë‹µë³€ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
#                     2. ì§ˆë¬¸ì— íŠ¹ì • ê·œì •(ì˜ˆ: ë³´ìˆ˜ê·œì •)ì´ ì–¸ê¸‰ë˜ì—ˆë‹¤ë©´, í•´ë‹¹ ê·œì •ì˜ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. (ë‹¤ë¥¸ ê·œì • ë‚´ìš©ì€ ë¬´ì‹œí•  ê²ƒ)
#                     3. **'ì§€ê¸‰ìœ¨(%)', 'ì¸ì›ë°°ë¶„(%)', 'ë“±ê¸‰(S,A,B...)'** ê°™ì€ ìˆ˜ì¹˜ ë°ì´í„°ëŠ” í…ìŠ¤íŠ¸ë¡œ í’€ì§€ ë§ê³ , **ë°˜ë“œì‹œ ë§ˆí¬ë‹¤ìš´ í‘œ(Table)**ë¡œ ì‘ì„±í•˜ì„¸ìš”.
#                     4. 'í‰ê°€(Assessment)'ì™€ 'í‰ê°€ê¸‰(Payment/Bonus)'ì„ ì—„ê²©íˆ êµ¬ë¶„í•˜ì„¸ìš”. ì§ˆë¬¸ì´ ëˆ(ì§€ê¸‰)ì— ê´€í•œ ê²ƒì´ë©´ 'ë³´ìˆ˜/ë³µë¦¬í›„ìƒ' ê´€ë ¨ í‘œë¥¼ ì°¾ìœ¼ì„¸ìš”.
#                     5. ë¬¸ë§¥ì— ë§ëŠ” ì •ë‹µì´ [ì œê³µëœ ê·œì •]ì— ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ ëª¨ë¥¸ë‹¤ê³  ë‹µí•˜ì„¸ìš”.
#                     6. ì§ˆë¬¸ì— ì–¸ê¸‰ëœ ê·œì • ë‚´ ë‹¨ì–´ë¥¼ ì°¸ì¡°í•´(ì˜ˆ: ë³´ìˆ˜, ì¸ì‚¬, ì•ˆì „) ìµœìš°ì„ ìœ¼ë¡œ ì¸ìš©í•˜ì„¸ìš”.
#                     7. ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì€ ì§€ì–´ë‚´ì§€ ë§ê³  "ê·œì •ì— ëª…ì‹œë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
#                     8. ê°€ëŠ¥í•œ ê²½ìš° ì¡°ë¬¸ ë²ˆí˜¸ì™€ í•¨ê»˜ ì„¤ëª…í•˜ì‹­ì‹œì˜¤.
#                     9. ë‹¤ì‹œ í•œë²ˆ í™•ì¸í•˜ì§€ë§Œ ë‹µë³€ì€ ë¬´ì¡°ê±´ í•œêµ­ì–´ë¡œë§Œ ì‘ì„±í•´ì¤˜!

#                     [ì œê³µëœ ê·œì •]:
#                     {context_text}

#                     [ì§ˆë¬¸]:
#                     {user_input}

#                     [ë‹µë³€]:
#                     """
                    
#                     try:
#                         response_text = llm.invoke(prompt_template).content
#                     except Exception as e:
#                         response_text = f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

#                 # ------------------------------------------------------------------
#                 # [UI ì²˜ë¦¬] ë©”ì‹œì§€ ë° ì¶œì²˜ ì •ì œ
#                 # ------------------------------------------------------------------
#                 st.session_state.messages.append({"role": "user", "content": user_input})
                
#                 formatted_sources = []
#                 seen_titles = set()
                
#                 for doc in final_docs: 
#                     source_file = os.path.basename(doc.metadata.get("source", "íŒŒì¼ ì •ë³´ ì—†ìŒ"))
#                     raw_title = doc.metadata.get("Article_Title", "ì¡°í•­ ì •ë³´ ì—†ìŒ")
                    
#                     match = re.match(r"(ì œ\s*\d+\s*ì¡°(?:ì˜\d+)?(?:\([^)]*\))?)", raw_title)
#                     if match:
#                         clean_title = match.group(1)
#                     else:
#                         clean_title = raw_title[:30] + "..." if len(raw_title) > 30 else raw_title

#                     unique_key = (source_file, clean_title)
#                     if unique_key not in seen_titles:
#                         formatted_sources.append({
#                             "source": source_file,
#                             "title": clean_title,
#                             "content": doc.page_content
#                         })
#                         seen_titles.add(unique_key)

#                 st.session_state.messages.append({
#                     "role": "assistant", 
#                     "content": response_text,
#                     "sources": formatted_sources,
#                     "status": status_msg
#                 })

#     # [3] ëŒ€í™” ë‚´ìš© ì¶œë ¥ (ìŠ¤íƒ êµ¬ì¡°: ìµœì‹  ëŒ€í™”ê°€ ìƒë‹¨, ë‚´ë¶€ëŠ” ì§ˆë¬¸->ë‹µë³€ ìˆœ)
#     st.divider()
    
#     # 1. ë©”ì‹œì§€ë¥¼ ëŒ€í™” ìŒ(ì§ˆë¬¸-ë‹µë³€)ìœ¼ë¡œ ê·¸ë£¹í™”
#     conversations = []
#     current_group = []

#     # ì „ì²´ ë©”ì‹œì§€ë¥¼ ìˆœíšŒí•˜ë©° [User, Assistant] ë‹¨ìœ„ë¡œ ë¬¶ìŒ
#     for msg in st.session_state.messages:
#         if msg["role"] == "user":
#             # ìƒˆë¡œìš´ ì§ˆë¬¸ì´ ì‹œì‘ë˜ë©´, ì´ì „ ê·¸ë£¹(ìˆë‹¤ë©´)ì„ ì €ì¥í•˜ê³  ì´ˆê¸°í™”
#             if current_group:
#                 conversations.append(current_group)
#             current_group = [msg]
#         else:
#             # AI ë‹µë³€(assistant)ì€ í˜„ì¬ ì§ˆë¬¸ ê·¸ë£¹ì— í¬í•¨
#             current_group.append(msg)

#     # ë§ˆì§€ë§‰ ë‚¨ì€ ê·¸ë£¹ ì €ì¥
#     if current_group:
#         conversations.append(current_group)

#     # 2. ê·¸ë£¹ ë‹¨ìœ„ë¡œ ì—­ìˆœ(ìµœì‹ ìˆœ) ì •ë ¬í•˜ì—¬ ì¶œë ¥
#     # (ê·¸ë£¹ ìì²´ëŠ” ìµœì‹ ìˆœìœ¼ë¡œ ë‚˜ì˜¤ì§€ë§Œ, ê·¸ë£¹ ë‚´ë¶€ì˜ for msg in groupì€ ì •ìˆœ(ì§ˆë¬¸->ë‹µë³€)ìœ¼ë¡œ ì¶œë ¥ë¨)
#     if conversations:
#         for group in reversed(conversations):
#             with st.container(): # ê·¸ë£¹ë³„ ì»¨í…Œì´ë„ˆ (ì‹œê°ì  ë¶„ë¦¬)
#                 for msg in group:
#                     with st.chat_message(msg["role"]):
#                         st.write(msg["content"])
                        
#                         # AI ë‹µë³€ì¼ ê²½ìš° ë¶€ê°€ ì •ë³´(ì¶œì²˜, ìƒíƒœ ë“±) í‘œì‹œ
#                         if msg["role"] == "assistant":
#                             if msg.get("status"):
#                                 st.caption(msg["status"])
                            
#                             if msg.get("sources"):
#                                 with st.expander("ğŸ“š ê´€ë ¨ ê·¼ê±° ê·œì • í™•ì¸ (ì›ë¬¸ ë³´ê¸°)"):
#                                     for i, src in enumerate(msg["sources"]):
#                                         st.markdown(f"**[{i+1}] {src['source']} - {src['title']}**")
#                                         st.info(f"{src['content'][:300]} ... (ìƒëµ)")
                
#                 # ëŒ€í™” ì„¸íŠ¸ ê°„ êµ¬ë¶„ì„  (ê°€ë…ì„± í–¥ìƒ)
#                 st.divider()

# ======================================
# TAB 1. ğŸ’¬ ê·œì • ì±—ë´‡ (ê°œì„ ëœ ë²„ì „)
# ======================================
with tab1:
    st.subheader("ğŸ’¬ ê·œì • ì „ë¬¸ ì±—ë´‡")
    st.caption("ğŸ’¡ íŒ: 'ë³´ìˆ˜ê·œì •ì—ì„œ í‰ê°€ê¸‰ ì§€ê¸‰ìœ¨ì€?' ì²˜ëŸ¼ ê·œì • ì´ë¦„ì„ í¬í•¨í•˜ë©´ ì •í™•ë„ê°€ ì˜¬ë¼ê°‘ë‹ˆë‹¤.")
    
    # [1] ìƒë‹¨ ê³ ì • ì…ë ¥ì°½
    with st.form(key="chat_form", clear_on_submit=True):
        col1, col2 = st.columns([8, 1])
        with col1:
            user_input = st.text_input(
                "ì§ˆë¬¸ ì…ë ¥", 
                placeholder="ì˜ˆ: ìœ„í—˜ë„í‰ê°€ ì ˆì°¨ëŠ” ì–´ë–»ê²Œ ë¼?", 
                label_visibility="collapsed"
            )
        with col2:
            submit_btn = st.form_submit_button("ì§ˆë¬¸í•˜ê¸°", use_container_width=True)

    # [2] ì§ˆë¬¸ ì²˜ë¦¬ ë¡œì§
    if submit_btn and user_input:
        if vectorstore is None:
            st.error("âš ï¸ ê·œì • ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        else:
            with st.spinner("ê·œì • ì •ë°€ ë¶„ì„ ë° ë‹µë³€ ìƒì„± ì¤‘..."):
                
                # --- 1. ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ë¡œì§ ---
                search_kwargs = {"k": 6} # ê¸°ë³¸ ê²€ìƒ‰ ì„¤ì •
                status_msg = "ğŸ” ì „ì²´ ê·œì • ë¬¸ì„œì—ì„œ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                
                try:
                    # DBì— ìˆëŠ” ì†ŒìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ê°€ë²¼ìš´ ë©”íƒ€ë°ì´í„° ì¡°íšŒ)
                    # ì£¼ì˜: ë°ì´í„°ê°€ ë§ìœ¼ë©´ ì´ ë¶€ë¶„ì´ ëŠë ¤ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‹¤ì œ ìš´ì˜ì‹œì—” ìºì‹± ê¶Œì¥
                    all_data = vectorstore.get() 
                    unique_sources = list(set([m['source'] for m in all_data['metadatas'] if m]))
                except:
                    unique_sources = []

                # ì‚¬ìš©ì ì…ë ¥ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° í•„í„°ë§
                target_source_name = None
                for source in unique_sources:
                    base_name = os.path.basename(source)
                    clean_name = os.path.splitext(base_name)[0]
                    
                    # íŒŒì¼ëª…ì„ í† í°í™” (ì˜ˆ: '02_ë³´ìˆ˜ê·œì •' -> ['02', 'ë³´ìˆ˜ê·œì •'])
                    keywords = re.split(r'[_\s\.\-\(\)\[\]]+', clean_name)
                    
                    for kw in keywords:
                        # 2ê¸€ì ì´ìƒì´ê³  ì§ˆë¬¸ì— í¬í•¨ëœ ê²½ìš° í•„í„° ì ìš©
                        if len(kw) >= 2 and kw in user_input:
                            search_kwargs["filter"] = {"source": source}
                            target_source_name = base_name
                            break
                    if target_source_name: break

                if target_source_name:
                    status_msg = f"ğŸ¯ **'{target_source_name}'** ë¬¸ì„œ ë‚´ì—ì„œ ì§‘ì¤‘ ê²€ìƒ‰í–ˆìŠµë‹ˆë‹¤."
                
                # --- 2. ê²€ìƒ‰ ìˆ˜í–‰ (MMR ë°©ì‹ ë„ì…) ---
                # MMR: ìœ ì‚¬ë„ë¿ë§Œ ì•„ë‹ˆë¼ ë¬¸ì„œ ê°„ ë‹¤ì–‘ì„±ë„ ê³ ë ¤í•˜ì—¬ ì¤‘ë³µëœ ë‚´ìš©(ê°™ì€ ì¡°í•­ì˜ ë°˜ë³µ)ì„ ì¤„ì„
                retriever = vectorstore.as_retriever(
                    search_type="mmr", 
                    search_kwargs={**search_kwargs, "fetch_k": 20, "lambda_mult": 0.7} 
                    # fetch_k: í›„ë³´êµ° 20ê°œ, lambda_mult: 0.7 (1ì— ê°€ê¹Œìš°ë©´ ìœ ì‚¬ë„ ì¤‘ì‹¬, 0ì— ê°€ê¹Œìš°ë©´ ë‹¤ì–‘ì„± ì¤‘ì‹¬)
                )
                
                retrieved_docs = retriever.invoke(user_input)
                
                # --- 3. ë¬¸ì„œ ì •ì œ ë° ì»¨í…ìŠ¤íŠ¸ ìƒì„± ---
                final_docs = []
                seen_content = set()
                
                for d in retrieved_docs:
                    # ë‚´ìš© ì¤‘ë³µ ì œê±°
                    if d.page_content not in seen_content:
                        # ì“°ë ˆê¸° ë°ì´í„°(íŒŒì´í”„ ë¼ì¸ ë“±)ê°€ í˜¹ì‹œ ë‚¨ì•„ìˆë‹¤ë©´ ì œì™¸
                        if "|||" in d.page_content or len(d.page_content.strip()) < 10:
                            continue
                        final_docs.append(d)
                        seen_content.add(d.page_content)
                
                context_text = "\n\n".join([d.page_content for d in final_docs])

                # --- 4. í”„ë¡¬í”„íŠ¸ ë° LLM í˜¸ì¶œ ---
                if not context_text:
                    response_text = "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ê·œì • ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê²€ìƒ‰ëœ ë¬¸ì„œ ì—†ìŒ)"
                    final_docs = [] # ì†ŒìŠ¤ ì—†ìŒ
                else:
                    prompt_template = f"""
                    [System Instruction]
                    ë‹¹ì‹ ì€ ì‚¬ë‚´ ê·œì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ [Context]ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ì„¸ìš”.
                    
                    **ë‹µë³€ ì‘ì„± ì›ì¹™**:
                    1. **ê·¼ê±° ì¤‘ì‹¬**: ìƒìƒí•˜ì§€ ë§ê³  ë°˜ë“œì‹œ [Context]ì— ìˆëŠ” ë‚´ìš©ìœ¼ë¡œë§Œ ë‹µí•˜ì„¸ìš”. 
                    2. **í‘œ/ìˆ˜ì¹˜ ìœ ì§€**: ë“±ê¸‰í‘œ, ì§€ê¸‰ìœ¨ ë“±ì€ ë§ˆí¬ë‹¤ìš´ í‘œ(Table)ë¡œ ê¹”ë”í•˜ê²Œ ì •ë¦¬í•˜ì„¸ìš”.
                    3. **ì¡°í•­ ëª…ì‹œ**: ê°€ëŠ¥í•˜ë‹¤ë©´ "ì œOOì¡°ì— ë”°ë¥´ë©´..." í˜•íƒœë¡œ ì¶œì²˜ë¥¼ ë°íˆì„¸ìš”.
                    4. **ëª¨ë¥´ë©´ ëª¨ë¥¸ë‹¤ê³  í•˜ê¸°**: ë¬¸ë§¥ì— ë‹µì´ ì—†ìœ¼ë©´ "ê·œì •ì— í•´ë‹¹ ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ë‹µí•˜ì„¸ìš”.
                    5. **ì–¸ì–´**: í•œêµ­ì–´ë¡œ ì •ì¤‘í•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”.

                    [Context]:
                    {context_text}

                    [Question]:
                    {user_input}

                    [Answer]:
                    """
                    try:
                        response_text = llm.invoke(prompt_template).content
                    except Exception as e:
                        response_text = f"AI ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"

                # --- 5. UI ì—…ë°ì´íŠ¸ (ë©”ì‹œì§€ ì €ì¥) ---
                st.session_state.messages.append({"role": "user", "content": user_input})
                
                # ì†ŒìŠ¤ ì •ì œ (ì œëª© ê¹”ë”í•˜ê²Œ)
                formatted_sources = []
                seen_titles = set()
                
                for doc in final_docs:
                    src_file = os.path.basename(doc.metadata.get("source", "íŒŒì¼"))
                    raw_title = doc.metadata.get("Article_Title", "ë³¸ë¬¸")
                    
                    # ì œëª© ì •ì œ Regex
                    match = re.match(r"(ì œ\s*\d+\s*ì¡°(?:ì˜\d+)?(?:\([^)]*\))?)", raw_title)
                    clean_title = match.group(1) if match else raw_title[:30]
                    
                    key = (src_file, clean_title)
                    if key not in seen_titles:
                        formatted_sources.append({
                            "source": src_file,
                            "title": clean_title,
                            "content": doc.page_content
                        })
                        seen_titles.add(key)

                st.session_state.messages.append({
                    "role": "assistant",
                    "content": response_text,
                    "sources": formatted_sources,
                    "status": status_msg
                })
                
    # [3] ëŒ€í™” ë‚´ìš© ì¶œë ¥ (ê·¸ë£¹í™” + ìµœì‹ ìˆœ ì •ë ¬)
    st.divider()
    
    conversations = []
    current_group = []

    # ë©”ì‹œì§€ ê·¸ë£¹í™”
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            if current_group:
                conversations.append(current_group)
            current_group = [msg]
        else:
            current_group.append(msg)
    if current_group:
        conversations.append(current_group)

    # ì¶œë ¥ loop
    if conversations:
        for group in reversed(conversations):
            with st.container():
                for msg in group:
                    with st.chat_message(msg["role"]):
                        st.write(msg["content"])
                        
                        if msg["role"] == "assistant":
                            if msg.get("status"):
                                st.caption(msg["status"])
                            if msg.get("sources"):
                                with st.expander("ğŸ“š ê´€ë ¨ ê·¼ê±° ê·œì • í™•ì¸"):
                                    for i, src in enumerate(msg["sources"]):
                                        st.markdown(f"**[{i+1}] {src['source']} - {src['title']}**")
                                        # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°ì—ì„œ íŒŒì´í”„ ë¬¸ì ë“±ì´ ë³´ì´ë©´ í•„í„°ë§í•´ì„œ ë³´ì—¬ì¤Œ
                                        display_content = src['content'].replace("|", " ").replace("\n", " ")[:200]
                                        st.caption(f"{display_content}...")
                st.divider()

# ======================================
# TAB 2. ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ (Professional Ver.)
# ======================================
with tab2:
    # 1. í—¤ë” & ì»¨íŠ¸ë¡¤ íŒ¨ë„
    col_header, col_filter = st.columns([3, 1])
    
    with col_header:
        st.subheader("ğŸ“ˆ ìœ„í—˜ ìƒí™© ëŒ€ì‹œë³´ë“œ")
        st.caption("ë°ì´í„° ê¸°ë°˜ ì‚¬ê³  ì›ì¸ ë° ì¶”ì„¸ ì‹¬ì¸µ ë¶„ì„")
        
    with col_filter:
        line_options = ["ì „ì²´", "1í˜¸ì„ ", "2í˜¸ì„ ", "7í˜¸ì„ "]
        selected_line = st.selectbox("ğŸ” í˜¸ì„  í•„í„°", line_options)

    st.markdown("---")

    if os.path.exists(FILE_PATH):
        try:
            df = pd.read_pickle(FILE_PATH)
            
            # -----------------------------------------------------------
            # [1] ë°ì´í„° ì „ì²˜ë¦¬
            # -----------------------------------------------------------
            col_map = {
                "line": "í˜¸ì„ ",
                "date": "ë°œìƒì¼ì",
                "cause": "ë¶€ì›ì¸",
                "place": "ë°œìƒì¥ì†Œ",
                "r_type": "ê·€ì±…êµ¬ë¶„",
                "age": "ì—°ë ¹ëŒ€"
            }
            
            for key, actual_col in col_map.items():
                if actual_col not in df.columns:
                    df[actual_col] = "ì •ë³´ì—†ìŒ" if key != "date" else "2024-01-01"

            # í˜¸ì„  ì •ì œ í•¨ìˆ˜
            def clean_line_name(val):
                val_str = str(val)
                if "1í˜¸ì„ " in val_str: return "1í˜¸ì„ "
                if "2í˜¸ì„ " in val_str: return "2í˜¸ì„ "
                if "7í˜¸ì„ " in val_str: return "7í˜¸ì„ "
                return "ê¸°íƒ€"
            
            # ê´„í˜¸ ë° ìˆ«ì ì œê±° í•¨ìˆ˜ ([2]ìŒì£¼ -> ìŒì£¼)
            def clean_label_text(val):
                val_str = str(val)
                # ëŒ€ê´„í˜¸ì™€ ê·¸ ì•ˆì˜ ìˆ«ì/ë¬¸ì ì œê±° í›„ ì•ë’¤ ê³µë°± ì œê±°
                return re.sub(r'\[.*?\]', '', val_str).strip()

            df["í˜¸ì„ _ì •ì œ"] = df[col_map["line"]].apply(clean_line_name)
            df[col_map["date"]] = pd.to_datetime(df[col_map["date"]], errors='coerce')
            df["ì›”"] = df[col_map["date"]].dt.strftime('%Y-%m')

            # ë¶„ì„ìš© ì»¬ëŸ¼ë“¤ì— ëŒ€í•´ ë¼ë²¨ í´ë¦¬ë‹ ë¯¸ë¦¬ ì ìš© (ê°€ë…ì„± í–¥ìƒ)
            target_cols_clean = [col_map["cause"], col_map["place"], col_map["r_type"], col_map["age"]]
            for col in target_cols_clean:
                df[col] = df[col].apply(clean_label_text)

            # -----------------------------------------------------------
            # [2] ë°ì´í„° í•„í„°ë§
            # -----------------------------------------------------------
            target_lines = ["1í˜¸ì„ ", "2í˜¸ì„ ", "7í˜¸ì„ "]
            
            if selected_line == "ì „ì²´":
                filtered_df = df[df["í˜¸ì„ _ì •ì œ"].isin(target_lines)]
                if filtered_df.empty: filtered_df = df 
            else:
                filtered_df = df[df["í˜¸ì„ _ì •ì œ"] == selected_line]

            # -----------------------------------------------------------
            # [3] ëŒ€ì‹œë³´ë“œ ì‹œê°í™”
            # -----------------------------------------------------------
            if not filtered_df.empty:
                
                # [KPI Section] í•µì‹¬ ìš”ì•½
                kpi1, kpi2, kpi3, kpi4 = st.columns(4)
                
                total_cnt = len(filtered_df)
                kpi1.metric("ì´ ë°œìƒ ê±´ìˆ˜", f"{total_cnt}ê±´")
                
                top_cause = filtered_df[col_map["cause"]].mode()[0] if not filtered_df[col_map["cause"]].empty else "-"
                cause_cnt = filtered_df[col_map["cause"]].value_counts().iloc[0] if not filtered_df[col_map["cause"]].empty else 0
                kpi2.metric("ìµœë‹¤ ë¹ˆë„ ì›ì¸", top_cause, f"{cause_cnt}ê±´")
                
                top_place = filtered_df[col_map["place"]].mode()[0] if not filtered_df[col_map["place"]].empty else "-"
                kpi3.metric("ì£¼ìš” ë°œìƒ ì¥ì†Œ", top_place)

                top_resp = filtered_df[col_map["r_type"]].mode()[0] if not filtered_df[col_map["r_type"]].empty else "-"
                kpi4.metric("ì£¼ìš” ê·€ì±… ì‚¬ìœ ", top_resp)

                st.markdown("###")

                # [Chart Row 1] ì‹œê³„ì—´ ë¶„ì„ (ê¸°ì¡´ ìœ ì§€)
                st.markdown("##### ğŸ“… ì›”ë³„ ì‚¬ê³  ë°œìƒ ì¶”ì´ ë° ì›ì¸ êµ¬ì„±")
                time_chart_data = filtered_df.groupby(["ì›”", col_map["cause"]]).size().reset_index(name='ê±´ìˆ˜')
                
                time_chart = alt.Chart(time_chart_data).mark_bar().encode(
                    x=alt.X('ì›”', title='ê¸°ê°„'),
                    y=alt.Y('ê±´ìˆ˜', title='ë°œìƒ ê±´ìˆ˜'),
                    color=alt.Color(col_map["cause"], title='ë¶€ì›ì¸'),
                    tooltip=['ì›”', col_map["cause"], 'ê±´ìˆ˜']
                ).properties(height=300) # ë†’ì´ ì•½ê°„ ì¡°ì •
                
                st.altair_chart(time_chart, use_container_width=True)

                st.divider()

                # [Chart Row 2] ìƒì„¸ í†µê³„ ë¶„ì„ (1x4 êµ¬ì¡°ë¡œ ë³€ê²½ + ì½”ë©˜íŠ¸)
                st.markdown("##### ğŸ“Š ìƒì„¸ í†µê³„ ë° ì¸ì‚¬ì´íŠ¸ ë¶„ì„")

                # --- [í•¨ìˆ˜] ì°¨íŠ¸, í…Œì´ë¸”, ì½”ë©˜íŠ¸ ìƒì„± ---
                def create_analysis_component(data, col_name, title):
                    # 1. ë°ì´í„° ì§‘ê³„
                    counts = data[col_name].value_counts().reset_index()
                    counts.columns = ["í•­ëª©", "ê±´ìˆ˜"]
                    
                    # 2. ë¹„ìœ¨ ê³„ì‚°
                    total = counts["ê±´ìˆ˜"].sum()
                    if total > 0:
                        counts["ë¹„ìœ¨"] = ((counts["ê±´ìˆ˜"] / total) * 100).round(1) # ì†Œìˆ˜ì  1ìë¦¬
                    else:
                        counts["ë¹„ìœ¨"] = 0
                    
                    # 3. Altair ë„ë„› ì°¨íŠ¸
                    base = alt.Chart(counts).encode(theta=alt.Theta("ê±´ìˆ˜", stack=True))
                    
                    pie = base.mark_arc(innerRadius=50, outerRadius=90).encode(
                        color=alt.Color("í•­ëª©", legend=alt.Legend(orient="right", title=None)), 
                        order=alt.Order("ê±´ìˆ˜", sort="descending"),
                        tooltip=["í•­ëª©", "ê±´ìˆ˜", alt.Tooltip("ë¹„ìœ¨", format=".1f")]
                    )
                    
                    # [ìˆ˜ì •] .filter() -> .transform_filter() ë¡œ ë³€ê²½
                    text = base.mark_text(radius=110).encode(
                        text=alt.Text("ë¹„ìœ¨", format=".0f"), 
                        order=alt.Order("ê±´ìˆ˜", sort="descending"),
                        color=alt.value("black")
                    ).transform_filter(
                        alt.datum.ë¹„ìœ¨ > 4  # ë¹„ìœ¨ì´ 4% ì´ˆê³¼ì¸ ê²ƒë§Œ í…ìŠ¤íŠ¸ í‘œì‹œ
                    )

                    chart = (pie + text).properties(height=250)

                    # 4. í…Œì´ë¸” ë°ì´í„° ì •ë¦¬
                    table_df = counts[["í•­ëª©", "ê±´ìˆ˜", "ë¹„ìœ¨"]].copy()
                    table_df.columns = ["í•­ëª©", "ê±´ìˆ˜", "ë¹„ìœ¨(%)"]
                    
                    # 5. ìë™ ë¶„ì„ í…ìŠ¤íŠ¸ ìƒì„±
                    if not counts.empty:
                        top1 = counts.iloc[0]
                        insight_text = f"""
                        - **ìµœë‹¤ ë¹ˆë„:** <span style='color:red'>**{top1['í•­ëª©']}**</span> ({top1['ê±´ìˆ˜']}ê±´, {top1['ë¹„ìœ¨']}%)
                        """
                        
                        if len(counts) > 1:
                            top2 = counts.iloc[1]
                            diff = top1['ê±´ìˆ˜'] - top2['ê±´ìˆ˜']
                            insight_text += f"""
                            - **2ìœ„ í•­ëª©:** {top2['í•­ëª©']} ({top2['ë¹„ìœ¨']}%)
                            - **ë¶„ì„:** 1ìœ„ í•­ëª©ì´ 2ìœ„ ëŒ€ë¹„ **{diff}ê±´** ë” ë§ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.
                            ì§‘ì¤‘ì ì¸ ê´€ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤.
                            """
                    else:
                        insight_text = "ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

                    return chart, table_df, insight_text

                # --- [ë©”ì¸ ë¡œì§] 1 Row per Metric (1x4 Stack) ---
                metrics = [
                    ("cause", "1. ë¶€ì›ì¸ ë¶„ì„"),
                    ("place", "2. ë°œìƒì¥ì†Œ ë¶„ì„"),
                    ("r_type", "3. ê·€ì±…êµ¬ë¶„ ë¶„ì„"),
                    ("age", "4. ì—°ë ¹ëŒ€ë³„ ë¶„ì„")
                ]

                for col_key, title in metrics:
                    st.markdown(f"**ğŸ“Œ {title}**")
                    
                    # ë ˆì´ì•„ì›ƒ ë¹„ìœ¨ [ì°¨íŠ¸(2) : í…Œì´ë¸”(1.5) : ì½”ë©˜íŠ¸(1.5)]
                    c1, c2, c3 = st.columns([2, 1.5, 1.5])
                    
                    chart, df_table, insight = create_analysis_component(filtered_df, col_map[col_key], title)
                    
                    with c1:
                        st.altair_chart(chart, use_container_width=True)
                    
                    with c2:
                        st.dataframe(
                            df_table, 
                            hide_index=True, 
                            use_container_width=True,
                            height=200
                        )
                    
                    with c3:
                        st.info("ğŸ’¡ **AI Insight**")
                        st.markdown(insight, unsafe_allow_html=True)
                    
                    st.divider() # í•­ëª© ê°„ êµ¬ë¶„ì„ 

                # [List Section] ë°ì´í„° ë¦¬ìŠ¤íŠ¸ (ê¸°ì¡´ ìœ ì§€)
                st.markdown(f"##### ğŸ“‹ {selected_line} Raw Data (ìƒìœ„ 100ê±´)")
                st.dataframe(
                    filtered_df.head(100), 
                    use_container_width=True, 
                    height=250, 
                    hide_index=True
                )
            
            else:
                st.warning(f"ì„ íƒí•˜ì‹  '{selected_line}'ì— í•´ë‹¹í•˜ëŠ” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")

        except Exception as e:
            st.error(f"ëŒ€ì‹œë³´ë“œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # ë””ë²„ê¹…ìš© traceback ì¶œë ¥ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
            # import traceback
            # st.text(traceback.format_exc())
    else:
        st.info("ì•„ì§ ìƒí™©ë³´ê³  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ê´€ë¦¬ì í˜ì´ì§€ì—ì„œ ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.")

# ======================================
# TAB 3. ğŸ›¡ï¸ í†µí•© ìœ„í—˜ ë¶„ì„ (Integrated Risk Analysis) - Ver 1.2
# ======================================
with tab3:
    st.subheader("ğŸ›¡ï¸ í†µí•© ìœ„í—˜ë„ í‰ê°€ (Risk Assessment)")
    
    # -------------------------------------------------------
    # [Data Load & Preprocessing]
    # -------------------------------------------------------
    if os.path.exists(FILE_PATH):
        df_risk = pd.read_pickle(FILE_PATH)
        
        # ë°ì´í„° ì „ì²˜ë¦¬
        col_map = {"cause": "ë¶€ì›ì¸"}
        if "ë¶€ì›ì¸" not in df_risk.columns:
            df_risk["ë¶€ì›ì¸"] = df_risk["cause"] if "cause" in df_risk.columns else "ì •ë³´ì—†ìŒ"
        
        # ë¼ë²¨ í´ë¦¬ë‹
        df_risk["ë¶€ì›ì¸"] = df_risk["ë¶€ì›ì¸"].apply(lambda x: re.sub(r'\[.*?\]', '', str(x)).strip())

        # -------------------------------------------------------
        # [Step 1] ì‹¬ê°ë„(Severity) ë°ì´í„° ì¤€ë¹„ (ì„¤ì • UIëŠ” í•˜ë‹¨/ìˆ¨ê¹€ ì²˜ë¦¬)
        # -------------------------------------------------------
        unique_causes = df_risk["ë¶€ì›ì¸"].unique()

        # ê¸°ë³¸ ì‹¬ê°ë„ ë§¤í•‘ í•¨ìˆ˜
        def get_default_severity(cause):
            cause = str(cause)
            if any(x in cause for x in ['ì‚¬ë§', 'íƒˆì„ ', 'ì¶©ëŒ', 'í™”ì¬', 'í­ë°œ', 'ìì‚´']): return 5
            if any(x in cause for x in ['ì¶”ë½', 'ê°ì „', 'ë¼ì„', 'í˜‘ì°©', 'ì ˆë‹¨']): return 4
            if any(x in cause for x in ['ê³¨ì ˆ', 'ë² ì„', 'í™”ìƒ', 'ëˆ„ìˆ˜']): return 3
            if any(x in cause for x in ['ë„˜ì–´ì§', 'ì „ë„', 'ë¶€ë”ªí˜', 'ìŒì£¼', 'ë¶€ì£¼ì˜']): return 2
            return 1

        # ë°ì´í„°í”„ë ˆì„ ìƒì„±
        severity_data = []
        for c in unique_causes:
            severity_data.append({"ì‚¬ê³ ìœ í˜•": c, "ì‹¬ê°ë„(1-5)": get_default_severity(c)})
        
        df_severity_default = pd.DataFrame(severity_data).sort_values(by="ì‹¬ê°ë„(1-5)", ascending=False)

        # -------------------------------------------------------
        # [Step 1-1] ì„¤ì •ì°½: ì‹œê°ì  ê°„ì†Œí™”ë¥¼ ìœ„í•´ Expander ì‚¬ìš©
        # -------------------------------------------------------
        # ì±—ë´‡ì˜ í•µì‹¬(ë¶„ì„ ê²°ê³¼)ì„ ë¨¼ì € ë³´ì—¬ì£¼ê¸° ìœ„í•´ ì„¤ì •ì„ ì ‘ì–´ë‘ 
        with st.expander("âš™ï¸ [ì„¤ì •] ì‚¬ê³  ìœ í˜•ë³„ ì‹¬ê°ë„ ê¸°ì¤€ ë³€ê²½í•˜ê¸° (í´ë¦­)", expanded=False):
            st.caption("ì•„ë˜ í‘œì—ì„œ ì‚¬ê³  ìœ í˜•ë³„ ì‹¬ê°ë„(1~5)ë¥¼ ìˆ˜ì •í•˜ë©´ ë§¤íŠ¸ë¦­ìŠ¤ì— ì¦‰ì‹œ ë°˜ì˜ë©ë‹ˆë‹¤.")
            edited_severity_df = st.data_editor(
                df_severity_default,
                column_config={
                    "ì‹¬ê°ë„(1-5)": st.column_config.NumberColumn(
                        "ì‹¬ê°ë„", help="1:ê²½ë¯¸ ~ 5:ì¹˜ëª…", min_value=1, max_value=5, step=1
                    )
                },
                use_container_width=True,
                hide_index=True,
                key="severity_editor" # í‚¤ë¥¼ ì§€ì •í•˜ì—¬ ìƒíƒœ ìœ ì§€
            )

        # -------------------------------------------------------
        # [Step 2] ìœ„í—˜ë„(Risk) ê³„ì‚° ë¡œì§
        # -------------------------------------------------------
        # 1. ë¹ˆë„(Frequency) ì§‘ê³„
        df_freq = df_risk["ë¶€ì›ì¸"].value_counts().reset_index()
        df_freq.columns = ["ì‚¬ê³ ìœ í˜•", "ë°œìƒê±´ìˆ˜"]

        # 2. ì‹¬ê°ë„(Severity) ë³‘í•© (í¸ì§‘ëœ ë°ì´í„° ì‚¬ìš©)
        df_calc = pd.merge(df_freq, edited_severity_df, on="ì‚¬ê³ ìœ í˜•", how="left")

        # 3. ë¹ˆë„ ë“±ê¸‰(Freq Level) ìë™ ì‚°ì¶œ (1~5ë“±ê¸‰)
        max_count = df_calc["ë°œìƒê±´ìˆ˜"].max()
        def get_freq_level(cnt, max_val):
            if max_val == 0: return 1
            ratio = cnt / max_val
            if ratio >= 0.8: return 5
            elif ratio >= 0.6: return 4
            elif ratio >= 0.4: return 3
            elif ratio >= 0.2: return 2
            else: return 1

        df_calc["ë¹ˆë„ë“±ê¸‰(1-5)"] = df_calc["ë°œìƒê±´ìˆ˜"].apply(lambda x: get_freq_level(x, max_count))
        df_calc["ìœ„í—˜ì ìˆ˜"] = df_calc["ë¹ˆë„ë“±ê¸‰(1-5)"] * df_calc["ì‹¬ê°ë„(1-5)"]

        # 4. Risk Zone íŒì •
        def get_risk_zone(score):
            if score >= 15: return "ğŸ”´ High"
            elif score >= 8: return "ğŸŸ¡ Medium"
            else: return "ğŸŸ¢ Low"

        df_calc["ìœ„í—˜ë“±ê¸‰"] = df_calc["ìœ„í—˜ì ìˆ˜"].apply(get_risk_zone)

        # Tab 4 ì—°ë™ì„ ìœ„í•œ ì„¸ì…˜ ì €ì¥
        top_risks = df_calc.sort_values(by=["ìœ„í—˜ì ìˆ˜", "ë°œìƒê±´ìˆ˜"], ascending=[False, False])
        st.session_state['priority_risks'] = top_risks

        st.divider()

        # -------------------------------------------------------
        # [Step 3] 5x5 Risk Matrix ì‹œê°í™” (ê°œì„ ëœ ë²„ì „)
        # -------------------------------------------------------
        c_left, c_right = st.columns([1.6, 1])

        with c_left:
            st.markdown("##### ğŸ“Š ìœ„í—˜ì„± í‰ê°€ ë§¤íŠ¸ë¦­ìŠ¤ (Risk Matrix)")
            
            # 1. ê·¸ë¦¬ë“œ ë°ì´í„° ìƒì„±
            grid_data = []
            for s in range(1, 6): 
                for f in range(1, 6):
                    score = s * f
                    if score >= 15: 
                        risk_grade, color, text_color = "High", "#FF4B4B", "white"
                    elif score >= 8: 
                        risk_grade, color, text_color = "Medium", "#FFAA00", "black"
                    else: 
                        risk_grade, color, text_color = "Low", "#00CC96", "black"
                    
                    grid_data.append({
                        "ì‹¬ê°ë„_X": s, "ë¹ˆë„ë“±ê¸‰_Y": f,
                        "ìœ„í—˜ì ìˆ˜": score,
                        "ë¼ë²¨": f"{risk_grade}\n{score}", # ì¤„ë°”ê¿ˆ ì ìš©
                        "ë°°ê²½ìƒ‰": color,
                        "ê¸€ììƒ‰": text_color
                    })
            df_grid_base = pd.DataFrame(grid_data)

            # 2. ë°ì´í„° ì§‘ê³„
            df_agg = df_calc.groupby(["ì‹¬ê°ë„(1-5)", "ë¹ˆë„ë“±ê¸‰(1-5)"]).agg(
                ì´ê±´ìˆ˜=("ë°œìƒê±´ìˆ˜", "sum"),
                ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸=("ì‚¬ê³ ìœ í˜•", lambda x: ", ".join(x.unique()))
            ).reset_index()
            
            # 3. ë³‘í•©
            df_matrix_final = pd.merge(
                df_grid_base, df_agg, 
                left_on=["ì‹¬ê°ë„_X", "ë¹ˆë„ë“±ê¸‰_Y"], 
                right_on=["ì‹¬ê°ë„(1-5)", "ë¹ˆë„ë“±ê¸‰(1-5)"], 
                how="left"
            ).fillna({"ì´ê±´ìˆ˜": 0, "ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸": "-"})

            # 4. Altair ì°¨íŠ¸ (í°íŠ¸ í¬ê¸° ë° ë°°ì¹˜ ìˆ˜ì •)
            base = alt.Chart(df_matrix_final).encode(
                x=alt.X("ì‹¬ê°ë„_X:O", title="ì¤‘ëŒ€ì„± (Severity) â¡ï¸", axis=alt.Axis(labelAngle=0)),
                y=alt.Y("ë¹ˆë„ë“±ê¸‰_Y:O", title="ê°€ëŠ¥ì„± (Frequency) â¬†ï¸", sort="descending")
            ).properties(height=450) # ë†’ì´ í™•ë³´

            # Layer 1: ë°°ê²½ íˆíŠ¸ë§µ
            heatmap = base.mark_rect().encode(
                color=alt.Color("ë°°ê²½ìƒ‰:N", scale=None),
                tooltip=["ì‹¬ê°ë„_X", "ë¹ˆë„ë“±ê¸‰_Y", "ë¼ë²¨", "ì´ê±´ìˆ˜", "ì‚¬ê³ ìœ í˜•_ë¦¬ìŠ¤íŠ¸"]
            )

            # Layer 2: ìœ„í—˜ ì ìˆ˜/ë“±ê¸‰ í…ìŠ¤íŠ¸ (í°íŠ¸ í¬ê²Œ!)
            text_score = base.mark_text(baseline="middle").encode(
                text=alt.Text("ë¼ë²¨"),
                color=alt.Color("ê¸€ììƒ‰:N", scale=None),
                size=alt.value(15),  # [ìˆ˜ì •] í°íŠ¸ í¬ê¸° ëŒ€í­ í™•ëŒ€ (24px)
                opacity=alt.value(0.6) # ë°°ê²½ ê¸€ì”¨ì²˜ëŸ¼ ì€ì€í•˜ê²Œ
            )

            # Layer 3: ì‹¤ì œ ë°œìƒ ê±´ìˆ˜ (ê°•ì¡°)
            text_count = base.transform_filter(
                alt.datum.ì´ê±´ìˆ˜ > 0
            ).mark_text(dy=25, fontWeight="bold").encode( # dy: ìœ„ì¹˜ë¥¼ ì•„ë˜ë¡œ
                text=alt.Text("ì´ê±´ìˆ˜", format="d"), # ìˆ«ìë§Œ í‘œì‹œ
                color=alt.value("blue"),
                size=alt.value(16)   # [ìˆ˜ì •] ê±´ìˆ˜ í°íŠ¸ í¬ê¸° í™•ëŒ€ (16px)
            )

            final_chart = (heatmap + text_score + text_count).configure_axis(
                labelFontSize=12,
                titleFontSize=14
            )
            
            st.altair_chart(final_chart, use_container_width=True)

        with c_right:
            st.markdown("##### ğŸš¨ ìœ„í—˜ ìš°ì„ ìˆœìœ„ (Top Risks)")
            
            # ìµœìš°ì„  ìœ„í—˜ í•­ëª© ì¹´ë“œë·°
            if not top_risks.empty:
                worst = top_risks.iloc[0]
                st.error(f"**1ìœ„: {worst['ì‚¬ê³ ìœ í˜•']}**")
                
                col_kpi1, col_kpi2 = st.columns(2)
                col_kpi1.metric("ìœ„í—˜ ì ìˆ˜", f"{worst['ìœ„í—˜ì ìˆ˜']}ì ", help="ì‹¬ê°ë„ x ë¹ˆë„")
                col_kpi2.metric("ë°œìƒ ê±´ìˆ˜", f"{worst['ë°œìƒê±´ìˆ˜']}ê±´")
                
                st.progress(min(worst['ìœ„í—˜ì ìˆ˜']/25.0, 1.0), text="ìœ„í—˜ë„ ìˆ˜ì¤€")

            st.write("") # ì—¬ë°±
            
            # ë¦¬ìŠ¤íŠ¸ ë·°
            st.dataframe(
                top_risks[["ì‚¬ê³ ìœ í˜•", "ìœ„í—˜ë“±ê¸‰", "ìœ„í—˜ì ìˆ˜", "ë°œìƒê±´ìˆ˜"]],
                hide_index=True,
                use_container_width=True,
                height=300
            )

        # AI Insight
        st.info("ğŸ’¡ **AI ë¶„ì„:** ë¶‰ì€ìƒ‰(High) ì˜ì—­ì— ìœ„ì¹˜í•œ ì‚¬ê³  ìœ í˜•ì€ 'ì¦‰ì‹œ ê°œì„ 'ì´ í•„ìš”í•œ í•­ëª©ì…ë‹ˆë‹¤. ìš°ì¸¡ ë¦¬ìŠ¤íŠ¸ ìƒìœ„ í•­ëª©ì„ ì¤‘ì‹¬ìœ¼ë¡œ ì•ˆì „ ëŒ€ì±…ì„ ìˆ˜ë¦½í•˜ì„¸ìš”.")

    else:
        st.warning("ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# ======================================
# TAB 4. ğŸ¤– ìœ„í—˜ íŒë‹¨ ë° ì¡°ì¹˜ (AI Action Plan) - Ver 1.2 (Debug Mode)
# ======================================
from langchain.schema import HumanMessage, SystemMessage

with tab4:
    st.subheader("ğŸ¤– AI ìœ„í—˜ ëŒ€ì‘ ì†”ë£¨ì…˜")
    st.caption("ìœ„í—˜ì„± í‰ê°€ ê²°ê³¼(Tab 3)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ê·œ ë°ì´í„°(Tab 1)ë¥¼ ê²€ìƒ‰í•˜ì—¬ ë§ì¶¤í˜• ì¡°ì¹˜ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤.")

    # 1. Tab 3 ë¶„ì„ ê²°ê³¼ ë¶ˆëŸ¬ì˜¤ê¸°
    if 'priority_risks' in st.session_state and not st.session_state['priority_risks'].empty:
        priority_df = st.session_state['priority_risks']
        risk_options = priority_df['ì‚¬ê³ ìœ í˜•'].tolist()

        c1, c2 = st.columns([1, 2])
        
        with c1:
            st.markdown("##### ğŸ” ë¶„ì„ ëŒ€ìƒ ì„ íƒ")
            selected_risk = st.selectbox("ì¡°ì¹˜ ë°©ì•ˆì„ í™•ì¸í•  ìœ„í—˜ ìš”ì¸:", risk_options)
            
            # ì„ íƒëœ í•­ëª© ì •ë³´
            target_row = priority_df[priority_df['ì‚¬ê³ ìœ í˜•'] == selected_risk].iloc[0]
            st.info(f"""
            **{selected_risk}**
            - ë“±ê¸‰: {target_row['ìœ„í—˜ë“±ê¸‰']}
            - ì ìˆ˜: {target_row['ìœ„í—˜ì ìˆ˜']} (ê±´ìˆ˜: {target_row['ë°œìƒê±´ìˆ˜']})
            """)
            
            generate_btn = st.button("ğŸ§¬ ì¡°ì¹˜ë°©ì•ˆ ìƒì„± (Real-time)", type="primary", use_container_width=True)

        with c2:
            st.markdown(f"##### ğŸ“‹ '{selected_risk}' ì•ˆì „ ì¡°ì¹˜ ê°€ì´ë“œ")
            
            if generate_btn:
                # [í•„ìˆ˜ ì²´í¬] ë²¡í„° DBì™€ LLM ë¡œë“œ ì—¬ë¶€ í™•ì¸
                if 'vectorstore' not in st.session_state:
                    st.error("âš ï¸ ë²¡í„° DBê°€ ì—†ìŠµë‹ˆë‹¤. Tab 1ì—ì„œ ë¬¸ì„œë¥¼ ë¨¼ì € ì„ë² ë”©í•´ì£¼ì„¸ìš”.")
                # elif 'llm' not in st.session_state: # (í˜¹ì‹œ llmì„ ì„¸ì…˜ì— ë„£ìœ¼ì…¨ë‹¤ë©´ ì²´í¬)
                #     st.error("âš ï¸ LLM ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    with st.spinner(f"ê·œì • DB ê²€ìƒ‰ ë° ë¶„ì„ ì¤‘..."):
                        try:
                            # ---------------------------------------------------
                            # [1] ê²€ìƒ‰ ì¿¼ë¦¬ ìµœì í™” (ë‹¨ìˆœ í‚¤ì›Œë“œ -> ë¬¸ì¥í˜•)
                            # ---------------------------------------------------
                            # í‚¤ì›Œë“œê°€ ë„ˆë¬´ ì§§ìœ¼ë©´ ê²€ìƒ‰ì´ ì˜ ì•ˆë˜ë¯€ë¡œ ê¼¬ë¦¬ë§ì„ ë¶™ì—¬ì¤ë‹ˆë‹¤.
                            search_query = f"{selected_risk} ì‚¬ê³  ì˜ˆë°© ì‘ì—… ì ˆì°¨ ì•ˆì „ ìˆ˜ì¹™ ê¸ˆì§€ ì‚¬í•­"
                            
                            # ---------------------------------------------------
                            # [2] ë²¡í„° DB ê²€ìƒ‰ (Retriever)
                            # ---------------------------------------------------
                            # k=4: ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì„œ ì¡°ê° 4ê°œë¥¼ ê°€ì ¸ì˜´
                            retriever = st.session_state['vectorstore'].as_retriever(search_kwargs={"k": 4})
                            docs = retriever.get_relevant_documents(search_query)
                            
                            # ê²€ìƒ‰ëœ ë¬¸ì„œ ë‚´ìš© í•©ì¹˜ê¸°
                            context_text = "\n\n".join([doc.page_content for doc in docs])
                            
                            # ---------------------------------------------------
                            # [3] ë””ë²„ê¹…ìš©: ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ë¬´ì—‡ì¸ì§€ í™•ì¸ (ì¤‘ìš”!)
                            # ---------------------------------------------------
                            with st.expander("ğŸ” [ë””ë²„ê¹…] ë²¡í„° DBê°€ ì°¾ì•„ë‚¸ ì›ë¬¸ ë‚´ìš© ë³´ê¸°", expanded=False):
                                if not docs:
                                    st.warning("ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê²€ìƒ‰ì–´ê°€ ë§¤ë‰´ì–¼ì— ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                                for i, doc in enumerate(docs):
                                    st.text(f"[ë¬¸ì„œ {i+1}] Source: {doc.metadata.get('source', 'unknown')}")
                                    st.caption(doc.page_content[:300] + "...") # ì•ë¶€ë¶„ë§Œ ë¯¸ë¦¬ë³´ê¸°

                            # ---------------------------------------------------
                            # [4] LLM ìƒì„± ìš”ì²­ (ì‹¤ì œ ì—°ë™)
                            # ---------------------------------------------------
                            # ë¬¸ë§¥ì´ ë„ˆë¬´ ì—†ìœ¼ë©´ ì†”ì§í•˜ê²Œ ë§í•˜ë„ë¡ í”„ë¡¬í”„íŠ¸ ì¡°ì •
                            if not context_text:
                                st.warning("ê´€ë ¨ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë°˜ì ì¸ ì•ˆì „ ì§€ì¹¨ì„ ìƒì„±í•©ë‹ˆë‹¤.")
                                context_text = "ê´€ë ¨ ì‚¬ê·œ ì—†ìŒ. ì¼ë°˜ì ì¸ ì‚°ì—… ì•ˆì „ ê¸°ì¤€ì„ ì ìš©í•  ê²ƒ."

                            prompt = f"""
                            ë‹¹ì‹ ì€ ì² ë„/ì‚°ì—… ì•ˆì „ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. 
                            ì•„ë˜ì˜ [ê²€ìƒ‰ëœ ì‚¬ê·œ/ë§¤ë‰´ì–¼]ë§Œì„ ê·¼ê±°ë¡œ í•˜ì—¬, 
                            ìœ„í—˜ ìš”ì¸ '{selected_risk}'ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ëŒ€ì‘ ë§¤ë‰´ì–¼ì„ ì‘ì„±í•˜ì„¸ìš”.

                            [ê²€ìƒ‰ëœ ì‚¬ê·œ/ë§¤ë‰´ì–¼]
                            {context_text}

                            [ì‘ì„± ì›ì¹™]
                            1. ê²€ìƒ‰ëœ ë‚´ìš©ì— '{selected_risk}'ì™€ ì§ì ‘ ê´€ë ¨ëœ ë‚´ìš©ì´ ì—†ë‹¤ë©´, "ê´€ë ¨ëœ ë‚´ë¶€ ê·œì •ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."ë¼ê³  ì†”ì§íˆ ë§í•˜ê³  ì¼ë°˜ì ì¸ ì•ˆì „ ìˆ˜ì¹™ì„ ì œì•ˆí•˜ì„¸ìš”.
                            2. ëœ¬êµ¬ë¦„ ì¡ëŠ” ì†Œë¦¬ ëŒ€ì‹  'ì‘ì—… ì „', 'ì‘ì—… ì¤‘', 'ë¹„ìƒ ì‹œ' ë“± êµ¬ì²´ì ì¸ í–‰ë™ ìš”ë ¹ì„ ë‚˜ì—´í•˜ì„¸ìš”.
                            3. ì¶œì²˜(ë¬¸ì„œëª… ë“±)ë¥¼ ì•Œ ìˆ˜ ìˆë‹¤ë©´ í•¨ê»˜ ëª…ì‹œí•˜ì„¸ìš”.
                            """
                            
                            # ì‹¤ì œ LLM í˜¸ì¶œ (main.py ìƒë‹¨ì— ì„ ì–¸ëœ llm ê°ì²´ ì‚¬ìš©)
                            # (st.write_streamì„ ì“°ë©´ íƒ€ìê¸° íš¨ê³¼ ê°€ëŠ¥ - LangChain ë²„ì „ì— ë”°ë¼ ë‹¤ë¦„)
                            
                            # ë°©ë²• A: invoke ì‚¬ìš© (LangChain ìµœì‹ )
                            # response = llm.invoke(prompt)
                            # result_text = response.content
                            
                            # ë°©ë²• B: predict ì‚¬ìš© (LangChain êµ¬ë²„ì „)
                            # result_text = llm.predict(prompt)
                            
                            # [ê°€ì •] main.pyì— 'llm' ê°ì²´ê°€ ìˆë‹¤ê³  ê°€ì •í•˜ê³  ì‹¤í–‰
                            # ë§Œì•½ llm ê°ì²´ ì´ë¦„ì´ ë‹¤ë¥´ë©´(chat_model ë“±) ìˆ˜ì • í•„ìš”
                            if 'llm' in globals():
                                response = llm.invoke([HumanMessage(content=prompt)])
                                result_text = response.content
                            elif 'chat_model' in globals(): # ì´ë¦„ì´ chat_modelì¼ ê²½ìš°
                                response = chat_model.invoke([HumanMessage(content=prompt)])
                                result_text = response.content
                            else:
                                result_text = "âš ï¸ ì½”ë“œ ì—ëŸ¬: 'llm' ë˜ëŠ” 'chat_model' ê°ì²´ê°€ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. main.pyë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

                            st.markdown(result_text)

                        except Exception as e:
                            st.error(f"ìƒì„± ì˜¤ë¥˜: {e}")
                            st.info("ğŸ’¡ íŒ: Tab 1ì—ì„œ ë²¡í„° DBê°€ ì •ìƒì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆëŠ”ì§€ í™•ì¸í•´ë³´ì„¸ìš”.")
            else:
                st.info("ğŸ‘ˆ ì™¼ìª½ì—ì„œ ìœ„í—˜ ìš”ì¸ì„ ì„ íƒí•˜ê³  ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

    else:
        st.warning("âš ï¸ Tab 3(ìœ„í—˜ ë¶„ì„)ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.")